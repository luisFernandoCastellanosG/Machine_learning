{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"P2_2_PLN_redes neuronales recurrentes (RNN).ipynb","provenance":[],"collapsed_sections":["w8jPcr-tb-a5","Tkeq57R55V-W","ikT-PEFlRc7y","0ucpDS5lTgKB","ZBlU-qNzVOO7","ekQyJUbvWvpZ","4h3kjfw4XikQ","FczzMAAEX-6h","WWfRY8pPYMYp","CoKm0kDwY5XG","9R9T2vJ6ZU9t","zGLMqyQvWRRv","Dz7aR7_eiYGg","FshwyfFykB_4","uIkOBKGAP0y-"],"mount_file_id":"1TYtgx4tMtOsiYhI5wZr-vVyMDdojfLj9","authorship_tag":"ABX9TyNrrEHcZC29Oqqra4eOT8hR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"w8jPcr-tb-a5"},"source":["#P0. Introducción -PLN\n","\n","---\n","\n","En la creación de redes neuronales necesitamos dos tipos de IA, para reconocer patrones o generar nuevos:\n","\n","*   Las que no tienen memoria, identifica el patrón y ya!...ejemplo las de visión artificial\n","*   Las de memoria corta (Long Short Term Memory)...PLN\n","*   Las que requieren mucha memoria (aprenden casi todo...BERT)...PLN y visión artificial.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"NyasC25K4L-Y"},"source":["**Caso de estudio: generación de texto**\n","\n","---\n","\n","\n","Cualquier dato que se necesite procesar (sonido, imágenes, texto) primero debe ser convertido en un tensor numérico, un paso llamado “vectorización” (One-hot Encoding y WordEmbedding) de datos (y en nuestro ejemplo previamente las letras deben ser pasadas a valores numéricos "]},{"cell_type":"markdown","metadata":{"id":"u1OVaNED56Fz"},"source":["Para este ejemplo usaremos “*Character level language model*” propuesto por Andrej Karpathy en su artículo \"*The Unreasonable Effectiveness of Recurrent Neural Networks*\"(y parcialmente basado en su implementado en el tutorial \"*Generate text with an RNN*\" de la web de TensorFlow:\n","\n","Consiste en darle a la RNN una palabra y se le pide que modele la distribución de probabilidad del siguiente carácter que le correspondería a la secuencia de caracteres anteriores:\n","\n","Como ejemplo, supongamos que solo tenemos un vocabulario de cuatro letras posibles [“a”,”h”,”l”,”o”], y queremos entrenar a una RNN en la secuencia de entrenamiento “hola”. Esta secuencia de entrenamiento es, de hecho, una fuente de 3 ejemplos de entrenamiento por separado: La probabilidad de “o” debería ser verosímil dada el contexto de “h”, “l” debería ser verosímil en el contexto de “ho”, y finalmente “a” debería ser también verosímil dado el contexto de “hol”.\n","\n","\n","---\n","*   https://unipython.com/generacion-de-textos-con-inteligencia-artificial/\n","*    https://medium.com/analytics-vidhya/solution-to-tensorflow-2-not-using-gpu-119fb3e04daa (https://www.youtube.com/watch?v=kaQCdv46OBA&ab_channel=JeffHeaton)"]},{"cell_type":"markdown","metadata":{"id":"k6zNNLvrPR1f"},"source":["#EJEMPLO 1: Prediciendo un texto (cuento los tres cerditos)."]},{"cell_type":"code","metadata":{"id":"znb5-a_wR2Bs"},"source":["!kill -9 -1 #reiniciando la maquina virtual"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MVxWwESyPWDg"},"source":["##P0. importando librerias"]},{"cell_type":"markdown","metadata":{"id":"Vl0r6XTg4Jj7"},"source":["###Librerias genericas"]},{"cell_type":"code","metadata":{"id":"P-gVYOjJ4h_W"},"source":["!pip list"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"97eE8L5n4dxZ"},"source":["import requests\n","import io\n","import os\n","\n","import numpy as np\n","import sys\n","\n","#librerías para graficar\n","import matplotlib.pyplot as plt\n","                 \n","plt.rcParams['figure.figsize'] = (16, 9)  #ver graficas grandes \n","plt.style.use('ggplot')\n","#guardar las imagenes y tablas en el cuaderno de jupyter\n","%matplotlib inline "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IQc-WNUY5QhI"},"source":["###librerias para DL (Deep Learning)"]},{"cell_type":"code","metadata":{"id":"gcCanSaNPY4Y"},"source":["import tensorflow as tf"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ABOLhv9Y5Fuf","executionInfo":{"status":"ok","timestamp":1649969423190,"user_tz":300,"elapsed":770,"user":{"displayName":"Luis Fernando Castellanos Guarin","userId":"08966922054785833228"}},"outputId":"9a92f718-1c0c-4ad5-828a-8230745193c7"},"source":["print(\"Version: \", tf.__version__)\n","print(\"Eager mode: \", tf.executing_eagerly())\n","print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Version:  2.8.0\n","Eager mode:  True\n","GPU is available\n"]}]},{"cell_type":"markdown","metadata":{"id":"ZcwUPBdNy8w_"},"source":["Verificando los recursos de maquina para entrenar:\n","\n","---\n","**CUDA (GPU-NVIDIA):**\n","CUDA es una plataforma de computación paralela y un modelo de programación que hace que el uso de una GPU para la computación de propósito general sea simple y elegante"]},{"cell_type":"code","metadata":{"id":"6SJ4g06UyoZR"},"source":["print(\"-------------------------------Espacio DISCO------------------------------\")\n","!df -h\n","print(\"-------------------------------Espacio DISCO Disponible------------------------------\")\n","!df -h / | awk '{print $4}'\n","print(\"-------------------------------RAM------------------------------\")\n","!cat /proc/meminfo  #cuanta memoria tenemos?\n","print(\"-----------------------------PROCESADOR-------------------------\")\n","!cat /proc/cpuinfo  # que procesador tenemos?\n","print(\"-----------------------------GPU-------------------------\")\n","!nvidia-smi -L\n","!nvidia-smi\n","print(\"-------------------------------CUDA-----------------------------\")\n","!nvcc -V   # version de CUDA"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Tkeq57R55V-W"},"source":["###Activando la GPU\n","\n","---\n","Logra aumentar la velocidad de entrenamiento en un 600% en PLN (RNN) y un 1000% en visión por computadores (CNN)\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vieZASeN5KHd","executionInfo":{"status":"ok","timestamp":1650328059042,"user_tz":300,"elapsed":3608,"user":{"displayName":"Luis Fernando Castellanos Guarin","userId":"08966922054785833228"}},"outputId":"e724a0ff-0501-4fe9-f93c-49d7aaf273d6"},"source":["tf.device('/GPU:0')# OJO: esto es para que tensorflow utilice la GPU (aumenta la velocidad de entrenamiento en un 600%) "],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.eager.context._EagerDeviceContext at 0x7f5263441a00>"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","metadata":{"id":"JjQUc0jjQVLR"},"source":["\n","##P1. Descarga y preprocesado de los datos"]},{"cell_type":"code","metadata":{"id":"2d5wzxaBQW40"},"source":["fileUrl     ='https://raw.githubusercontent.com/luisFernandoCastellanosG/Machine_learning/master/2-Deep_Learning/PLN/Datasets/Panel_Txt_Files/cuento_los_tres_cerditos.txt'\n","fileContent = tf.keras.utils.get_file('Tres_cerditos.txt',fileUrl)\n","texto       = open(fileContent, 'rb').read().decode(encoding='utf-8')\n","raw_text    = texto.lower()\n","print(raw_text)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ikT-PEFlRc7y"},"source":["##P2. pasar el texto a números\n","\n","---\n","Sin importan el origen de la informacción (video, sonido, sensor, texto)...siempre debemos convertirlos en datos númericos.\n"]},{"cell_type":"code","metadata":{"id":"16uNdDlRRg4O","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650328068496,"user_tz":300,"elapsed":196,"user":{"displayName":"Luis Fernando Castellanos Guarin","userId":"08966922054785833228"}},"outputId":"f772b1dc-bacb-468a-a582-45a4b119c5b8"},"source":["chars = sorted(list(set(raw_text)))\n","char_to_int = dict((c, i) for i, c in enumerate(chars))\n","print(chars)\n","print(char_to_int)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['\\n', '\\r', ' ', '!', ',', '-', '.', ':', '?', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'y', 'z', '¡', '¿', 'á', 'é', 'í', 'ñ', 'ó']\n","{'\\n': 0, '\\r': 1, ' ': 2, '!': 3, ',': 4, '-': 5, '.': 6, ':': 7, '?': 8, 'a': 9, 'b': 10, 'c': 11, 'd': 12, 'e': 13, 'f': 14, 'g': 15, 'h': 16, 'i': 17, 'j': 18, 'l': 19, 'm': 20, 'n': 21, 'o': 22, 'p': 23, 'q': 24, 'r': 25, 's': 26, 't': 27, 'u': 28, 'v': 29, 'y': 30, 'z': 31, '¡': 32, '¿': 33, 'á': 34, 'é': 35, 'í': 36, 'ñ': 37, 'ó': 38}\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xU_SXe5JSXT0","executionInfo":{"status":"ok","timestamp":1649523946470,"user_tz":300,"elapsed":263,"user":{"displayName":"Luis Fernando Castellanos Guarin","userId":"08966922054785833228"}},"outputId":"69d387a4-fece-448d-b8bd-d67c250e7f3f"},"source":["n_chars = len(raw_text)\n","n_vocab = len(chars)\n","print(\"En total hay %d caracteres, y el diccionario tiene un tamaño de %d caracteres.\" % (n_chars, n_vocab))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["En total hay 2688 caracteres, y el diccionario tiene un tamaño de 39 caracteres.\n"]}]},{"cell_type":"markdown","metadata":{"id":"0ucpDS5lTgKB"},"source":["###P2.1 Dividimos el texto en secuencias:\n","---\n","Dividimos el texto en estas secuencias (adrede), convertimos los caracteres a números enteros usando nuestra tabla de búsqueda que preparamos anteriormente\n","\n"]},{"cell_type":"code","metadata":{"id":"QdJi9bHtTI46"},"source":["# preparar el conjunto de datos de los pares de entrada a salida codificados como enteros\n","seq_length = 50   #largo de las secciones de texto que usaremos para entrenar\n","dataX = []\n","dataY = []\n","for i in range(0, n_chars - seq_length, 1):\n","\tprint(\"Seq(\",i,\")=\",raw_text[i:i + seq_length],\"---->\",raw_text[i + seq_length])\n","\tseq_in \t= raw_text[i:i + seq_length]         \t\t\t\t\t#secuencia de entrada\n","\tseq_out = raw_text[i + seq_length]\t\t\t\t\t\t\t\t\t\t#siguiente letra despues de la secuencia (la que el va a aprender)\n","\tdataX.append([char_to_int[char] for char in seq_in])  # convertimos cada secuencia en numeros\n","\tdataY.append(char_to_int[seq_out])\n","n_patterns = len(dataX)\n","print (\"Se generaron \",format(n_patterns) ,\" secuencias texto de un tamaño de \",seq_length,\" caracteres\" )\n","print(\"Como se ven los datos de X convertidos a números\\n\")\n","print(dataX)\n","print(\"\\nComo se ven los datos de Y convertidos a números\\n\")\n","print(dataY)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZBlU-qNzVOO7"},"source":["##P3. preparar nuestros datos de entrenamiento\n","\n","---\n","\n","\n","1.   Primero debemos transformar la lista de secuencias de entrada en la forma [muestras, pasos de tiempo, características] esperada por una red LSTM.\n","2.   Luego debemos cambiar la escala de los números enteros al rango de 0 a 1 para que los patrones sean más fáciles de aprender mediante la red LSTM que utiliza la función de activación sigmoidea de forma predeterminada.\n","3.   por ultimo necesitamos convertir los patrones de salida (caracteres individuales convertidos en enteros) en una codificación one hot. Esto es para que podamos configurar la red para predecir la probabilidad de cada uno de los 54 caracteres diferentes en el vocabulario (una representación más fácil)\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"GbY1cgrHVSjC"},"source":["#transformar la lista X de secuencias de entrada en la forma [muestras (3091), pasos de tiempo, características]\n","X = np.reshape(dataX, (n_patterns, seq_length, 1))\n","# normalizar (cambiar la escala de los números enteros al rango de 0 a 1 )\n","X = X / float(n_vocab)\n","# convertir los patrones de salida (caracteres individuales convertidos en enteros) en una codificación one hot.\n","y = tf.keras.utils.to_categorical(dataY)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ekQyJUbvWvpZ"},"source":["##P4.Construcción del modelo RNN\n","\n","---\n","definimos nuestro modelo LSTM: \n","Aquí definimos una única capa LSTM oculta con 256 unidades de memoria. La red usa deserción con una probabilidad de 20. La capa de salida es una capa densa que usa la función de activación softmax para generar una predicción de probabilidad para cada uno de los 54 caracteres entre 0 y 1.\n"]},{"cell_type":"code","metadata":{"id":"8sjIOgf8XE_g"},"source":["# define the LSTM model\n","\n","model = tf.keras.models.Sequential()\n","model.add(tf.keras.layers.LSTM(256, input_shape=(X.shape[1], X.shape[2])))    #creamos una capa con 256 unidades de memoria\n","model.add(tf.keras.layers.Dropout(0.2))\n","model.add(tf.keras.layers.Dense(y.shape[1], activation='softmax'))            #Softmax convierte un vector de valores en una distribución de probabilidad para cada uno de los 39\n","                                                                              #Softmax se utiliza a menudo como la activación para la última capa de una red de clasificación\n","#utilizamos el algoritmo de optimización de ADAM para la velocidad\n","model.compile(loss='categorical_crossentropy', optimizer='adam')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4h3kjfw4XikQ"},"source":["###P4.1 Creando chekpoints\n","\n","---\n","\n","La red es lenta de entrenar (alrededor de 300 segundos por época) teniendo activa la GPU, ASí que crearemos CHECKPOINTS (puntos de control) para registrar todos los pesos de la red para archivar cada vez que se observe una mejora en la pérdida al final de la época. Usaremos el mejor conjunto de pesos (menor pérdida) para instanciar nuestro modelo generativo en la siguiente sección"]},{"cell_type":"code","metadata":{"id":"DcvIQPOHXzYL"},"source":["# definimos  una carpeta para guardar los checkpoint\n","filepath=\"/content/ckeckpointsRNN/weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n","checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n","callbacks_list = [checkpoint]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FczzMAAEX-6h"},"source":["###P4.2 entrenando"]},{"cell_type":"code","metadata":{"id":"HPSD1VSHYAJH"},"source":["history = model.fit(X, y, epochs=1000, batch_size=128, verbose=1,callbacks=callbacks_list)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WWfRY8pPYMYp"},"source":["##P5.Generando texto con una red LSTM\n","\n","\n","---\n","Vamos a cargar el ultimo CHECKPOINT de entrenamiento y con el haremos MAGIA!!!\n"]},{"cell_type":"code","metadata":{"id":"ngH34tw2YVB6"},"source":["filename = \"/content/ckeckpointsRNN/weights-improvement-976-0.0010.hdf5\"\n","model.load_weights(filename)\n","model.compile(loss='categorical_crossentropy', optimizer='adam')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CoKm0kDwY5XG"},"source":["###P5.1 mapeo inverso (números a letras)\n","creamos un mapeo inverso que podamos usar para convertir los números enteros nuevamente en caracteres para que podamos entender las predicciones"]},{"cell_type":"code","metadata":{"id":"pEuAaVxpY-ro"},"source":["int_to_char = dict((i, c) for i, c in enumerate(chars))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9R9T2vJ6ZU9t"},"source":["###P5.2 hacer predicciones\n","La forma más sencilla de utilizar el modelo Keras LSTM para hacer predicciones es comenzar primero con una secuencia semilla como entrada, generar el siguiente carácter y luego actualizar la secuencia semilla para agregar el carácter generado al final y recortar el primer carácter. Este proceso se repite mientras queramos predecir nuevos caracteres (por ejemplo, una secuencia de 1000 caracteres de longitud)."]},{"cell_type":"code","metadata":{"id":"YEJmnxm6ZenD"},"source":["# elige una semilla al azar\n","start = np.random.randint(0, len(dataX)-1)\n","pattern = dataX[start]\n","print (\"Semilla:\")\n","print (\"\\\"\" + \" \".join([int_to_char[value] for value in pattern])+\"\\\"\")\n","# generación de 10000 caracteres\n","for i in range(1000):\n","\tx = np.reshape(pattern, (1, len(pattern), 1))\n","\tx = x / float(n_vocab)\n","\tprediction = model.predict(x, verbose=0)\n","\tindex = np.argmax(prediction)\n","\tresult = int_to_char[index]\n","\tseq_in = [int_to_char[value] for value in pattern]\n","\tsys.stdout.write(result)\n","\tpattern.append(index)\n","\tpattern = pattern[1:len(pattern)]\n","print (\"\\nDone.\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TRh4YwjBVmvx"},"source":["##P6.Mejorando la red (una LSTM más grande)"]},{"cell_type":"code","metadata":{"id":"7z5w5CleVu6j"},"source":["model = tf.keras.models.Sequential()\n","model.add(tf.keras.layers.LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n","model.add(tf.keras.layers.Dropout(0.2))\n","model.add(tf.keras.layers.LSTM(256))                                                                #agregaremos una segunda capa. \n","model.add(tf.keras.layers.Dropout(0.2))\n","model.add(tf.keras.layers.Dense(y.shape[1], activation='softmax'))\n","\n","\n","model.compile(loss='categorical_crossentropy', optimizer='adam')\n","#cambiamos el nombre de archivo de los pesos con puntos de control para que \n","#podamos distinguir entre los pesos de esta red \n","filepath=\"/content/checkpointsRNNv2/weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zGLMqyQvWRRv"},"source":["###P6.1 mejoramos el entrenamiento\n","\n","---\n","aumentamos las epoch y disminuiremos el tamaño del lote de 128 a 64 para darle a la red más oportunidades de actualizarse y aprender.\n"]},{"cell_type":"code","metadata":{"id":"9kjWAw-JWVce"},"source":["#los tiempos de entrenamiento aumentaran al doble que en la versión anterior\n","model.fit(X, y, epochs=100, batch_size=32, callbacks=callbacks_list)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-TOM8C2_Y2To"},"source":["###P6.2 haciendo predicciones"]},{"cell_type":"code","metadata":{"id":"gFEPBYrxY5xq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1649525669674,"user_tz":300,"elapsed":42554,"user":{"displayName":"Luis Fernando Castellanos Guarin","userId":"08966922054785833228"}},"outputId":"aac55af1-f4dd-4930-d773-03ece574bfa6"},"source":["# elige una semilla al azar\n","start = np.random.randint(0, len(dataX)-1)\n","pattern = dataX[start]\n","print (\"Semilla:\")\n","print (\"\\\"\" + \" \".join([int_to_char[value] for value in pattern])+\"\\\"\")\n","# generación de caracteres\n","for i in range(1000):\n","\tx = np.reshape(pattern, (1, len(pattern), 1))\n","\tx = x / float(n_vocab)\n","\tprediction = model.predict(x, verbose=0)\n","\tindex = np.argmax(prediction)\n","\tresult = int_to_char[index]\n","\tseq_in = [int_to_char[value] for value in pattern]\n","\tsys.stdout.write(result)\n","\tpattern.append(index)\n","\tpattern = pattern[1:len(pattern)]\n","print (\"\\nDone.\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Semilla:\n","\"o n   a l   f u e g o   u n   g r a n   c a l d e r o   c o n   a g u a . \r \n"," \r \n"," a s í   c u a n d\"\n","o el lobo cayó por la chimenea el agua estaba hirviendo y se pegó tal quemazo que salió gritando de la casa y no volvió a comer cerditos en una larga temporada.al la casa de su hermano mayor.\n","\n","el lobo estaba cada vez más hambriento así que sopló y sopló con todas sus fuerzas, pero esta vez no tenía nada que hacer porque la casa no se movía ni siquiera un poco. dentro los cerditos le oyeron, y para darle su merecido llenaron la chimenea de leña y pusieron al fuego un gran caldero con agua.\n","\n","así cuando el lobo cayó por la chimenea el agua estaba hirviendo y se pegó tal quemazo que salió gritando de la casa y no volvió a comer cerditos en una larga temporada.al la casa de su hermano mayor.\n","\n","el lobo estaba cada vez más hambriento así que sopló y sopló con todas sus fuerzas, pero esta vez no tenía nada que hacer porque la casa no se movía ni siquiera un poco. dentro los cerditos le oyeron, y para darle su merecido llenaron la chimenea de leña y pusieron al fuego un gran caldero con ag\n","Done.\n"]}]},{"cell_type":"markdown","metadata":{"id":"Dz7aR7_eiYGg"},"source":["##P7. exportar modelo RNN"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tU7_ao0Ciibo","executionInfo":{"status":"ok","timestamp":1649525730674,"user_tz":300,"elapsed":2792,"user":{"displayName":"Luis Fernando Castellanos Guarin","userId":"08966922054785833228"}},"outputId":"45ce5908-6d95-402c-b75c-59bd2d1e288e"},"source":["!pip install h5py"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (3.1.0)\n","Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py) (1.5.2)\n","Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from h5py) (1.21.5)\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rbuFNARNisdA","executionInfo":{"status":"ok","timestamp":1649525743148,"user_tz":300,"elapsed":228,"user":{"displayName":"Luis Fernando Castellanos Guarin","userId":"08966922054785833228"}},"outputId":"c9c20e78-2aea-49f2-ab1d-f3d6a46729cd"},"source":["from keras.models import model_from_json\n","import os\n","# Serializamos el modelo en forma JSON\n","model_json = model.to_json()\n","with open(\"modelRNN_cuentos.json\", \"w\") as json_file:\n","    json_file.write(model_json)\n","# serialize weights to HDF5\n","model.save_weights(\"/content/modeloRNN_cuentosPesos.hdf5\")\n","model.save('modelRNN_cuentos_v_h5.h5')\n","print(\"modelo salvado en disco\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["modelo salvado en disco\n"]}]},{"cell_type":"markdown","metadata":{"id":"FshwyfFykB_4"},"source":["###P7.1 cargando un modelo"]},{"cell_type":"code","metadata":{"id":"X2BD6XFKkEmg"},"source":["# Recrea exactamente el mismo modelo solo desde el archivo\n","import keras\n","import numpy\n","new_model = keras.models.load_model('/content/modelRNN_cuentos_v_h5.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bjz0OYUYlO2B","executionInfo":{"status":"ok","timestamp":1649525834388,"user_tz":300,"elapsed":275,"user":{"displayName":"Luis Fernando Castellanos Guarin","userId":"08966922054785833228"}},"outputId":"6155cd84-0586-4267-e82f-9a59261b36ab"},"source":["chars = sorted(list(set(\"comiendo una manzana\")))\n","char_to_int = dict((c, i) for i, c in enumerate(chars))\n","n_chars = len(raw_text)\n","n_vocab = len(chars)\n","print(\"En total hay %d caracteres, y el diccionario tiene un tamaño de %d caracteres.\" % (n_chars, n_vocab))\n","pattern = dataX[5]\n","print(pattern)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["En total hay 2688 caracteres, y el diccionario tiene un tamaño de 11 caracteres.\n","[2, 28, 21, 9, 2, 29, 13, 31, 2, 27, 25, 13, 26, 2, 16, 13, 25, 20, 9, 21, 22, 26, 2, 11, 13, 25, 12, 17, 27, 22, 26, 2, 24, 28, 13, 2, 29, 17, 29, 36, 9, 21, 2, 13, 21, 2, 13, 19, 2, 10]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P5z_PSwlkoGg","executionInfo":{"status":"ok","timestamp":1649525896778,"user_tz":300,"elapsed":42017,"user":{"displayName":"Luis Fernando Castellanos Guarin","userId":"08966922054785833228"}},"outputId":"1f19a857-e7f5-4b7e-b3d2-247ee4354cd9"},"source":["start = numpy.random.randint(0, len(dataX)-1)\n","pattern = dataX[start]\n","print (\"Semilla:\")\n","print (\"\\\"\" + \" \".join([int_to_char[value] for value in pattern])+\"\\\"\")\n","# generación de caracteres\n","for i in range(1000):\n","\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n","\tx = x / float(n_vocab)\n","\tprediction = new_model.predict(x, verbose=0)\n","\tindex = numpy.argmax(prediction)\n","\tresult = int_to_char[index]\n","\tseq_in = [int_to_char[value] for value in pattern]\n","\tsys.stdout.write(result)\n","\tpattern.append(index)\n","\tpattern = pattern[1:len(pattern)]\n","print (\"\\nDone.\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Semilla:\n","\"h i m e n e a   d e   l e ñ a   y   p u s i e r o n   a l   f u e g o   u n   g r a n   c a l d e r\"\n","   co  q au q s su  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s pu  q s \n","Done.\n"]}]},{"cell_type":"markdown","metadata":{"id":"5X8cLamkWi52"},"source":["\n","\n","---\n","\n","\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"eHu5fIzX9Xlp"},"source":["#Ejemplo 2: generar texto de cuentos, usando Keras"]},{"cell_type":"markdown","metadata":{"id":"LqoUp3ewRpf9"},"source":["##Instalando librerias CUDA"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ul9CHmeeRwy1","executionInfo":{"status":"ok","timestamp":1637626145923,"user_tz":300,"elapsed":519,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"c7d136f3-e4ce-4e14-e8bc-a285eeb37eac"},"source":["#!pip list\n","!nvcc --version  #Version de CUDA en la maquina virtual"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2020 NVIDIA Corporation\n","Built on Mon_Oct_12_20:09:46_PDT_2020\n","Cuda compilation tools, release 11.1, V11.1.105\n","Build cuda_11.1.TC455_06.29190527_0\n"]}]},{"cell_type":"markdown","metadata":{"id":"O5WVmMwYt7Uk"},"source":["##P0. importar librerias"]},{"cell_type":"code","metadata":{"id":"CJdVpcLu7R7y"},"source":["#OPCIONAL \n","!pip install tensorflow-gpu #(opcional sobre para trabajar con EQUIPOS LOCALES..google colab ya la trae instalada)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tGa1tvf5t5r4","executionInfo":{"status":"ok","timestamp":1650428322361,"user_tz":300,"elapsed":202,"user":{"displayName":"Luis Fernando Castellanos Guarin","userId":"08966922054785833228"}}},"source":["import tensorflow as tf\n","import timeit               #para medir tiempos\n","import datetime\n","import numpy as np\n","import pandas as pd \n","import os\n","import time\n","import sys\n","#----librerias para normalización de textos\n","import re\n","from unicodedata import normalize"],"execution_count":64,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZYzaL8aex1Lz"},"source":["###P0.1 Uso de GPU para entrenar en tensorflow\n","\n","---\n","https://medium.com/analytics-vidhya/solution-to-tensorflow-2-not-using-gpu-119fb3e04daa\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DXlRSrBJrK9T","executionInfo":{"status":"ok","timestamp":1650428324698,"user_tz":300,"elapsed":486,"user":{"displayName":"Luis Fernando Castellanos Guarin","userId":"08966922054785833228"}},"outputId":"eafbb372-a5c7-431e-a759-346e8233d1a6"},"source":["print(\"Tensorflow Version: \", tf.__version__)\n","print(\"Dispositivos disponibles para entrenar: \", tf.config.list_physical_devices())\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  raise SystemError('GPU device not found')\n","print('Encontrada la GPU: {}'.format(device_name))"],"execution_count":65,"outputs":[{"output_type":"stream","name":"stdout","text":["Tensorflow Version:  2.8.0\n","Dispositivos disponibles para entrenar:  [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n","Encontrada la GPU: /device:GPU:0\n"]}]},{"cell_type":"markdown","metadata":{"id":"7fgEsGpyQE4E"},"source":["###P0.2 probando rendimiento de CPU vs GPU"]},{"cell_type":"code","metadata":{"id":"-8hkb1wlQKET"},"source":["def cpu():\n","  with tf.device('/cpu:0'):\n","    random_image_cpu = tf.random.normal((100, 100, 100, 3))\n","    net_cpu = tf.keras.layers.Conv2D(32, 7)(random_image_cpu)\n","    return tf.math.reduce_sum(net_cpu)\n","\n","def gpu():\n","  with tf.device('/device:GPU:0'):\n","    random_image_gpu = tf.random.normal((100, 100, 100, 3))\n","    net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\n","    return tf.math.reduce_sum(net_gpu)   "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NsqDzp_4Q0nV","executionInfo":{"status":"ok","timestamp":1650339199725,"user_tz":300,"elapsed":4410,"user":{"displayName":"Luis Fernando Castellanos Guarin","userId":"08966922054785833228"}},"outputId":"145aa897-2676-445a-888a-6a6bc995a1c2"},"source":["cpu()  #ejecutamos entrenamiento con CPU\n","gpu()  #ejecutamos entrenamiento con GPU\n","# Run the op several times.\n","print('TIEMPO (seg) para entrenar una red convolucional de 32x7x7x3 filtros sobre un randomico de 100x100x100x3 imagenes '\n","      '(batch x height x width x channel). suma de 10 epochs.')\n","print('CPU (s):')\n","cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n","print(cpu_time)\n","print('GPU (s):')\n","gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n","print(gpu_time)\n","print('GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["TIEMPO (seg) para entrenar una red convolucional de 32x7x7x3 filtros sobre un randomico de 100x100x100x3 imagenes (batch x height x width x channel). suma de 10 epochs.\n","CPU (s):\n","3.7553839289994357\n","GPU (s):\n","0.04974163599945314\n","GPU speedup over CPU: 75x\n"]}]},{"cell_type":"markdown","metadata":{"id":"kEoHXnuYS1lt"},"source":["###P0.3 Dejando activo la GPU"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E9E2ihO2rLjM","executionInfo":{"status":"ok","timestamp":1650428330118,"user_tz":300,"elapsed":318,"user":{"displayName":"Luis Fernando Castellanos Guarin","userId":"08966922054785833228"}},"outputId":"5ae51c01-95a7-47c4-f352-d887b5240794"},"source":["#tf.device('/gpu:0') #activando la CPU\n","tf.device('/device:GPU:0') #activando la GPU "],"execution_count":66,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.eager.context._EagerDeviceContext at 0x7fd167edb280>"]},"metadata":{},"execution_count":66}]},{"cell_type":"markdown","metadata":{"id":"9Ot0vNyP9jlQ"},"source":["##P0. Descarga y preprocesado de los datos"]},{"cell_type":"code","metadata":{"id":"6PETkDFl3Mff"},"source":["#urlText='https://raw.githubusercontent.com/luisFernandoCastellanosG/Machine_learning/master/2-Deep_Learning/PLN/Datasets/Panel_Txt_Files/LasMinasDelReySalomon.txt'\n","urlText='https://raw.githubusercontent.com/luisFernandoCastellanosG/Machine_learning/master/2-Deep_Learning/PLN/Datasets/Panel_Txt_Files/ElGatoConBotas.txt'\n","fileDL= tf.keras.utils.get_file('ElGatoConBotas.txt',urlText)\n","texto = open(fileDL, 'rb').read().decode(encoding='utf-8')\n","print(texto)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B5KuT5nIe2SO"},"source":["###P0.1 limpiar/normalizar el texto\n","\n","---\n","*   pasar todo a minusculas\n","*   convertir tildes a vocales sin tilde\n","*   eliminar caracteres especiales (*#!()%=\n","*   eliminar saltos de linea y tab (identación)"]},{"cell_type":"code","metadata":{"id":"-SbnxWwxfNnH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650428337396,"user_tz":300,"elapsed":225,"user":{"displayName":"Luis Fernando Castellanos Guarin","userId":"08966922054785833228"}},"outputId":"3543e5b9-6ad4-4afc-bfb1-fb83629504f0"},"source":["#pasa todo a minuscula\n","texto     = texto.lower()\n","#reemplazar tildes por letras similares sin tildes\n","transfor  = dict.fromkeys(map(ord, u'\\u0301\\u0308'), None)\n","texto     = normalize('NFKC', normalize('NFKD', texto).translate(transfor))\n","#quitar saltos de linea\n","texto      = texto.strip()\n","texto      = re.sub('\\r|\\n', ' ',texto)\n","#quitar espacios dobles\n","texto      = re.sub(' +', ' ', texto)\n","#quitando caracteres especiales\n","texto = re.sub(r\"[^a-zA-Z0-9]+\",\" \",texto)\n","print(texto)"],"execution_count":68,"outputs":[{"output_type":"stream","name":"stdout","text":["el gato con botas un molinero dejo como unica herencia a sus tres hijos su molino su burro y su gato el reparto fue bien simple ya que no se necesito llamar ni al abogado ni al notario pues habrian consumido por el cobro todo el pobre patrimonio el mayor recibio el molino el segundo se quedo con el burro y al menor le toco solo el gato este se lamentaba de su misera herencia mis hermanos decia podran ganarse la vida convenientemente trabajando juntos lo que es yo despues de comerme a mi gato y de hacerme un manguito con su piel me morire de hambre el gato que escuchaba estas palabras pero se hacia el desentendido le dijo en tono serio y pausado no debes afligirte mi se or solo tienes que proporcionarme una bolsa y un par de botas para andar por entre los matorrales y veras que tu herencia no es tan pobre como piensas aunque el amo del gato no abrigaba sobre esto grandes ilusiones aunque le habia visto dar tantas muestras de agilidad para cazar ratas y ratones colgarse de los pies esconderse en la harina para hacerse el muerto que no desespero de verse socorrido por el en su miseria cuando el gato tuvo lo que habia pedido se calzo las botas y echandose la bosa tras el cuello sujeto los cordones de esta con las dos patas delanteras y se dirigio a un campo donde habia muchos conejos se puso a recoger hierbas las metio en su saco y se tendio en el suelo como si estuviera muerto aguardo a que algun conejillo poco conocedor aun de las astucias de este mundo viniera a meter su hocico en la bolsa para comer lo que habia dentro apenas se habia recostado cuando vio un atolondrado conejillo que se metia en el saco y el maestro gato tirando los cordones lo encerro y lo mato sin misericordia muy ufano con su presa fue al palacio del rey y pidio hablar con el lo hicieron subir a los aposentos de su majestad donde al entrar hizo una gran reverencia ante el rey y le dijo he aqui majestad un conejo de campo que el se or marques de carabas era el nombre que invento para su amo me ha encargado obsequiarle de su parte dile a tu amo respondio el rey que le doy las gracias y que me agrada mucho en otra ocasion se oculto en un trigal dejando siempre su saco abierto y cuando en el entraron dos perdices tiro los cordones y las cazo fue en seguida a ofrendarlas al rey tal como habia hecho con el conejo de campo el rey recibio con agrado las dos perdices y ordeno que le diesen de beber el gato continuo durante dos o tres meses llevando al rey obsequios de parte de su amo un dia supo que el rey iria a pasear a orillas del rio con su hija la mas hermosa princesa del mundo y le dijo a su amo si sigues mi consejo tu fortuna estara asegurada tienes que ba arte en el rio en el sitio que te mostrare y en seguida yo hare lo demas el marques de carabas hizo lo que su gato le aconsejo sin saber de que serviria mientras se estaba ba ando el rey paso por ahi y el gato se puso a gritar con todas sus fuerzas socorro socorro el se or marques de carabas se esta ahogando al oir el grito el rey asomo la cabeza por la portezuela y reconociendo al gato que tantas veces le habia llevado obsequios ordeno a sus guardias que acudieran rapidamente a socorrer al marques de carabas mientras sacaban del rio al pobre marques el gato se acerco a la carroza y le dijo al rey que cuando su amo se estaba ba ando unos ladrones se llevaron sus ropas a pesar de que el al verlos grito con todas sus fuerzas auxilio ladrones auxilio el picaro del gato las habia escondido debajo de una enorme piedra el rey ordeno de inmediato a los encargados de su guardarropa que fuesen en busca de sus mas bellas vestiduras para el se or marques de carabas el rey le hizo mil atenciones y como el hermoso traje que le acababan de dar realzaba su figura ya que era apuesto y bien formado la hija del rey lo encontro de su agrado basto que el marques de carabas le dirigiera dos o tres miradas sumamente respetuosas y algo tiernas y ella quedo locamente enamorada el rey quiso que subiera a su carroza y lo acompa ara en el paseo el gato encantado al ver que su proyecto empezaba a resultar se adelanto y habiendo encontrado a unos campesinos que segaban un prado les dijo buenos segadores si no dicen al rey que el prado que estan segando es del marques de carabas los hare picadillo como carne de budin cuando el rey pregunto a los segadores de quien era ese prado que estaban segando es del se or marques de carabas dijeron a una sola voz puesto que la amenaza del gato los habia asustado tienes aqui una hermosa herencia dijo el rey al marques de carabas vera majestad es una tierra que no deja de producir con abundancia cada a o el maestro gato que iba siempre delante encontro a unos campesinos que cosechaban y les dijo buena gente que estan cosechando si no dicen que todos estos campos pertenecen al marques de carabas os hare picadillo como carne de budin el rey que paso momentos despues quiso saber a quien pertenecian los campos que veia son del se or marques de carabas contestaron los campesinos y el rey nuevamente se alegro con el marques el gato que iba delante de la carroza decia siempre lo mismo a todos cuantos encontraba y el rey estaba muy asombrado con las riquezas del se or marques de carabas el maestro gato llego finalmente ante un hermoso castillo cuyo due o era un ogro el mas rico que jamas se hubiera visto pues todas las tierras por donde habian pasado eran dependientes de este castillo el gato que tuvo la precaucion de informarse acerca de quien era este ogro y de lo que sabia hacer pidio hablar con el diciendo que no habia querido pasar tan cerca de su castillo sin tener el honor de hacerle la reverencia el ogro lo recibio en la forma mas cortes que puede hacerlo un ogro y lo invito a descansar me han asegurado dijo el gato que tienes el don de convertirte en cualquier clase de animal que puedes por ejemplo transformarte en leon en elefante es cierto respondio el ogro con brusquedad y para demostrartelo veras como me convierto en leon el gato se asusto tanto al ver a un leon delante de el que en un santiamen se trepo a las canaletas no sin pena ni riesgo a causa de las botas que nada servian para andar por las tejas algun rato despues viendo que el ogro habia recuperado su forma primitiva el gato bajo y confeso que habia tenido mucho miedo ademas me han asegurado dijo el gato pero no puedo creerlo que tambien tienes el poder de adquirir la forma del mas peque o animalillo por ejemplo que puedes convertirte en un raton en una rata te confieso que eso me parece imposible imposible repuso el ogro ya veras y al mismo tiempo en que dijo eso se transformo en una rata que se puso a correr por el piso apenas la vio el gato se echo encima de ella y se la comio entretanto el rey que al pasar vio el hermoso castillo del ogro quiso entrar el gato al oir el ruido del carruaje que atravesaba el puente levadizo corrio y le dijo al rey vuestra majestad sea bienvenida al castillo del se or marques de carabas como se or marques exclamo el rey este castillo tambien os pertenece nada hay mas bello que este patio y todos estos edificios que lo rodean veamos el interior por favor el marques ofrecio la mano a la joven princesa y siguiendo al rey que iba primero entraron a una gran sala donde encontraron una magnifica colacion que el ogro habia mandado preparar para sus amigos que vendrian a verlo ese mismo dia los cuales no se habian atrevido a entrar sabiendo que el rey estaba alli el rey encantado con las buenas cualidades del se or marques de carabas al igual que su hija que ya estaba loca de amor viendo los valiosos bienes que poseia le dijo despues de haber bebido cinco o seis copas solo dependera de ti se or marques que seas mi yerno el marques haciendo grandes reverencias acepto el honor que le hacia el rey y ese mismo dia se caso con la princesa el gato se convirtio en gran se or y ya no corrio tras las ratas sino para divertirse \n"]}]},{"cell_type":"markdown","metadata":{"id":"i-Qr24Chypjd"},"source":["##P1. entendiendo el texto"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TpxHpVkcys57","executionInfo":{"status":"ok","timestamp":1650428340279,"user_tz":300,"elapsed":282,"user":{"displayName":"Luis Fernando Castellanos Guarin","userId":"08966922054785833228"}},"outputId":"1dd2a0bd-59f4-4284-8e23-6de07e915bcb"},"source":["print('el texto tiene longitud de:{} caracteres'. format(len(texto)))\n","vocab = sorted(set(texto))\n","print('el texto esta compuesto de estos :{} caracteres'. format(len(vocab)))\n","print(vocab)"],"execution_count":69,"outputs":[{"output_type":"stream","name":"stdout","text":["el texto tiene longitud de:7884 caracteres\n","el texto esta compuesto de estos :25 caracteres\n","[' ', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'x', 'y', 'z']\n"]}]},{"cell_type":"markdown","metadata":{"id":"xPUI-QIDy7Mm"},"source":["##P2. pasar el texto a números\n","\n","---\n","Las redes neuronales solo procesan valores numéricos, no letras, por tanto tenemos que traducir los caracteres a representación numérica. Para ello crearemos dos “tablas de traducción”: una de caracteres a números y otra de números a caracteres"]},{"cell_type":"code","metadata":{"id":"YUZb1tLVzIke"},"source":["char2idx = {u:i for i, u in enumerate(vocab)} # asignamos un número a cada vocablo\n","idx2char = np.array(vocab)\n","#-----------revisando las conversiones\n","\n","#for char,_ in zip(char2idx, range(len(vocab))):\n","    #print(' {:4s}: {:3d},'.format(repr(char),char2idx[char]))\n","\n","#pasamos todo el texto a números\n","texto_como_entero= np.array([char2idx[c] for c in texto])\n","print('texto: {}'.format(repr(texto[:100])))\n","print('{}'.format(repr(texto_como_entero[:100])))"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(idx2char)   # vocablos\n","print(char2idx)   # numero de vocablos"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"se1apwoTwWjG","executionInfo":{"status":"ok","timestamp":1650418312506,"user_tz":300,"elapsed":231,"user":{"displayName":"Luis Fernando Castellanos Guarin","userId":"08966922054785833228"}},"outputId":"8de4f677-23bd-4892-ea00-fb0675a8aa9e"},"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["[' ' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'l' 'm' 'n' 'o' 'p' 'q' 'r'\n"," 's' 't' 'u' 'v' 'x' 'y' 'z']\n","{' ': 0, 'a': 1, 'b': 2, 'c': 3, 'd': 4, 'e': 5, 'f': 6, 'g': 7, 'h': 8, 'i': 9, 'j': 10, 'l': 11, 'm': 12, 'n': 13, 'o': 14, 'p': 15, 'q': 16, 'r': 17, 's': 18, 't': 19, 'u': 20, 'v': 21, 'x': 22, 'y': 23, 'z': 24}\n"]}]},{"cell_type":"markdown","metadata":{"id":"gI9Zv9zVfe7V"},"source":["###P2.1 exportar vocablos y matriz de numerica\n","\n","---\n","\n","exporta en un CSV para usarlo cuando se cargue el modelo en otra instancia"]},{"cell_type":"code","metadata":{"id":"Zl6mkWE6u2iH","executionInfo":{"status":"ok","timestamp":1650428351812,"user_tz":300,"elapsed":184,"user":{"displayName":"Luis Fernando Castellanos Guarin","userId":"08966922054785833228"}}},"source":["rows=[]\n","columns=['num','vocab']\n","for i, voc in enumerate(vocab):\n","  #print(i,'-->', voc)\n","  rows.append([i,voc])\n","df= pd.DataFrame(columns=['num','vocab'],data=rows)\n","df.head(10)\n","df.to_csv('data_vocab.csv',index=False)"],"execution_count":71,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kIT7JzLG4LIs"},"source":["##P3. preparar los datos para ser usados en la RNN"]},{"cell_type":"code","metadata":{"id":"ky_cT7xN4OiO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650428352823,"user_tz":300,"elapsed":230,"user":{"displayName":"Luis Fernando Castellanos Guarin","userId":"08966922054785833228"}},"outputId":"0db3830f-3bba-40f8-ffba-9a1c65a04a04"},"source":["char_dataset= tf.data.Dataset.from_tensor_slices(texto_como_entero)\n","#cantidad de secuencia de caracteres\n","secu_length=50\n","#creamos secuencias de maximo 100 caractereres\n","secuencias= char_dataset.batch(secu_length+1, drop_remainder=True)\n","for item in secuencias.take(10):\n","  print(repr(''.join(idx2char[item.numpy()])))"],"execution_count":72,"outputs":[{"output_type":"stream","name":"stdout","text":["'el gato con botas un molinero dejo como unica heren'\n","'cia a sus tres hijos su molino su burro y su gato e'\n","'l reparto fue bien simple ya que no se necesito lla'\n","'mar ni al abogado ni al notario pues habrian consum'\n","'ido por el cobro todo el pobre patrimonio el mayor '\n","'recibio el molino el segundo se quedo con el burro '\n","'y al menor le toco solo el gato este se lamentaba d'\n","'e su misera herencia mis hermanos decia podran gana'\n","'rse la vida convenientemente trabajando juntos lo q'\n","'ue es yo despues de comerme a mi gato y de hacerme '\n"]}]},{"cell_type":"markdown","metadata":{"id":"Xz5cEwf6_bpv"},"source":["###P3.1 separar los datos en agrupamientos (batches)"]},{"cell_type":"code","metadata":{"id":"-l6Tobzz7hww","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650428356684,"user_tz":300,"elapsed":177,"user":{"displayName":"Luis Fernando Castellanos Guarin","userId":"08966922054785833228"}},"outputId":"cd29c592-6ffa-4db9-d974-288fc31260d9"},"source":["#funcion para obtener el conjunto de datos de trainning\n","def split_input_target(chunk):\n","  input_text = chunk[:-1]\n","  target_text= chunk[1:]\n","  return input_text, target_text\n","\n","dataset  = secuencias.map(split_input_target)\n","#el dataset contiene un conjunto de parejas de secuencia de texto\n","#(con la representación numérica de los caracteres), donde el \n","#primer componente de la pareja contiene un paquete con una secuencia \n","#de 100 caracteres del texto original y la segunda su correspondiente salida, \n","#también de 100 caracteres. )\n","for input_example, target_example in dataset.take(1):\n","  print('input data: ', repr(''.join(idx2char[input_example.numpy()])))\n","  print('Target data: ', repr(''.join(idx2char[target_example.numpy()])))"],"execution_count":73,"outputs":[{"output_type":"stream","name":"stdout","text":["input data:  'el gato con botas un molinero dejo como unica here'\n","Target data:  'l gato con botas un molinero dejo como unica heren'\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8UM54Sfe9x80","executionInfo":{"status":"ok","timestamp":1650428359401,"user_tz":300,"elapsed":192,"user":{"displayName":"Luis Fernando Castellanos Guarin","userId":"08966922054785833228"}},"outputId":"8de5309d-beef-40ca-ee92-d2d7738abce4"},"source":["#imprimimos el tensor del dataset\n","print(dataset)\n","#Hyper-Parametros para entrenamiento  de una rede neuronal \n","#   -los datos se agrupan en batch\n","BATCH_SIZE= 64\n","#    -Tamaño de memoria disponible \n","BUFFER_SIZE=10000\n","dataset= dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n","print (dataset)\n","#En el tensor dataset disponemos los datos de entrenamiento\n","#con agrupamienttos (batches) compuestos de 64 parejas de secuencias \n","#de 100 integers de 64 bits que representan el carácter correspondiente \n","#en el vocabulario."],"execution_count":74,"outputs":[{"output_type":"stream","name":"stdout","text":["<MapDataset element_spec=(TensorSpec(shape=(50,), dtype=tf.int64, name=None), TensorSpec(shape=(50,), dtype=tf.int64, name=None))>\n","<BatchDataset element_spec=(TensorSpec(shape=(64, 50), dtype=tf.int64, name=None), TensorSpec(shape=(64, 50), dtype=tf.int64, name=None))>\n"]}]},{"cell_type":"markdown","metadata":{"id":"kDFFru4s_jon"},"source":["##P4.Construcción del modelo RNN\n","\n","---\n","Para construir el modelo usaremos tf.keras.Sequential. Usaremos una versión mínima de RNN, que contenga solo una capa LSTM y 3 capas.\n","![rnn_layers.png](data:image/png;base64,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)"]},{"cell_type":"code","metadata":{"id":"Ox_5lKZh_qUN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650429743093,"user_tz":300,"elapsed":1188,"user":{"displayName":"Luis Fernando Castellanos Guarin","userId":"08966922054785833228"}},"outputId":"14dfb728-fcac-4346-871a-055efff0111f"},"source":["#como es un problema de clasificación estándar \n","#para el que debemos definir la función de Lossy el optimizador.\n","def lossPLN(labels, logits):\n","  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n","\n","def create_model(vocab_size, embedding_dim, rnn_units, batch_size):\n","  #creando el modelo cuya entrada es la cantidad de vocablos que se encontraron en el texto\n","  model = tf.keras.Sequential([\n","    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n","                              batch_input_shape=[batch_size, None]),\n","    tf.keras.layers.LSTM(rnn_units,\n","                         return_sequences=True,\n","                         stateful=True,\n","                         recurrent_initializer='glorot_uniform'),\n","    tf.keras.layers.Dense(vocab_size)                               \n","  ])\n","  #En cuanto al optimizador usaremos tf.keras.optimizers.Adam \n","  #usaremos para el calculo de perdida SparseCategoricalCrossentropy con el parametro from_logits=True\n","  #este atributo informa a la función de pérdida que los valores de salida generados por el modelo no están normalizados, \n","  #es decir, logits. En otras palabras, no se les ha aplicado la función softmax para producir una distribución de probabilidad.\n","  model.compile(optimizer='adam',\n","              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n","              metrics=['accuracy'])\n","  return model\n","vocab_size= len(vocab)\n","#dimensiones de los vectores que tendrá la capa.\n","embedding_dim= 256\n","#cantidad de neuronas\n","rnn_units=1024\n","#creamos nuestra red neuronal RNN\n","model=create_model(vocab_size   =vocab_size,\n","                  embedding_dim =embedding_dim,\n","                  rnn_units     =rnn_units,\n","                  batch_size    =BATCH_SIZE)\n","#summary()para visualizar la estructura del modelo\n","model.summary()\n","#resultados=  -La capa LSTM consta más de 5 millones de parametros)"],"execution_count":105,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_24\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_24 (Embedding)    (64, None, 256)           6400      \n","                                                                 \n"," lstm_24 (LSTM)              (64, None, 1024)          5246976   \n","                                                                 \n"," dense_24 (Dense)            (64, None, 25)            25625     \n","                                                                 \n","=================================================================\n","Total params: 5,279,001\n","Trainable params: 5,279,001\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","metadata":{"id":"dPnll1ubFvZO"},"source":["###P4.1 Creando chekpoints\n","\n","---\n","una técnica de tolerancia de fallos para procesos cuyo tiempo de ejecución es muy largo. La idea es guardar una instantánea del estado del sistema periódicamente para recuperar desde ese punto la ejecución en caso de fallo del sistema.\n","\n","---\n","los crearemos en google drive para mejorar la capacidad de reentrenamiento de la red\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L24WhqeauMWk","executionInfo":{"status":"ok","timestamp":1650429754162,"user_tz":300,"elapsed":1482,"user":{"displayName":"Luis Fernando Castellanos Guarin","userId":"08966922054785833228"}},"outputId":"4134cf7e-6e4f-4ef4-b1f8-7c2c56e924f7"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":106,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"id":"XbeXxiWLF5hN","executionInfo":{"status":"ok","timestamp":1650429755296,"user_tz":300,"elapsed":200,"user":{"displayName":"Luis Fernando Castellanos Guarin","userId":"08966922054785833228"}}},"source":["checkpoint_dir='/content/gdrive/MyDrive/IA/PLN/ckeckpoint_RNN'\n","checkpoint_prefix= os.path.join(checkpoint_dir,\"cp_{epoch:04d}.ckpt\")\n","\n","cp_callback=tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix,\n","                                               monitor='loss',\n","                                               verbose=1,\n","                                               save_weights_only=True,\n","                                               save_best_only=True,\n","                                               mode='auto')\n"],"execution_count":107,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"trmMLMjxGjuP"},"source":["###P4.2 entrenando"]},{"cell_type":"markdown","metadata":{"id":"LPXvQuLrQEAF"},"source":["####P4.2a entrenando para usar chekpoints\n","\n","\n","---\n","\n","*   https://keras.io/api/callbacks/model_checkpoint/\n","*   https://towardsdatascience.com/checkpointing-deep-learning-models-in-keras-a652570b8de6"]},{"cell_type":"code","metadata":{"id":"9l5cnXgLQI7H","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650429987807,"user_tz":300,"elapsed":46482,"user":{"displayName":"Luis Fernando Castellanos Guarin","userId":"08966922054785833228"}},"outputId":"0e027354-12cd-41a3-dbe2-a11a6d66c44f"},"source":["EPOCHS=300\n","history=model.fit(dataset, \n","                  epochs=EPOCHS, \n","                  verbose=1,\n","                  callbacks=[cp_callback])"],"execution_count":108,"outputs":[{"output_type":"stream","name":"stdout","text":["2/2 [==============================] - ETA: 0s - loss: 0.1441 - accuracy: 0.9620\n","Epoch 200: loss did not improve from 0.14048\n","2/2 [==============================] - 0s 134ms/step - loss: 0.1441 - accuracy: 0.9620\n","Epoch 201/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1470 - accuracy: 0.9614\n","Epoch 201: loss did not improve from 0.14048\n","2/2 [==============================] - 0s 135ms/step - loss: 0.1470 - accuracy: 0.9614\n","Epoch 202/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1489 - accuracy: 0.9623\n","Epoch 202: loss did not improve from 0.14048\n","2/2 [==============================] - 0s 132ms/step - loss: 0.1489 - accuracy: 0.9623\n","Epoch 203/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1461 - accuracy: 0.9631\n","Epoch 203: loss did not improve from 0.14048\n","2/2 [==============================] - 0s 133ms/step - loss: 0.1461 - accuracy: 0.9631\n","Epoch 204/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1382 - accuracy: 0.9647\n","Epoch 204: loss improved from 0.14048 to 0.13816, saving model to /content/gdrive/MyDrive/IA/PLN/ckeckpoint_RNN/cp_0204.ckpt\n","2/2 [==============================] - 1s 376ms/step - loss: 0.1382 - accuracy: 0.9647\n","Epoch 205/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1398 - accuracy: 0.9627\n","Epoch 205: loss did not improve from 0.13816\n","2/2 [==============================] - 0s 139ms/step - loss: 0.1398 - accuracy: 0.9627\n","Epoch 206/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1420 - accuracy: 0.9650\n","Epoch 206: loss did not improve from 0.13816\n","2/2 [==============================] - 0s 138ms/step - loss: 0.1420 - accuracy: 0.9650\n","Epoch 207/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1391 - accuracy: 0.9625\n","Epoch 207: loss did not improve from 0.13816\n","2/2 [==============================] - 0s 135ms/step - loss: 0.1391 - accuracy: 0.9625\n","Epoch 208/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1407 - accuracy: 0.9634\n","Epoch 208: loss did not improve from 0.13816\n","2/2 [==============================] - 0s 135ms/step - loss: 0.1407 - accuracy: 0.9634\n","Epoch 209/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1317 - accuracy: 0.9642\n","Epoch 209: loss improved from 0.13816 to 0.13169, saving model to /content/gdrive/MyDrive/IA/PLN/ckeckpoint_RNN/cp_0209.ckpt\n","2/2 [==============================] - 1s 977ms/step - loss: 0.1317 - accuracy: 0.9642\n","Epoch 210/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1364 - accuracy: 0.9641\n","Epoch 210: loss did not improve from 0.13169\n","2/2 [==============================] - 0s 139ms/step - loss: 0.1364 - accuracy: 0.9641\n","Epoch 211/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1311 - accuracy: 0.9638\n","Epoch 211: loss improved from 0.13169 to 0.13109, saving model to /content/gdrive/MyDrive/IA/PLN/ckeckpoint_RNN/cp_0211.ckpt\n","2/2 [==============================] - 1s 381ms/step - loss: 0.1311 - accuracy: 0.9638\n","Epoch 212/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1375 - accuracy: 0.9623\n","Epoch 212: loss did not improve from 0.13109\n","2/2 [==============================] - 0s 134ms/step - loss: 0.1375 - accuracy: 0.9623\n","Epoch 213/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1409 - accuracy: 0.9623\n","Epoch 213: loss did not improve from 0.13109\n","2/2 [==============================] - 0s 136ms/step - loss: 0.1409 - accuracy: 0.9623\n","Epoch 214/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1277 - accuracy: 0.9663\n","Epoch 214: loss improved from 0.13109 to 0.12771, saving model to /content/gdrive/MyDrive/IA/PLN/ckeckpoint_RNN/cp_0214.ckpt\n","2/2 [==============================] - 1s 563ms/step - loss: 0.1277 - accuracy: 0.9663\n","Epoch 215/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1373 - accuracy: 0.9645\n","Epoch 215: loss did not improve from 0.12771\n","2/2 [==============================] - 0s 134ms/step - loss: 0.1373 - accuracy: 0.9645\n","Epoch 216/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1353 - accuracy: 0.9644\n","Epoch 216: loss did not improve from 0.12771\n","2/2 [==============================] - 0s 142ms/step - loss: 0.1353 - accuracy: 0.9644\n","Epoch 217/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1346 - accuracy: 0.9645\n","Epoch 217: loss did not improve from 0.12771\n","2/2 [==============================] - 0s 132ms/step - loss: 0.1346 - accuracy: 0.9645\n","Epoch 218/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1279 - accuracy: 0.9648\n","Epoch 218: loss did not improve from 0.12771\n","2/2 [==============================] - 0s 132ms/step - loss: 0.1279 - accuracy: 0.9648\n","Epoch 219/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1243 - accuracy: 0.9658\n","Epoch 219: loss improved from 0.12771 to 0.12432, saving model to /content/gdrive/MyDrive/IA/PLN/ckeckpoint_RNN/cp_0219.ckpt\n","2/2 [==============================] - 1s 461ms/step - loss: 0.1243 - accuracy: 0.9658\n","Epoch 220/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1373 - accuracy: 0.9638\n","Epoch 220: loss did not improve from 0.12432\n","2/2 [==============================] - 0s 138ms/step - loss: 0.1373 - accuracy: 0.9638\n","Epoch 221/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1285 - accuracy: 0.9652\n","Epoch 221: loss did not improve from 0.12432\n","2/2 [==============================] - 0s 128ms/step - loss: 0.1285 - accuracy: 0.9652\n","Epoch 222/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1367 - accuracy: 0.9663\n","Epoch 222: loss did not improve from 0.12432\n","2/2 [==============================] - 0s 128ms/step - loss: 0.1367 - accuracy: 0.9663\n","Epoch 223/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1202 - accuracy: 0.9655\n","Epoch 223: loss improved from 0.12432 to 0.12019, saving model to /content/gdrive/MyDrive/IA/PLN/ckeckpoint_RNN/cp_0223.ckpt\n","2/2 [==============================] - 1s 1s/step - loss: 0.1202 - accuracy: 0.9655\n","Epoch 224/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1206 - accuracy: 0.9656\n","Epoch 224: loss did not improve from 0.12019\n","2/2 [==============================] - 0s 140ms/step - loss: 0.1206 - accuracy: 0.9656\n","Epoch 225/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1303 - accuracy: 0.9638\n","Epoch 225: loss did not improve from 0.12019\n","2/2 [==============================] - 0s 135ms/step - loss: 0.1303 - accuracy: 0.9638\n","Epoch 226/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1338 - accuracy: 0.9650\n","Epoch 226: loss did not improve from 0.12019\n","2/2 [==============================] - 0s 144ms/step - loss: 0.1338 - accuracy: 0.9650\n","Epoch 227/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1289 - accuracy: 0.9655\n","Epoch 227: loss did not improve from 0.12019\n","2/2 [==============================] - 0s 138ms/step - loss: 0.1289 - accuracy: 0.9655\n","Epoch 228/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1280 - accuracy: 0.9658\n","Epoch 228: loss did not improve from 0.12019\n","2/2 [==============================] - 0s 139ms/step - loss: 0.1280 - accuracy: 0.9658\n","Epoch 229/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1243 - accuracy: 0.9673\n","Epoch 229: loss did not improve from 0.12019\n","2/2 [==============================] - 0s 138ms/step - loss: 0.1243 - accuracy: 0.9673\n","Epoch 230/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1253 - accuracy: 0.9669\n","Epoch 230: loss did not improve from 0.12019\n","2/2 [==============================] - 0s 129ms/step - loss: 0.1253 - accuracy: 0.9669\n","Epoch 231/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1289 - accuracy: 0.9678\n","Epoch 231: loss did not improve from 0.12019\n","2/2 [==============================] - 0s 141ms/step - loss: 0.1289 - accuracy: 0.9678\n","Epoch 232/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1226 - accuracy: 0.9670\n","Epoch 232: loss did not improve from 0.12019\n","2/2 [==============================] - 0s 143ms/step - loss: 0.1226 - accuracy: 0.9670\n","Epoch 233/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1194 - accuracy: 0.9669\n","Epoch 233: loss improved from 0.12019 to 0.11942, saving model to /content/gdrive/MyDrive/IA/PLN/ckeckpoint_RNN/cp_0233.ckpt\n","2/2 [==============================] - 1s 448ms/step - loss: 0.1194 - accuracy: 0.9669\n","Epoch 234/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1200 - accuracy: 0.9655\n","Epoch 234: loss did not improve from 0.11942\n","2/2 [==============================] - 0s 134ms/step - loss: 0.1200 - accuracy: 0.9655\n","Epoch 235/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1215 - accuracy: 0.9661\n","Epoch 235: loss did not improve from 0.11942\n","2/2 [==============================] - 0s 143ms/step - loss: 0.1215 - accuracy: 0.9661\n","Epoch 236/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1178 - accuracy: 0.9658\n","Epoch 236: loss improved from 0.11942 to 0.11779, saving model to /content/gdrive/MyDrive/IA/PLN/ckeckpoint_RNN/cp_0236.ckpt\n","2/2 [==============================] - 1s 473ms/step - loss: 0.1178 - accuracy: 0.9658\n","Epoch 237/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1218 - accuracy: 0.9669\n","Epoch 237: loss did not improve from 0.11779\n","2/2 [==============================] - 0s 144ms/step - loss: 0.1218 - accuracy: 0.9669\n","Epoch 238/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1283 - accuracy: 0.9672\n","Epoch 238: loss did not improve from 0.11779\n","2/2 [==============================] - 0s 128ms/step - loss: 0.1283 - accuracy: 0.9672\n","Epoch 239/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1193 - accuracy: 0.9675\n","Epoch 239: loss did not improve from 0.11779\n","2/2 [==============================] - 0s 145ms/step - loss: 0.1193 - accuracy: 0.9675\n","Epoch 240/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1254 - accuracy: 0.9666\n","Epoch 240: loss did not improve from 0.11779\n","2/2 [==============================] - 0s 135ms/step - loss: 0.1254 - accuracy: 0.9666\n","Epoch 241/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1153 - accuracy: 0.9683\n","Epoch 241: loss improved from 0.11779 to 0.11534, saving model to /content/gdrive/MyDrive/IA/PLN/ckeckpoint_RNN/cp_0241.ckpt\n","2/2 [==============================] - 1s 384ms/step - loss: 0.1153 - accuracy: 0.9683\n","Epoch 242/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1160 - accuracy: 0.9670\n","Epoch 242: loss did not improve from 0.11534\n","2/2 [==============================] - 0s 136ms/step - loss: 0.1160 - accuracy: 0.9670\n","Epoch 243/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1108 - accuracy: 0.9689\n","Epoch 243: loss improved from 0.11534 to 0.11084, saving model to /content/gdrive/MyDrive/IA/PLN/ckeckpoint_RNN/cp_0243.ckpt\n","2/2 [==============================] - 1s 964ms/step - loss: 0.1108 - accuracy: 0.9689\n","Epoch 244/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1172 - accuracy: 0.9672\n","Epoch 244: loss did not improve from 0.11084\n","2/2 [==============================] - 0s 129ms/step - loss: 0.1172 - accuracy: 0.9672\n","Epoch 245/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1162 - accuracy: 0.9672\n","Epoch 245: loss did not improve from 0.11084\n","2/2 [==============================] - 0s 128ms/step - loss: 0.1162 - accuracy: 0.9672\n","Epoch 246/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1115 - accuracy: 0.9689\n","Epoch 246: loss did not improve from 0.11084\n","2/2 [==============================] - 0s 139ms/step - loss: 0.1115 - accuracy: 0.9689\n","Epoch 247/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1114 - accuracy: 0.9680\n","Epoch 247: loss did not improve from 0.11084\n","2/2 [==============================] - 0s 135ms/step - loss: 0.1114 - accuracy: 0.9680\n","Epoch 248/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1227 - accuracy: 0.9659\n","Epoch 248: loss did not improve from 0.11084\n","2/2 [==============================] - 0s 129ms/step - loss: 0.1227 - accuracy: 0.9659\n","Epoch 249/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1175 - accuracy: 0.9659\n","Epoch 249: loss did not improve from 0.11084\n","2/2 [==============================] - 0s 136ms/step - loss: 0.1175 - accuracy: 0.9659\n","Epoch 250/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1219 - accuracy: 0.9672\n","Epoch 250: loss did not improve from 0.11084\n","2/2 [==============================] - 0s 140ms/step - loss: 0.1219 - accuracy: 0.9672\n","Epoch 251/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1080 - accuracy: 0.9691\n","Epoch 251: loss improved from 0.11084 to 0.10795, saving model to /content/gdrive/MyDrive/IA/PLN/ckeckpoint_RNN/cp_0251.ckpt\n","2/2 [==============================] - 1s 383ms/step - loss: 0.1080 - accuracy: 0.9691\n","Epoch 252/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1108 - accuracy: 0.9692\n","Epoch 252: loss did not improve from 0.10795\n","2/2 [==============================] - 0s 141ms/step - loss: 0.1108 - accuracy: 0.9692\n","Epoch 253/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1139 - accuracy: 0.9673\n","Epoch 253: loss did not improve from 0.10795\n","2/2 [==============================] - 0s 138ms/step - loss: 0.1139 - accuracy: 0.9673\n","Epoch 254/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1048 - accuracy: 0.9688\n","Epoch 254: loss improved from 0.10795 to 0.10478, saving model to /content/gdrive/MyDrive/IA/PLN/ckeckpoint_RNN/cp_0254.ckpt\n","2/2 [==============================] - 1s 625ms/step - loss: 0.1048 - accuracy: 0.9688\n","Epoch 255/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1160 - accuracy: 0.9670\n","Epoch 255: loss did not improve from 0.10478\n","2/2 [==============================] - 0s 144ms/step - loss: 0.1160 - accuracy: 0.9670\n","Epoch 256/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1133 - accuracy: 0.9673\n","Epoch 256: loss did not improve from 0.10478\n","2/2 [==============================] - 0s 139ms/step - loss: 0.1133 - accuracy: 0.9673\n","Epoch 257/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1106 - accuracy: 0.9684\n","Epoch 257: loss did not improve from 0.10478\n","2/2 [==============================] - 0s 137ms/step - loss: 0.1106 - accuracy: 0.9684\n","Epoch 258/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1145 - accuracy: 0.9678\n","Epoch 258: loss did not improve from 0.10478\n","2/2 [==============================] - 0s 134ms/step - loss: 0.1145 - accuracy: 0.9678\n","Epoch 259/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1132 - accuracy: 0.9689\n","Epoch 259: loss did not improve from 0.10478\n","2/2 [==============================] - 0s 134ms/step - loss: 0.1132 - accuracy: 0.9689\n","Epoch 260/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1163 - accuracy: 0.9666\n","Epoch 260: loss did not improve from 0.10478\n","2/2 [==============================] - 0s 133ms/step - loss: 0.1163 - accuracy: 0.9666\n","Epoch 261/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1094 - accuracy: 0.9684\n","Epoch 261: loss did not improve from 0.10478\n","2/2 [==============================] - 0s 136ms/step - loss: 0.1094 - accuracy: 0.9684\n","Epoch 262/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1094 - accuracy: 0.9692\n","Epoch 262: loss did not improve from 0.10478\n","2/2 [==============================] - 0s 138ms/step - loss: 0.1094 - accuracy: 0.9692\n","Epoch 263/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1068 - accuracy: 0.9695\n","Epoch 263: loss did not improve from 0.10478\n","2/2 [==============================] - 0s 129ms/step - loss: 0.1068 - accuracy: 0.9695\n","Epoch 264/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1093 - accuracy: 0.9689\n","Epoch 264: loss did not improve from 0.10478\n","2/2 [==============================] - 0s 135ms/step - loss: 0.1093 - accuracy: 0.9689\n","Epoch 265/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1097 - accuracy: 0.9698\n","Epoch 265: loss did not improve from 0.10478\n","2/2 [==============================] - 0s 147ms/step - loss: 0.1097 - accuracy: 0.9698\n","Epoch 266/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1023 - accuracy: 0.9700\n","Epoch 266: loss improved from 0.10478 to 0.10229, saving model to /content/gdrive/MyDrive/IA/PLN/ckeckpoint_RNN/cp_0266.ckpt\n","2/2 [==============================] - 1s 506ms/step - loss: 0.1023 - accuracy: 0.9700\n","Epoch 267/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1077 - accuracy: 0.9705\n","Epoch 267: loss did not improve from 0.10229\n","2/2 [==============================] - 0s 153ms/step - loss: 0.1077 - accuracy: 0.9705\n","Epoch 268/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1089 - accuracy: 0.9681\n","Epoch 268: loss did not improve from 0.10229\n","2/2 [==============================] - 0s 158ms/step - loss: 0.1089 - accuracy: 0.9681\n","Epoch 269/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1068 - accuracy: 0.9692\n","Epoch 269: loss did not improve from 0.10229\n","2/2 [==============================] - 0s 139ms/step - loss: 0.1068 - accuracy: 0.9692\n","Epoch 270/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1091 - accuracy: 0.9681\n","Epoch 270: loss did not improve from 0.10229\n","2/2 [==============================] - 0s 149ms/step - loss: 0.1091 - accuracy: 0.9681\n","Epoch 271/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1099 - accuracy: 0.9695\n","Epoch 271: loss did not improve from 0.10229\n","2/2 [==============================] - 0s 130ms/step - loss: 0.1099 - accuracy: 0.9695\n","Epoch 272/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1086 - accuracy: 0.9688\n","Epoch 272: loss did not improve from 0.10229\n","2/2 [==============================] - 0s 143ms/step - loss: 0.1086 - accuracy: 0.9688\n","Epoch 273/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1033 - accuracy: 0.9694\n","Epoch 273: loss did not improve from 0.10229\n","2/2 [==============================] - 0s 131ms/step - loss: 0.1033 - accuracy: 0.9694\n","Epoch 274/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1070 - accuracy: 0.9712\n","Epoch 274: loss did not improve from 0.10229\n","2/2 [==============================] - 0s 129ms/step - loss: 0.1070 - accuracy: 0.9712\n","Epoch 275/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1033 - accuracy: 0.9692\n","Epoch 275: loss did not improve from 0.10229\n","2/2 [==============================] - 0s 134ms/step - loss: 0.1033 - accuracy: 0.9692\n","Epoch 276/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1013 - accuracy: 0.9703\n","Epoch 276: loss improved from 0.10229 to 0.10133, saving model to /content/gdrive/MyDrive/IA/PLN/ckeckpoint_RNN/cp_0276.ckpt\n","2/2 [==============================] - 1s 383ms/step - loss: 0.1013 - accuracy: 0.9703\n","Epoch 277/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1051 - accuracy: 0.9703\n","Epoch 277: loss did not improve from 0.10133\n","2/2 [==============================] - 0s 124ms/step - loss: 0.1051 - accuracy: 0.9703\n","Epoch 278/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1044 - accuracy: 0.9689\n","Epoch 278: loss did not improve from 0.10133\n","2/2 [==============================] - 0s 141ms/step - loss: 0.1044 - accuracy: 0.9689\n","Epoch 279/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1034 - accuracy: 0.9691\n","Epoch 279: loss did not improve from 0.10133\n","2/2 [==============================] - 0s 132ms/step - loss: 0.1034 - accuracy: 0.9691\n","Epoch 280/300\n","2/2 [==============================] - ETA: 0s - loss: 0.0966 - accuracy: 0.9700\n","Epoch 280: loss improved from 0.10133 to 0.09662, saving model to /content/gdrive/MyDrive/IA/PLN/ckeckpoint_RNN/cp_0280.ckpt\n","2/2 [==============================] - 1s 973ms/step - loss: 0.0966 - accuracy: 0.9700\n","Epoch 281/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1049 - accuracy: 0.9697\n","Epoch 281: loss did not improve from 0.09662\n","2/2 [==============================] - 0s 128ms/step - loss: 0.1049 - accuracy: 0.9697\n","Epoch 282/300\n","2/2 [==============================] - ETA: 0s - loss: 0.0998 - accuracy: 0.9719\n","Epoch 282: loss did not improve from 0.09662\n","2/2 [==============================] - 0s 141ms/step - loss: 0.0998 - accuracy: 0.9719\n","Epoch 283/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1007 - accuracy: 0.9708\n","Epoch 283: loss did not improve from 0.09662\n","2/2 [==============================] - 0s 125ms/step - loss: 0.1007 - accuracy: 0.9708\n","Epoch 284/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1056 - accuracy: 0.9678\n","Epoch 284: loss did not improve from 0.09662\n","2/2 [==============================] - 0s 128ms/step - loss: 0.1056 - accuracy: 0.9678\n","Epoch 285/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1041 - accuracy: 0.9697\n","Epoch 285: loss did not improve from 0.09662\n","2/2 [==============================] - 0s 135ms/step - loss: 0.1041 - accuracy: 0.9697\n","Epoch 286/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1037 - accuracy: 0.9706\n","Epoch 286: loss did not improve from 0.09662\n","2/2 [==============================] - 0s 135ms/step - loss: 0.1037 - accuracy: 0.9706\n","Epoch 287/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1021 - accuracy: 0.9686\n","Epoch 287: loss did not improve from 0.09662\n","2/2 [==============================] - 0s 135ms/step - loss: 0.1021 - accuracy: 0.9686\n","Epoch 288/300\n","2/2 [==============================] - ETA: 0s - loss: 0.0946 - accuracy: 0.9720\n","Epoch 288: loss improved from 0.09662 to 0.09459, saving model to /content/gdrive/MyDrive/IA/PLN/ckeckpoint_RNN/cp_0288.ckpt\n","2/2 [==============================] - 1s 364ms/step - loss: 0.0946 - accuracy: 0.9720\n","Epoch 289/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1039 - accuracy: 0.9711\n","Epoch 289: loss did not improve from 0.09459\n","2/2 [==============================] - 0s 128ms/step - loss: 0.1039 - accuracy: 0.9711\n","Epoch 290/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1005 - accuracy: 0.9702\n","Epoch 290: loss did not improve from 0.09459\n","2/2 [==============================] - 0s 146ms/step - loss: 0.1005 - accuracy: 0.9702\n","Epoch 291/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1000 - accuracy: 0.9711\n","Epoch 291: loss did not improve from 0.09459\n","2/2 [==============================] - 0s 132ms/step - loss: 0.1000 - accuracy: 0.9711\n","Epoch 292/300\n","2/2 [==============================] - ETA: 0s - loss: 0.0963 - accuracy: 0.9703\n","Epoch 292: loss did not improve from 0.09459\n","2/2 [==============================] - 0s 160ms/step - loss: 0.0963 - accuracy: 0.9703\n","Epoch 293/300\n","2/2 [==============================] - ETA: 0s - loss: 0.0973 - accuracy: 0.9706\n","Epoch 293: loss did not improve from 0.09459\n","2/2 [==============================] - 0s 147ms/step - loss: 0.0973 - accuracy: 0.9706\n","Epoch 294/300\n","2/2 [==============================] - ETA: 0s - loss: 0.0941 - accuracy: 0.9698\n","Epoch 294: loss improved from 0.09459 to 0.09414, saving model to /content/gdrive/MyDrive/IA/PLN/ckeckpoint_RNN/cp_0294.ckpt\n","2/2 [==============================] - 1s 525ms/step - loss: 0.0941 - accuracy: 0.9698\n","Epoch 295/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1023 - accuracy: 0.9683\n","Epoch 295: loss did not improve from 0.09414\n","2/2 [==============================] - 0s 136ms/step - loss: 0.1023 - accuracy: 0.9683\n","Epoch 296/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1026 - accuracy: 0.9678\n","Epoch 296: loss did not improve from 0.09414\n","2/2 [==============================] - 0s 132ms/step - loss: 0.1026 - accuracy: 0.9678\n","Epoch 297/300\n","2/2 [==============================] - ETA: 0s - loss: 0.1023 - accuracy: 0.9689\n","Epoch 297: loss did not improve from 0.09414\n","2/2 [==============================] - 0s 126ms/step - loss: 0.1023 - accuracy: 0.9689\n","Epoch 298/300\n","2/2 [==============================] - ETA: 0s - loss: 0.0962 - accuracy: 0.9727\n","Epoch 298: loss did not improve from 0.09414\n","2/2 [==============================] - 0s 131ms/step - loss: 0.0962 - accuracy: 0.9727\n","Epoch 299/300\n","2/2 [==============================] - ETA: 0s - loss: 0.0938 - accuracy: 0.9702\n","Epoch 299: loss improved from 0.09414 to 0.09381, saving model to /content/gdrive/MyDrive/IA/PLN/ckeckpoint_RNN/cp_0299.ckpt\n","2/2 [==============================] - 1s 500ms/step - loss: 0.0938 - accuracy: 0.9702\n","Epoch 300/300\n","2/2 [==============================] - ETA: 0s - loss: 0.0983 - accuracy: 0.9717\n","Epoch 300: loss did not improve from 0.09381\n","2/2 [==============================] - 0s 147ms/step - loss: 0.0983 - accuracy: 0.9717\n"]}]},{"cell_type":"markdown","metadata":{"id":"URtG1ZI0L99C"},"source":["\n","#####4.2a-1 entrenando desde un checkpoint\n","\n","---\n","Desde la carpeta que optamos guardar los checkpoints\n","\n","*   el archivo .data es el archivo que contiene nuestras variables de entrenamiento y vamos a ir tras él.\n","*   el archivo checkpoint, simplemente mantiene un registro de los últimos archivos de punto de control guardados\n","\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8o4h9cq8ac68","executionInfo":{"status":"ok","timestamp":1650428386121,"user_tz":300,"elapsed":433,"user":{"displayName":"Luis Fernando Castellanos Guarin","userId":"08966922054785833228"}},"outputId":"5fe3ecae-8cc6-4478-ec7b-8b3803f27b89"},"source":["#creamos un modelo con iguales caracteristicas al 1° modelo\n","model=create_model(vocab_size   =vocab_size,\n","                  embedding_dim =embedding_dim,\n","                  rnn_units     =rnn_units,\n","                  batch_size    =BATCH_SIZE)\n","\n","#buscamos el ultimo checkpoint de entrenamiento\n","latest = tf.train.latest_checkpoint(checkpoint_dir)\n","print(latest)"],"execution_count":78,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/IA/PLN/ckeckpoint_RNN/cp_0297.ckpt\n"]}]},{"cell_type":"code","metadata":{"id":"CGZCz4W3lkWa"},"source":["# cargamos los pesos al nuevo modelo (estos valores tienes una variación de un 10%)\n","model.load_weights(latest)\n","# continuamos el entrenamiento desde el checkpoint en que quedamos\n","history2=model.fit(dataset, \n","                    epochs=300, \n","                    verbose=1,\n","                    callbacks=[cp_callback])              \n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uIkOBKGAP0y-"},"source":["####P4.2b entrenando con tensorboard (opcional)"]},{"cell_type":"markdown","metadata":{"id":"hFDzT0NtUpua"},"source":["#####Activando TENSORBOARD \n","\n","---\n","(DASHBOARD para ver el proceso de entrenamiento)"]},{"cell_type":"code","metadata":{"id":"uJ1L-Vm1ZrTU"},"source":["%load_ext tensorboard  #cargando la extensión de tensorboard\n","!rm -rf /content/drive/MyDrive/IA/PLN/checkpoints_rnn/  # limpiamos la carpeta de cualquier log de entrenamiento previo (en google drive)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#definimos una carpeta dentro de google drive\n","log_dir = \"/content/drive/MyDrive/IA/PLN/checkpoints_rnn/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n","tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"],"metadata":{"id":"cdGwbNQ1hgTm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SmC4IO8rg5TV"},"source":["#####Fit"]},{"cell_type":"code","metadata":{"id":"jcLIbeJjGmDF"},"source":["model.fit(dataset, \n","          epochs=500, \n","          callbacks=[tensorboard_callback])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#####tensorboard - resultado fit"],"metadata":{"id":"ijFZ0cjcmHV5"}},{"cell_type":"code","source":["!tensorboard dev upload \\\n","  --logdir /content/drive/MyDrive/IA/PLN/checkpoints_rnn \\\n","  --name \"RNN gato con botas\" \\\n","  --description \"RNN gato con botas\" \\\n","  --one_shot"],"metadata":{"id":"SL2TKBt4jxOh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FnIbqMyqzrWU"},"source":["##P5. Generando texto nuevo usando la RNN"]},{"cell_type":"code","metadata":{"id":"1vGr7GvUzwxg","executionInfo":{"status":"ok","timestamp":1650430034417,"user_tz":300,"elapsed":999,"user":{"displayName":"Luis Fernando Castellanos Guarin","userId":"08966922054785833228"}}},"source":["#creamos un modelo tomando como base el ultimo checkpoint\n","model = create_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n","model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n","model.build(tf.TensorShape([1,None]))"],"execution_count":109,"outputs":[]},{"cell_type":"code","source":["print(input_eval)"],"metadata":{"id":"qK1YF75Yv28g"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CvoSiWWp2_H-","executionInfo":{"status":"ok","timestamp":1650430036675,"user_tz":300,"elapsed":272,"user":{"displayName":"Luis Fernando Castellanos Guarin","userId":"08966922054785833228"}}},"source":["#funcion para generar texto\n","def generate_text(model, start_string):\n","  #definimos cuantos tensores/cantidad de texto generaremos\n","  num_generate=500\n","  #convertimos el texto en números\n","  input_eval=[char2idx[s] for s in start_string]\n","  input_eval= tf.expand_dims (input_eval,0)\n","  text_generated = []\n","\n","  temperature = 0.2  #(0.0 a  1) entre más alta la temperatura más creatividad al modelo, pero tambien más errores ortograficos.\n","  model.reset_states() #bucle para generar caracteres, mediante predicciones\n","  for i in range(num_generate):\n","    predictions = model(input_eval)\n","    predictions = tf.squeeze(predictions, 0)\n","    predictions = predictions / temperature\n","    predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n","    input_eval= tf.expand_dims([predicted_id],0)\n","    text_generated.append (idx2char[predicted_id])\n","  \n","  return (start_string+ ''.join(text_generated))\n"],"execution_count":110,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZFfQ5EiP4ghF"},"source":["###P5.1 generando texto "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BkLdbX724kBy","executionInfo":{"status":"ok","timestamp":1650430043209,"user_tz":300,"elapsed":4389,"user":{"displayName":"Luis Fernando Castellanos Guarin","userId":"08966922054785833228"}},"outputId":"cc30f5c0-0468-41ba-e267-9fe0875a9395"},"source":["print(generate_text(model, start_string=u\"te odio\"))"],"execution_count":111,"outputs":[{"output_type":"stream","name":"stdout","text":["te odio pado con las riquezas del se or marques de carabas al iga del rey y ese mismo dia se caso con la princesa el gato se asusto tanto al ver a un leon delante de la forma del mas peque o animalillo por ejemplo que puedes por ejemplo transformarte en leon en elefieso que eso me parece imposible imposible repuso al ver que su proyecto empezaba a resultar se adel reparto fue bien simple ya que no se necesito llas vera majestad es una tierra que no deja de producia a sus tres hijos su molino su burro y\n"]}]},{"cell_type":"markdown","metadata":{"id":"T-3PF45LpJBS"},"source":["##P6.exportando modelo\n","\n","---\n","Guardamos y Serializamos el Modelo (con esto ya podemos vender nuestro modelo de predicción de texto según lo aprendido por nuestra RNN).\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5_BJSb-7pL7B","executionInfo":{"status":"ok","timestamp":1650430087294,"user_tz":300,"elapsed":465,"user":{"displayName":"Luis Fernando Castellanos Guarin","userId":"08966922054785833228"}},"outputId":"8d535feb-a30e-4e56-cb97-0074dad1bd5a"},"source":["from keras.models import model_from_json\n","import os\n","dir_export= '/content/gdrive/MyDrive/IA/PLN/Modelos'\n","dir_export= '/content'\n","#dir_export= os.path.join(dir_drive)\n","# Serializamos el modelo en forma JSON\n","model_json = model.to_json()\n","with open(os.path.join(dir_export,'elGatoConBotas.json'), 'w') as json_file:\n","    json_file.write(model_json)\n","# serialize weights to HDF5\n","model.save_weights(os.path.join(dir_export,'elGatoConBotas.hdf5'))\n","model.save(os.path.join(dir_export,'elGatoConBotas.h5'))\n","print(\"modelo salvado en Drive de google\")"],"execution_count":113,"outputs":[{"output_type":"stream","name":"stdout","text":["modelo salvado en Drive de google\n"]}]},{"cell_type":"markdown","metadata":{"id":"JfogT546zoDp"},"source":["##P7.Cargando un modelo serializado"]},{"cell_type":"markdown","metadata":{"id":"2d_bhKoHCE7m"},"source":["###P7.1a descargamos el modelo usando wget (no esta descargando completo el archivo)"]},{"cell_type":"code","metadata":{"id":"3R11dLzBzwv0"},"source":["!wget https://github.com/luisFernandoCastellanosG/Machine_learning/blob/master/2-Deep_Learning/PLN/recurrent_network_RNN/Modelos/ElGatoConBotas/elGatoConBotas.h5?raw=true \\\n","      -O elGatoConBotas.h5"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SKuJocQwCLg1"},"source":["###P7.1b descargamos el modelo usando PYRIND & URLLIB (OPCIONAL)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2w_jNNbCAul4","executionInfo":{"status":"ok","timestamp":1650336301059,"user_tz":300,"elapsed":3651,"user":{"displayName":"Luis Fernando Castellanos Guarin","userId":"08966922054785833228"}},"outputId":"7f94774d-623f-4cbb-df8c-157c0eb5837e"},"source":["!pip install pyprind"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting pyprind\n","  Downloading PyPrind-2.11.3-py2.py3-none-any.whl (8.4 kB)\n","Installing collected packages: pyprind\n","Successfully installed pyprind-2.11.3\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IZcueKBiAqRd","executionInfo":{"status":"ok","timestamp":1650428887420,"user_tz":300,"elapsed":26261,"user":{"displayName":"Luis Fernando Castellanos Guarin","userId":"08966922054785833228"}},"outputId":"c51e7ac0-876d-44c8-f106-ce6226c2a42f"},"source":["def reporthook(count, block_size, total_size):\n","    global start_time\n","    if count == 0:\n","        start_time = time.time()\n","        return\n","    duration = time.time() - start_time\n","    progress_size = int(count * block_size)\n","    speed = progress_size / (1024.**2 * duration)\n","    percent = count * block_size * 100. / total_size\n","    sys.stdout.write(\"\\r%d%% | %d MB | %.2f MB/s | %d segundos transcurrido\" %\n","                    (percent, progress_size / (1024.**2), speed, duration))\n","    sys.stdout.flush()\n","\n","import urllib.request\n","url_github_Model='https://github.com/luisFernandoCastellanosG/Machine_learning/blob/master/2-Deep_Learning/PLN/recurrent_network_RNN/Modelos/ElGatoConBotas/elGatoConBotas.h5?raw=true'\n","urllib.request.urlretrieve(url_github_Model,\n","                           'elGatoConBotas.h5', \n","                           reporthook)"],"execution_count":90,"outputs":[{"output_type":"stream","name":"stdout","text":["100% | 60 MB | 4.50 MB/s | 13 segundos transcurrido"]},{"output_type":"execute_result","data":{"text/plain":["('elGatoConBotas.h5', <http.client.HTTPMessage at 0x7fd06987d650>)"]},"metadata":{},"execution_count":90}]},{"cell_type":"markdown","metadata":{"id":"7lxBCpidCk7b"},"source":["###P7.2 instanciamos el modelo descargado"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dewzz_pW9fFE","executionInfo":{"status":"ok","timestamp":1650430101107,"user_tz":300,"elapsed":695,"user":{"displayName":"Luis Fernando Castellanos Guarin","userId":"08966922054785833228"}},"outputId":"f3f37658-bccb-4a8f-a617-3b141eed5288"},"source":["new_model = tf.keras.models.load_model('/content/elGatoConBotas.h5')"],"execution_count":114,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"eFClGoVR2rFG","executionInfo":{"status":"ok","timestamp":1650336612249,"user_tz":300,"elapsed":192,"user":{"displayName":"Luis Fernando Castellanos Guarin","userId":"08966922054785833228"}},"outputId":"1a9b65ba-719d-4a19-d959-a4ac71d70f23"},"source":["df2 = pd.read_csv(\"https://raw.githubusercontent.com/luisFernandoCastellanosG/Machine_learning/master/2-Deep_Learning/PLN/recurrent_network_RNN/Modelos/LasMinasDelReySalomon/data_vocab.csv\")\n","df2.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   num vocab\n","0    0      \n","1    1     0\n","2    2     1\n","3    3     2\n","4    4     3"],"text/html":["\n","  <div id=\"df-67a464e7-d852-4b7c-a4fb-5dda85dbefbf\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>num</th>\n","      <th>vocab</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td></td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-67a464e7-d852-4b7c-a4fb-5dda85dbefbf')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-67a464e7-d852-4b7c-a4fb-5dda85dbefbf button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-67a464e7-d852-4b7c-a4fb-5dda85dbefbf');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":93}]},{"cell_type":"code","source":["char2idx = df2[[\"num\"]].to_numpy()\n","idx2char = df2[[\"vocab\"]].to_numpy()"],"metadata":{"id":"VqQjOv_Ew5b2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(idx2char)   # vocablos\n","print(char2idx)   # numero de vocablos"],"metadata":{"id":"q06qGkFdxYDS"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NyHgx1AP2oz4","executionInfo":{"status":"ok","timestamp":1650430146298,"user_tz":300,"elapsed":201,"user":{"displayName":"Luis Fernando Castellanos Guarin","userId":"08966922054785833228"}}},"source":["#funcion para generar texto\n","def generate_text(model, start_string):\n","  #definimos cuantos tensores/cantidad de texto generaremos\n","  num_generate=500\n","  #convertimos el texto en números\n","  input_eval  = [char2idx[s] for s in start_string]\n","  input_eval  = tf.expand_dims (input_eval,0)\n","  text_generated = []\n","\n","  temperature = 0.5  #(0.0 a  1) entre más alta la temperatura más creatividad al modelo, pero tambien más errores ortograficos.\n","  model.reset_states() #bucle para generar caracteres, mediante predicciones\n","  for i in range(num_generate):\n","    predictions = model(input_eval)\n","    predictions = tf.squeeze(predictions, 0)\n","    predictions = predictions / temperature\n","    predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n","    input_eval= tf.expand_dims([predicted_id],0)\n","    text_generated.append (idx2char[predicted_id])\n","  \n","  return (start_string+ ''.join(text_generated))\n"],"execution_count":117,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z-rwH5vd0oGc","executionInfo":{"status":"ok","timestamp":1650430153114,"user_tz":300,"elapsed":4432,"user":{"displayName":"Luis Fernando Castellanos Guarin","userId":"08966922054785833228"}},"outputId":"d5b220d2-8e44-4e0a-b54e-f77dca90537c"},"source":["print(generate_text(new_model, start_string=u\"los fantasmas de \"))"],"execution_count":118,"outputs":[{"output_type":"stream","name":"stdout","text":["los fantasmas de carabas hermoso que eso me parece imposible imposible repuso se or marques que seas mi yerno el marques haciendo que el rey iria a pasear a orillas del rio con suen busca de sus mas bellas vestiduras para el se or marques de carabas el rey le hizo mil atenciones y se or marques que seas mi yerno el marques haciendo que el rey iria a pasear a orillas del rio con sue es yo despues de comerme a mi gato y de hacerme el interior por favor el marques ofrecio la mano a los cuales no se habian atrevido \n"]}]}]}