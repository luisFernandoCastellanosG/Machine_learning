{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red neuronal multi usos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Este código es la estructura basica de una red neuronal de dos capas la cual se puede adecuar para distintos usos solo para fines se prueba se le alimentaran los datos de MNIST, para poderla usar con otros set de datos solo cambia la data de entrada (dependiendo de las variables que vayas a manejar) y las salidas (numero de clasificaciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Parametros de entrenamiento de nuestra red\n",
    "\n",
    "numero_pasos = 500 #El numero de pasos (iteraciones) que se llevaran a cabo en el entrenamiento\n",
    "\n",
    "lotes = 128 #Cada lote de entrenamiento de cuantos elementos va a ser\n",
    "\n",
    "taza_aprendizaje = 0.01 #Que tan rapido aprende el algoritmo \n",
    "\n",
    "display_step = 100 #Cada cuantos pasos de entrenamiento nos desplegara la terminal como va el aprendizaje del programa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Parametros de la estructura de nuestra red\n",
    "\n",
    "numero_entradas = 784 # Numero de entrada que tendremos para nuestra primera capa \n",
    "\n",
    "neuronas_capa1 = 100 # Numero de neuronas en nuestra primera capa\n",
    "\n",
    "neuronas_capa2 = 100 # Numero de neuronas en la segunda capa\n",
    "\n",
    "numero_clasificaciones = 10 # Numero de clasificaciones en nuestra ultima capa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variables que manejaran las entradas y saliedas de nuestra red\n",
    "\n",
    "X = tf.placeholder(\"float\", [None, numero_entradas])\n",
    "Y = tf.placeholder(\"float\", [None, numero_clasificaciones])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Hacemos dos diccionarios, uno con los pesos que usara nuestra red y el otro con los sesgos o bias\n",
    "diccionario_pesos_W = \\\n",
    "    {\n",
    "    'entrada_capa1': tf.Variable(tf.random_normal([numero_entradas, neuronas_capa1])), #pesos de la entrada a la primera capa\n",
    "    'capa1_capa2': tf.Variable(tf.random_normal([neuronas_capa1, neuronas_capa2])), #pesos de primera a segunda capa \n",
    "    'capa2_salida': tf.Variable(tf.random_normal([neuronas_capa2, numero_clasificaciones])) #pesos de segunda capa a salida\n",
    "    }\n",
    "diccionario_sesgos_b = \\\n",
    "    {\n",
    "    'biascapa1': tf.Variable(tf.random_normal([neuronas_capa1])), #sesgo de primera capa\n",
    "    'biascapa2': tf.Variable(tf.random_normal([neuronas_capa2])), #seso de segunda capa\n",
    "    'biasultimacapa': tf.Variable(tf.random_normal([numero_clasificaciones])) #sesgo de ultima capa \n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Funcion la cual une todo lo que hicimos en los ultimos pasos para ya tener una estructura armada \n",
    "def armar_red_neuronal(x):\n",
    "    # Hidden fully connected layer with 256 neurons\n",
    "    capa1 = tf.add(tf.matmul(x, diccionario_pesos_W['entrada_capa1']), diccionario_sesgos_b['biascapa1'])\n",
    "    # Hidden fully connected layer with 256 neurons\n",
    "    capa2 = tf.add(tf.matmul(capa1, diccionario_pesos_W['capa1_capa2']), diccionario_sesgos_b['biascapa2'])\n",
    "    # Output fully connected layer with a neuron for each class\n",
    "    capaSalida = tf.matmul(capa2, diccionario_pesos_W['capa2_salida']) + diccionario_sesgos_b['biasultimacapa']\n",
    "    return capaSalida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Construimos la red y hacemos que la ultima capa pase por una funcion de softmax para hacer la clasificacion\n",
    "logits = armar_red_neuronal(X) #Le alimentamos X ya que es la variable que utilizaremos para la primera capa\n",
    "prediccion = tf.nn.softmax(logits) #Cual es la prediccion de nuestra red (Que clasificacion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos las funciones las cuales se encargan de hacer que nuestro algoritmo aprenda\n",
    "perdida = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y))\n",
    "optimizador = tf.train.AdamOptimizer(learning_rate=taza_aprendizaje)\n",
    "minimizador = optimizador.minimize(perdida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Funciones para medir que tan bien esta aprendiendo el programa durante su entrenamiento\n",
    "predicciones = tf.equal(tf.argmax(prediccion, 1), tf.argmax(Y, 1))\n",
    "certeza = tf.reduce_mean(tf.cast(predicciones, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#inicializamos nuestras variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paso 1,Perdida= 718.1907, Certeza= 0.211\n",
      "Paso 100,Perdida= 71.7677, Certeza= 0.797\n",
      "Paso 200,Perdida= 20.2565, Certeza= 0.914\n",
      "Paso 300,Perdida= 40.0049, Certeza= 0.812\n",
      "Paso 400,Perdida= 13.0502, Certeza= 0.891\n",
      "Paso 500,Perdida= 20.2619, Certeza= 0.883\n",
      "Porcentaje de certeza: 88.66 %\n"
     ]
    }
   ],
   "source": [
    "#Llevamos a cabo el entrenamiento de nuestro modelo\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    sess.run(init)\n",
    "\n",
    "    for step in range(1, numero_pasos + 1):\n",
    "        batch_x, batch_y = mnist.train.next_batch(lotes)\n",
    "        \n",
    "        sess.run(minimizador, feed_dict={X: batch_x, Y: batch_y}) #Correr una paso de entrenamiento\n",
    "        \n",
    "        #Todo esto nos enseña que tan bien esta aprendiendo el programa cada 100 pasos de entrenamiento\n",
    "        if step % display_step == 0 or step == 1:\n",
    "            loss, acc = sess.run([perdida, accuracy], feed_dict={X: batch_x,Y: batch_y})\n",
    "            print(\"Paso \"+str(step)+ \",Perdida= \"+\"{:.4f}\".format(loss)+\", Certeza= \"+\"{:.3f}\".format(acc))\n",
    "\n",
    "\n",
    "    print(\"Porcentaje de certeza: {:.2f}\" .format(sess.run(certeza, feed_dict=\n",
    "                                                           {X: mnist.test.images,Y: mnist.test.labels})*100),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
