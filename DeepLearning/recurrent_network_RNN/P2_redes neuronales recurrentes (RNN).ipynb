{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"P2_redes neuronales recurrentes (RNN).ipynb","provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyMRSJVjAdpmh12tF+opR0K0"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"NyasC25K4L-Y"},"source":["**Caso de estudio: generación de texto**\n","\n","---\n","\n","\n","Cualquier dato que se necesite procesar (sonido, imágenes, texto) primero debe ser convertido en un tensor numérico, un paso llamado “vectorización” (One-hot Encoding y WordEmbedding) de datos (y en nuestro ejemplo previamente las letras deben ser pasadas a valores numéricos "]},{"cell_type":"markdown","metadata":{"id":"u1OVaNED56Fz"},"source":["Para este ejemplo usaremos “*Character level language model*” propuesto por Andrej Karpathy en su artículo \"*The Unreasonable Effectiveness of Recurrent Neural Networks*\"(y parcialmente basado en su implementado en el tutorial \"*Generate text with an RNN*\" de la web de TensorFlow:\n","\n","Consiste en darle a la RNN una palabra y se le pide que modele la distribución de probabilidad del siguiente carácter que le correspondería a la secuencia de caracteres anteriores:\n","\n","Como ejemplo, supongamos que solo tenemos un vocabulario de cuatro letras posibles [“a”,”h”,”l”,”o”], y queremos entrenar a una RNN en la secuencia de entrenamiento “hola”. Esta secuencia de entrenamiento es, de hecho, una fuente de 3 ejemplos de entrenamiento por separado: La probabilidad de “o” debería ser verosímil dada el contexto de “h”, “l” debería ser verosímil en el contexto de “ho”, y finalmente “a” debería ser también verosímil dado el contexto de “hol”."]},{"cell_type":"markdown","metadata":{"id":"GXZpn_Mp9RKj"},"source":["#Ejemplo 1: generando nombre de mascotas"]},{"cell_type":"markdown","metadata":{"id":"71pROykO9fdN"},"source":["##P0. Importación de librerías"]},{"cell_type":"code","metadata":{"id":"2Js5ve559XLy","executionInfo":{"status":"ok","timestamp":1622504139121,"user_tz":300,"elapsed":210,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}}},"source":["#import base64\n","#import requests\n","\n","import tensorflow as tf\n","from keras.models import Model\n","from keras.optimizers import SGD #optimizador del Gradiente Descendente (SGD)\n","from keras.layers import Input, Dense, SimpleRNN\n","#from keras.utils import to_categorical\n","from tensorflow.keras.utils import to_categorical\n","from keras import backend as K # representar la entrada y salida al modelo e\n","import numpy as np\n","np.random.seed(5)\n"],"execution_count":14,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nFgdy6D899kk"},"source":["##P1. Descarga y preprocesado de los datos"]},{"cell_type":"code","metadata":{"id":"4f-k1b5h-IzQ"},"source":["fileDL= tf.keras.utils.get_file('perros_nombres.txt','https://raw.githubusercontent.com/luisFernandoCastellanosG/Machine_learning/master/DeepLearning/recurrent_network_RNN/Datasets/Panel_Txt_Files/perros_nombres.txt')\n","texto = open(fileDL, 'rb').read().decode(encoding='latin-1')\n","nombres= texto.lower()\n","print(nombres)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oIVJuHAbFhp5"},"source":["master = \"https://raw.githubusercontent.com/luisFernandoCastellanosG/Machine_learning/master/DeepLearning/recurrent_network_RNN/Datasets/Panel_Txt_Files/perros_nombres.txt\"\n","req = requests.get(master)\n","nombres = req.text\n","nombres= nombres.lower()\n","print(nombres)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"62SuKzh_ADur"},"source":["##P2. pasar el texto a números"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HfAp_N1FAGU4","executionInfo":{"status":"ok","timestamp":1622504271431,"user_tz":300,"elapsed":221,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"260fcab5-e5ab-4e1a-ab4e-491751245a29"},"source":["alfabeto = list(set(nombres))\n","tam_datos, tam_alfabeto = len(nombres), len(alfabeto)\n","print(\"En total hay %d caracteres, y el diccionario tiene un tamaño de %d caracteres.\" % (tam_datos, tam_alfabeto))"],"execution_count":16,"outputs":[{"output_type":"stream","text":["En total hay 2181 caracteres, y el diccionario tiene un tamaño de 29 caracteres.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"n-lgEvQpAV0q","executionInfo":{"status":"ok","timestamp":1622504290299,"user_tz":300,"elapsed":486,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"be3c63b4-c04d-4188-f9bc-8c5f9b9cf8fb"},"source":["# Conversión de caracteres a índices y viceversa\n","car_a_ind = { car:ind for ind,car in enumerate(sorted(alfabeto))}\n","ind_a_car = { ind:car for ind,car in enumerate(sorted(alfabeto))}\n","print(car_a_ind)\n","print(ind_a_car)"],"execution_count":17,"outputs":[{"output_type":"stream","text":["{'\\n': 0, '\\r': 1, ',': 2, 'a': 3, 'b': 4, 'c': 5, 'd': 6, 'e': 7, 'f': 8, 'g': 9, 'h': 10, 'i': 11, 'j': 12, 'k': 13, 'l': 14, 'm': 15, 'n': 16, 'o': 17, 'p': 18, 'q': 19, 'r': 20, 's': 21, 't': 22, 'u': 23, 'v': 24, 'w': 25, 'x': 26, 'y': 27, 'z': 28}\n","{0: '\\n', 1: '\\r', 2: ',', 3: 'a', 4: 'b', 5: 'c', 6: 'd', 7: 'e', 8: 'f', 9: 'g', 10: 'h', 11: 'i', 12: 'j', 13: 'k', 14: 'l', 15: 'm', 16: 'n', 17: 'o', 18: 'p', 19: 'q', 20: 'r', 21: 's', 22: 't', 23: 'u', 24: 'v', 25: 'w', 26: 'x', 27: 'y', 28: 'z'}\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"1aGrkZXrAcQU"},"source":["P3.Construcción del modelo RNN\n","\n","---\n","Tendrá dos entradas:\n","\n","\n","*    (un carácter del set de entrenamiento) que se representará en el formato one-hot como un vector con 27 elementos (que es el tamaño del alfabeto)\n","*   (el estado oculto en el instante de tiempo anterior) que se representará con un vector de 25 elementos (que será el mismo tamaño de la capa oculta)\n","\n","Además, el modelo generará dos salidas:\n","\n"," *    (la predicción, o el carácter generado por el modelo) que, al igual que la entrada, se representará como un vector con 27 elementos en formato one-hot\n"," *    (el estado oculto en el instante de tiempo actual), un vector también de 25 elementos.\n","\n","\n","\n"," "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LV8QOYtOAdcB","executionInfo":{"status":"ok","timestamp":1622504333589,"user_tz":300,"elapsed":202,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"431b8a22-3a3e-402a-a98d-fe0c26767d89"},"source":["#Creación de la Red Recurrente en Keras\n","n_a = 25    # Número de unidades en la capa oculta (neuronas)\n","entrada  = Input(shape=(None,tam_alfabeto))\n","a0 = Input(shape=(n_a,))\n","\n","celda_recurrente = SimpleRNN(n_a, activation='tanh', return_state = True)\n","#la celda recurrente, tomará la entrada  y el estado oculto anterior, y generará el nuevo estado oculto usando la función de activación tangente hiperbólica\n","capa_salida = Dense(tam_alfabeto, activation='softmax') #tendra tantas nueronas como el numero de caracteres\n","#la capa de salida tendra la función de activación softmax, que tomará la activación generada por la celda recurrente y generará la salida  o predicción\n","salida = []\n","hs, _ = celda_recurrente(entrada, initial_state=a0)\n","salida.append(capa_salida(hs))\n","modelo = Model([entrada,a0],salida)\n","#vusualizamos el modelo\n","modelo.summary()\n"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_3 (InputLayer)            [(None, None, 29)]   0                                            \n","__________________________________________________________________________________________________\n","input_4 (InputLayer)            [(None, 25)]         0                                            \n","__________________________________________________________________________________________________\n","simple_rnn_1 (SimpleRNN)        [(None, 25), (None,  1375        input_3[0][0]                    \n","                                                                 input_4[0][0]                    \n","__________________________________________________________________________________________________\n","dense_1 (Dense)                 (None, 29)           754         simple_rnn_1[0][0]               \n","==================================================================================================\n","Total params: 2,129\n","Trainable params: 2,129\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hB6r5jH3CPDP","executionInfo":{"status":"ok","timestamp":1622504350420,"user_tz":300,"elapsed":198,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"1732b74c-4ada-49d0-9af1-a83eda89a0a8"},"source":["#creamos el optimizador (Gradiente Descendente) y lo añadimos al modelo\n","opt = SGD(lr=0.0005)\n","modelo.compile(optimizer=opt, loss='categorical_crossentropy')"],"execution_count":19,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n","  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"ZogMpDE-CxeM"},"source":["##P4. Entrenamiento de la Red Recurrente RNN"]},{"cell_type":"code","metadata":{"id":"5Lbw6oy7FAS9","executionInfo":{"status":"ok","timestamp":1622504371711,"user_tz":300,"elapsed":200,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}}},"source":["## EJEMPLOS DE ENTRENAMIENTO\n","with open(fileDL) as f:\n","    ejemplos = f.readlines()\n","ejemplos = [x.lower().strip() for x in ejemplos]\n","np.random.shuffle(ejemplos)"],"execution_count":20,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"x1bJkb9BGKyS"},"source":["s definimos una función que tome uno a uno cada ejemplo de entrenamiento y que genere tres vectores, que serán las entradas al modelo"]},{"cell_type":"code","metadata":{"id":"I_z_5BvsGBb7","executionInfo":{"status":"ok","timestamp":1622504419748,"user_tz":300,"elapsed":205,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}}},"source":["# Crear ejemplos de entrenamiento usando un generador\n","def train_generator():\n","    while True:\n","        # Tomar un ejemplo aleatorio\n","        ejemplo = ejemplos[np.random.randint(0,len(ejemplos))]\n","\n","        # Convertir el ejemplo a representación numérica\n","        X = [None] + [car_a_ind[c] for c in ejemplo]\n","\n","        # Crear \"Y\", resultado de desplazar \"X\" un caracter a la derecha\n","        Y = X[1:] + [car_a_ind['\\n']]\n","\n","        # Representar \"X\" y \"Y\" en formato one-hot\n","        x = np.zeros((len(X),1,tam_alfabeto))\n","        onehot = to_categorical(X[1:],tam_alfabeto).reshape(len(X)-1,1,tam_alfabeto)\n","        x[1:,:,:] = onehot\n","        y = to_categorical(Y,tam_alfabeto).reshape(len(X),tam_alfabeto)\n","\n","        # Activación inicial (matriz de ceros)\n","        a = np.zeros((len(X), n_a))\n","\n","        yield [x, a], y\n"],"execution_count":21,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"yTLrhxcCGU3i"},"source":["###P4.1 parametros y entrenamiento"]},{"cell_type":"code","metadata":{"id":"gQUXLHafGdiD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622504659594,"user_tz":300,"elapsed":220874,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"53061f7d-8c6d-4b13-d39d-6ef9ca467004"},"source":["BATCH_SIZE = 80\t\t# Número de ejemplos de entrenamiento a usar en cada iteración\n","NITS = 1000\t\t\t# Número de iteraciones\n","\n","for j in range(NITS):\n","  #historia = modelo.fit_generator(train_generator(), steps_per_epoch=BATCH_SIZE, epochs=1, verbose=0)\n","  historia = modelo.fit(train_generator(), steps_per_epoch=BATCH_SIZE, epochs=1, verbose=0)\n","\n","  # Imprimir evolución del entrenamiento cada 1000 iteraciones\n","  if j%1000 == 0:\n","    print('\\nIteración: %d, Error: %f' % (j, historia.history['loss'][0]) + '\\n')"],"execution_count":22,"outputs":[{"output_type":"stream","text":["\n","Iteración: 0, Error: 3.396321\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_uhJUo_8GlE8"},"source":["##P5 Predicción de la RNN"]},{"cell_type":"code","metadata":{"id":"7eRoextRGubI","executionInfo":{"status":"ok","timestamp":1622504679986,"user_tz":300,"elapsed":188,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}}},"source":["def generar_nombre(modelo,car_a_num,tam_alfabeto,n_a):\n","    # Inicializar x y a con ceros\n","    x = np.zeros((1,1,tam_alfabeto,))\n","    a = np.zeros((1, n_a))\n","\n","    # Nombre generado y caracter de fin de linea\n","    nombre_generado = ''\n","    fin_linea = '\\n'\n","    car = -1\n","\n","    # Iterar sobre el modelo y generar predicción hasta tanto no se alcance\n","    # \"fin_linea\" o el nombre generado llegue a los 50 caracteres\n","    contador = 0\n","    while (car != fin_linea and contador != 50):\n","          # Generar predicción usando la celda RNN\n","          a, _ = celda_recurrente(K.constant(x), initial_state=K.constant(a))\n","          y = capa_salida(a)\n","          prediccion = K.eval(y)\n","\n","          # Escoger aleatoriamente un elemento de la predicción (el elemento con\n","          # con probabilidad más alta tendrá más opciones de ser seleccionado)\n","          ix = np.random.choice(list(range(tam_alfabeto)),p=prediccion.ravel())\n","\n","          # Convertir el elemento seleccionado a caracter y añadirlo al nombre generado\n","          car = ind_a_car[ix]\n","          nombre_generado += car\n","\n","          # Crear x_(t+1) = y_t, y a_t = a_(t-1)\n","          x = to_categorical(ix,tam_alfabeto).reshape(1,1,tam_alfabeto)\n","          a = K.eval(a)\n","\n","          # Actualizar contador y continuar\n","          contador += 1\n","\n","          # Agregar fin de línea al nombre generado en caso de tener más de 50 caracteres\n","          if (contador == 50):\n","            nombre_generado += '\\n'\n","\n","    print(nombre_generado)"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"b_96AD1AG6WK"},"source":["# Generar 10 ejemplos de nombres generados por el modelo ya entrenado\n","for i in range(10):\n","    generar_nombre(modelo,car_a_ind,tam_alfabeto,n_a)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IN7mgVqtPPRw"},"source":["\n","\n","---\n","\n","\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"k6zNNLvrPR1f"},"source":["#EJEMPLO 2: leyendo un cuento"]},{"cell_type":"markdown","metadata":{"id":"MVxWwESyPWDg"},"source":["##P0. importando librerias"]},{"cell_type":"code","metadata":{"id":"gcCanSaNPY4Y","executionInfo":{"status":"ok","timestamp":1622505129833,"user_tz":300,"elapsed":275,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}}},"source":["import numpy\n","import sys\n","from tensorflow import keras\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import Dropout\n","from keras.layers import LSTM\n","from keras.callbacks import ModelCheckpoint\n","from keras.utils import np_utils"],"execution_count":27,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JjQUc0jjQVLR"},"source":["##P1. Descarga y preprocesado de los datos"]},{"cell_type":"code","metadata":{"id":"2d5wzxaBQW40"},"source":["fileDL= tf.keras.utils.get_file('cuentos_infantiles.txt','https://raw.githubusercontent.com/luisFernandoCastellanosG/Machine_learning/master/DeepLearning/recurrent_network_RNN/Datasets/Panel_Txt_Files/varios_cuentos_infantiles.txt')\n","texto = open(fileDL, 'rb').read().decode(encoding='latin-1')\n","raw_text = texto.lower()\n","print(raw_text)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ikT-PEFlRc7y"},"source":["##P2. pasar el texto a números"]},{"cell_type":"code","metadata":{"id":"16uNdDlRRg4O","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622505447872,"user_tz":300,"elapsed":214,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"14373728-6101-4972-aef0-82a9030ea5d2"},"source":["chars = sorted(list(set(raw_text)))\n","char_to_int = dict((c, i) for i, c in enumerate(chars))\n","print(chars)\n","print(char_to_int)"],"execution_count":32,"outputs":[{"output_type":"stream","text":["['\\n', '\\r', ' ', '!', '\"', ',', '-', '.', '0', '1', '2', '7', '8', ':', ';', '?', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '\\x85', '\\x93', '\\x94', '\\x96', '¡', '¿', 'á', 'é', 'í', 'ñ', 'ó', 'ú']\n","{'\\n': 0, '\\r': 1, ' ': 2, '!': 3, '\"': 4, ',': 5, '-': 6, '.': 7, '0': 8, '1': 9, '2': 10, '7': 11, '8': 12, ':': 13, ';': 14, '?': 15, 'a': 16, 'b': 17, 'c': 18, 'd': 19, 'e': 20, 'f': 21, 'g': 22, 'h': 23, 'i': 24, 'j': 25, 'k': 26, 'l': 27, 'm': 28, 'n': 29, 'o': 30, 'p': 31, 'q': 32, 'r': 33, 's': 34, 't': 35, 'u': 36, 'v': 37, 'w': 38, 'x': 39, 'y': 40, 'z': 41, '\\x85': 42, '\\x93': 43, '\\x94': 44, '\\x96': 45, '¡': 46, '¿': 47, 'á': 48, 'é': 49, 'í': 50, 'ñ': 51, 'ó': 52, 'ú': 53}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xU_SXe5JSXT0","executionInfo":{"status":"ok","timestamp":1622505715818,"user_tz":300,"elapsed":205,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"902e5512-6f5e-4f85-bb94-0d65afebf4e0"},"source":["n_chars = len(raw_text)\n","n_vocab = len(chars)\n","print(\"En total hay %d caracteres, y el diccionario tiene un tamaño de %d caracteres.\" % (n_chars, n_vocab))"],"execution_count":36,"outputs":[{"output_type":"stream","text":["En total hay 55827 caracteres, y el diccionario tiene un tamaño de 54 caracteres.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"0ucpDS5lTgKB"},"source":["###P2.1 Dividimos el texto en secuencias:\n","---\n","Dividimos el texto en estas secuencias, convertimos los caracteres a números enteros usando nuestra tabla de búsqueda que preparamos anteriormente\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QdJi9bHtTI46","executionInfo":{"status":"ok","timestamp":1622505602604,"user_tz":300,"elapsed":567,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"468ab4cb-145d-4e4f-b489-68d5f716e73d"},"source":["# preparar el conjunto de datos de los pares de entrada a salida codificados como enteros\n","seq_length = 100\n","dataX = []\n","dataY = []\n","for i in range(0, n_chars - seq_length, 1):\n","\tseq_in = raw_text[i:i + seq_length]\n","\tseq_out = raw_text[i + seq_length]\n","\tdataX.append([char_to_int[char] for char in seq_in])\n","\tdataY.append(char_to_int[seq_out])\n","n_patterns = len(dataX)\n","print (\"Se generaron {} secuencias del 100 caracteres desde texto\". format(n_patterns))"],"execution_count":34,"outputs":[{"output_type":"stream","text":["Se generaron 55727 secuencias del 100 caracteres desde texto\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ZBlU-qNzVOO7"},"source":["##P3. preparar nuestros datos de entrenamiento\n","\n","---\n","\n","\n","1.   Primero debemos transformar la lista de secuencias de entrada en la forma [muestras, pasos de tiempo, características] esperada por una red LSTM.\n","2.   Luego debemos cambiar la escala de los números enteros al rango de 0 a 1 para que los patrones sean más fáciles de aprender mediante la red LSTM que utiliza la función de activación sigmoidea de forma predeterminada.\n","3.   por ultimo necesitamos convertir los patrones de salida (caracteres individuales convertidos en enteros) en una codificación one hot. Esto es para que podamos configurar la red para predecir la probabilidad de cada uno de los 54 caracteres diferentes en el vocabulario (una representación más fácil)\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"GbY1cgrHVSjC","executionInfo":{"status":"ok","timestamp":1622505737884,"user_tz":300,"elapsed":4,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}}},"source":["#transformar la lista X de secuencias de entrada en la forma [muestras, pasos de tiempo, características]\n","X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n","# normalizar (cambiar la escala de los números enteros al rango de 0 a 1 )\n","X = X / float(n_vocab)\n","# convertir los patrones de salida (caracteres individuales convertidos en enteros) en una codificación one hot.\n","y = np_utils.to_categorical(dataY)"],"execution_count":37,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ekQyJUbvWvpZ"},"source":["##P4.Construcción del modelo RNN\n","\n","---\n","definimos nuestro modelo LSTM: \n","Aquí definimos una única capa LSTM oculta con 256 unidades de memoria. La red usa deserción con una probabilidad de 20. La capa de salida es una capa densa que usa la función de activación softmax para generar una predicción de probabilidad para cada uno de los 54 caracteres entre 0 y 1.\n"]},{"cell_type":"code","metadata":{"id":"8sjIOgf8XE_g","executionInfo":{"status":"ok","timestamp":1622505813734,"user_tz":300,"elapsed":633,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}}},"source":["# define the LSTM model\n","model = Sequential()\n","model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n","model.add(Dropout(0.2))\n","model.add(Dense(y.shape[1], activation='softmax'))\n","#utilizamos el algoritmo de optimización de ADAM para la velocidad\n","model.compile(loss='categorical_crossentropy', optimizer='adam')"],"execution_count":38,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4h3kjfw4XikQ"},"source":["###P4.1 Creando chekpoints\n","\n","---\n","\n","La red es lenta de entrenar (alrededor de 300 segundos por época) teniendo activa la GPU, ASí que crearemos CHECKPOINTS (puntos de control) para registrar todos los pesos de la red para archivar cada vez que se observe una mejora en la pérdida al final de la época. Usaremos el mejor conjunto de pesos (menor pérdida) para instanciar nuestro modelo generativo en la siguiente sección"]},{"cell_type":"code","metadata":{"id":"DcvIQPOHXzYL","executionInfo":{"status":"ok","timestamp":1622505904765,"user_tz":300,"elapsed":198,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}}},"source":["# definimos  los checkpoint\n","filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n","checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n","callbacks_list = [checkpoint]"],"execution_count":39,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FczzMAAEX-6h"},"source":["###P4.2 entrenando"]},{"cell_type":"code","metadata":{"id":"HPSD1VSHYAJH"},"source":["model.fit(X, y, epochs=1000, batch_size=128, callbacks=callbacks_list)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WWfRY8pPYMYp"},"source":["##P5.Generando texto con una red LSTM\n","\n","\n","---\n","Vamos a cargar el ultimo CHECKPOINT de entrenamiento y con el haremos MAGIA!!!\n"]},{"cell_type":"code","metadata":{"id":"ngH34tw2YVB6","executionInfo":{"status":"ok","timestamp":1622506550880,"user_tz":300,"elapsed":209,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}}},"source":["filename = \"/content/weights-improvement-1000-0.3400.hdf5\"\n","model.load_weights(filename)\n","model.compile(loss='categorical_crossentropy', optimizer='adam')"],"execution_count":43,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CoKm0kDwY5XG"},"source":["###P5.1 mapeo inverso (números a letras)\n","creamos un mapeo inverso que podamos usar para convertir los números enteros nuevamente en caracteres para que podamos entender las predicciones"]},{"cell_type":"code","metadata":{"id":"pEuAaVxpY-ro","executionInfo":{"status":"ok","timestamp":1622506587382,"user_tz":300,"elapsed":4,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}}},"source":["int_to_char = dict((i, c) for i, c in enumerate(chars))"],"execution_count":44,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9R9T2vJ6ZU9t"},"source":["###P5.2 hacer predicciones\n","La forma más sencilla de utilizar el modelo Keras LSTM para hacer predicciones es comenzar primero con una secuencia semilla como entrada, generar el siguiente carácter y luego actualizar la secuencia semilla para agregar el carácter generado al final y recortar el primer carácter. Este proceso se repite mientras queramos predecir nuevos caracteres (por ejemplo, una secuencia de 1000 caracteres de longitud)."]},{"cell_type":"code","metadata":{"id":"YEJmnxm6ZenD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622507045268,"user_tz":300,"elapsed":34978,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"114d5d5b-ae38-448e-ea82-17012b99f9c9"},"source":["# elige una semilla al azar\n","start = numpy.random.randint(0, len(dataX)-1)\n","pattern = dataX[start]\n","print (\"Semilla:\")\n","print (\"\\\"\" + \" \".join([int_to_char[value] for value in pattern])+\"\\\"\")\n","# generación de caracteres\n","for i in range(1000):\n","\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n","\tx = x / float(n_vocab)\n","\tprediction = model.predict(x, verbose=0)\n","\tindex = numpy.argmax(prediction)\n","\tresult = int_to_char[index]\n","\tseq_in = [int_to_char[value] for value in pattern]\n","\tsys.stdout.write(result)\n","\tpattern.append(index)\n","\tpattern = pattern[1:len(pattern)]\n","print (\"\\nDone.\")"],"execution_count":46,"outputs":[{"output_type":"stream","text":["Semilla:\n","\"a r   p a r a   b u s c a r l e s . \r \n"," p i n o c h o   y   g r i l l o   d e c i d i e r o n   i r   a   b u s c a r l e ,   p e r o   s e   c r u z a r o n   c o n   u n   g r u p o   d e   n i ñ o\"\n","s:\n","- ¿dónde vais?- preguntó pinocho.\n","\n","\n","sesii dlcpó mesor er farelterta ale nevor de lu abpilon de la casa de én ceríano ee parno.\n","\n","- espera  ses rod dono sa sistó ca ellara, es aloa el lasa qu qedin\n","Done.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"TRh4YwjBVmvx"},"source":["##P6.Mejorando la red (una LSTM más grande)"]},{"cell_type":"code","metadata":{"id":"7z5w5CleVu6j","executionInfo":{"status":"ok","timestamp":1622507068899,"user_tz":300,"elapsed":752,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}}},"source":["model = Sequential()\n","model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n","model.add(Dropout(0.2))\n","#pero agregaremos una segunda capa.\n","model.add(LSTM(256))\n","model.add(Dropout(0.2))\n","model.add(Dense(y.shape[1], activation='softmax'))\n","model.compile(loss='categorical_crossentropy', optimizer='adam')\n","#cambiamos el nombre de archivo de los pesos con puntos de control para que \n","#podamos distinguir entre los pesos de esta red \n","filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\""],"execution_count":47,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zGLMqyQvWRRv"},"source":["###P6.1 mejoramos el entrenamiento\n","\n","---\n","aumentamos las epoch y disminuiremos el tamaño del lote de 128 a 64 para darle a la red más oportunidades de actualizarse y aprender.\n"]},{"cell_type":"code","metadata":{"id":"9kjWAw-JWVce","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622508031962,"user_tz":300,"elapsed":952854,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"fbc4def7-60f0-4a53-f622-08e392ce3c50"},"source":["#los tiempos de entrenamiento aumentaran al doble que en la versión anterior\n","model.fit(X, y, epochs=50, batch_size=64, callbacks=callbacks_list)"],"execution_count":48,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n","871/871 [==============================] - 21s 22ms/step - loss: 3.0557\n","\n","Epoch 00001: loss did not improve from 1.34735\n","Epoch 2/50\n","871/871 [==============================] - 19s 22ms/step - loss: 2.7523\n","\n","Epoch 00002: loss did not improve from 1.34735\n","Epoch 3/50\n","871/871 [==============================] - 19s 22ms/step - loss: 2.6226\n","\n","Epoch 00003: loss did not improve from 1.34735\n","Epoch 4/50\n","871/871 [==============================] - 19s 22ms/step - loss: 2.5282\n","\n","Epoch 00004: loss did not improve from 1.34735\n","Epoch 5/50\n","871/871 [==============================] - 19s 22ms/step - loss: 2.4478\n","\n","Epoch 00005: loss did not improve from 1.34735\n","Epoch 6/50\n","871/871 [==============================] - 19s 22ms/step - loss: 2.3582\n","\n","Epoch 00006: loss did not improve from 1.34735\n","Epoch 7/50\n","871/871 [==============================] - 19s 22ms/step - loss: 2.2554\n","\n","Epoch 00007: loss did not improve from 1.34735\n","Epoch 8/50\n","871/871 [==============================] - 19s 22ms/step - loss: 2.1692\n","\n","Epoch 00008: loss did not improve from 1.34735\n","Epoch 9/50\n","871/871 [==============================] - 19s 22ms/step - loss: 2.0900\n","\n","Epoch 00009: loss did not improve from 1.34735\n","Epoch 10/50\n","871/871 [==============================] - 19s 22ms/step - loss: 2.0213\n","\n","Epoch 00010: loss did not improve from 1.34735\n","Epoch 11/50\n","871/871 [==============================] - 19s 22ms/step - loss: 1.9549\n","\n","Epoch 00011: loss did not improve from 1.34735\n","Epoch 12/50\n","871/871 [==============================] - 19s 22ms/step - loss: 1.8993\n","\n","Epoch 00012: loss did not improve from 1.34735\n","Epoch 13/50\n","871/871 [==============================] - 19s 22ms/step - loss: 1.8408\n","\n","Epoch 00013: loss did not improve from 1.34735\n","Epoch 14/50\n","871/871 [==============================] - 19s 22ms/step - loss: 1.7981\n","\n","Epoch 00014: loss did not improve from 1.34735\n","Epoch 15/50\n","871/871 [==============================] - 19s 22ms/step - loss: 1.7543\n","\n","Epoch 00015: loss did not improve from 1.34735\n","Epoch 16/50\n","871/871 [==============================] - 19s 22ms/step - loss: 1.6995\n","\n","Epoch 00016: loss did not improve from 1.34735\n","Epoch 17/50\n","871/871 [==============================] - 19s 22ms/step - loss: 1.6597\n","\n","Epoch 00017: loss did not improve from 1.34735\n","Epoch 18/50\n","871/871 [==============================] - 19s 22ms/step - loss: 1.6181\n","\n","Epoch 00018: loss did not improve from 1.34735\n","Epoch 19/50\n","871/871 [==============================] - 19s 22ms/step - loss: 1.5773\n","\n","Epoch 00019: loss did not improve from 1.34735\n","Epoch 20/50\n","871/871 [==============================] - 19s 22ms/step - loss: 1.5351\n","\n","Epoch 00020: loss did not improve from 1.34735\n","Epoch 21/50\n","871/871 [==============================] - 19s 22ms/step - loss: 1.5046\n","\n","Epoch 00021: loss did not improve from 1.34735\n","Epoch 22/50\n","871/871 [==============================] - 19s 22ms/step - loss: 1.4755\n","\n","Epoch 00022: loss did not improve from 1.34735\n","Epoch 23/50\n","871/871 [==============================] - 19s 22ms/step - loss: 1.4449\n","\n","Epoch 00023: loss did not improve from 1.34735\n","Epoch 24/50\n","871/871 [==============================] - 19s 22ms/step - loss: 1.4126\n","\n","Epoch 00024: loss did not improve from 1.34735\n","Epoch 25/50\n","871/871 [==============================] - 19s 22ms/step - loss: 1.3825\n","\n","Epoch 00025: loss did not improve from 1.34735\n","Epoch 26/50\n","871/871 [==============================] - 19s 22ms/step - loss: 1.3465\n","\n","Epoch 00026: loss did not improve from 1.34735\n","Epoch 27/50\n","871/871 [==============================] - 19s 22ms/step - loss: 1.3166\n","\n","Epoch 00027: loss improved from 1.34735 to 1.34141, saving model to weights-improvement-27-1.3414.hdf5\n","Epoch 28/50\n","871/871 [==============================] - 19s 22ms/step - loss: 1.2934\n","\n","Epoch 00028: loss improved from 1.34141 to 1.31561, saving model to weights-improvement-28-1.3156.hdf5\n","Epoch 29/50\n","871/871 [==============================] - 19s 22ms/step - loss: 1.2666\n","\n","Epoch 00029: loss improved from 1.31561 to 1.28988, saving model to weights-improvement-29-1.2899.hdf5\n","Epoch 30/50\n","871/871 [==============================] - 19s 22ms/step - loss: 1.2411\n","\n","Epoch 00030: loss improved from 1.28988 to 1.26687, saving model to weights-improvement-30-1.2669.hdf5\n","Epoch 31/50\n","871/871 [==============================] - 19s 22ms/step - loss: 1.2087\n","\n","Epoch 00031: loss improved from 1.26687 to 1.23724, saving model to weights-improvement-31-1.2372.hdf5\n","Epoch 32/50\n","871/871 [==============================] - 19s 22ms/step - loss: 1.1935\n","\n","Epoch 00032: loss improved from 1.23724 to 1.21709, saving model to weights-improvement-32-1.2171.hdf5\n","Epoch 33/50\n","871/871 [==============================] - 19s 22ms/step - loss: 1.1799\n","\n","Epoch 00033: loss improved from 1.21709 to 1.20089, saving model to weights-improvement-33-1.2009.hdf5\n","Epoch 34/50\n","871/871 [==============================] - 19s 22ms/step - loss: 1.1557\n","\n","Epoch 00034: loss improved from 1.20089 to 1.17680, saving model to weights-improvement-34-1.1768.hdf5\n","Epoch 35/50\n","871/871 [==============================] - 19s 22ms/step - loss: 1.1259\n","\n","Epoch 00035: loss improved from 1.17680 to 1.15622, saving model to weights-improvement-35-1.1562.hdf5\n","Epoch 36/50\n","871/871 [==============================] - 19s 22ms/step - loss: 1.1135\n","\n","Epoch 00036: loss improved from 1.15622 to 1.14022, saving model to weights-improvement-36-1.1402.hdf5\n","Epoch 37/50\n","871/871 [==============================] - 19s 22ms/step - loss: 1.1015\n","\n","Epoch 00037: loss improved from 1.14022 to 1.12829, saving model to weights-improvement-37-1.1283.hdf5\n","Epoch 38/50\n","871/871 [==============================] - 19s 22ms/step - loss: 1.0794\n","\n","Epoch 00038: loss improved from 1.12829 to 1.10574, saving model to weights-improvement-38-1.1057.hdf5\n","Epoch 39/50\n","871/871 [==============================] - 19s 22ms/step - loss: 1.0705\n","\n","Epoch 00039: loss improved from 1.10574 to 1.09353, saving model to weights-improvement-39-1.0935.hdf5\n","Epoch 40/50\n","871/871 [==============================] - 19s 22ms/step - loss: 1.0586\n","\n","Epoch 00040: loss improved from 1.09353 to 1.07638, saving model to weights-improvement-40-1.0764.hdf5\n","Epoch 41/50\n","871/871 [==============================] - 19s 22ms/step - loss: 1.0313\n","\n","Epoch 00041: loss improved from 1.07638 to 1.05674, saving model to weights-improvement-41-1.0567.hdf5\n","Epoch 42/50\n","871/871 [==============================] - 19s 22ms/step - loss: 1.0229\n","\n","Epoch 00042: loss improved from 1.05674 to 1.04270, saving model to weights-improvement-42-1.0427.hdf5\n","Epoch 43/50\n","871/871 [==============================] - 19s 22ms/step - loss: 1.0069\n","\n","Epoch 00043: loss improved from 1.04270 to 1.03452, saving model to weights-improvement-43-1.0345.hdf5\n","Epoch 44/50\n","871/871 [==============================] - 19s 22ms/step - loss: 0.9997\n","\n","Epoch 00044: loss improved from 1.03452 to 1.02376, saving model to weights-improvement-44-1.0238.hdf5\n","Epoch 45/50\n","871/871 [==============================] - 19s 22ms/step - loss: 0.9831\n","\n","Epoch 00045: loss improved from 1.02376 to 1.01080, saving model to weights-improvement-45-1.0108.hdf5\n","Epoch 46/50\n","871/871 [==============================] - 19s 22ms/step - loss: 0.9768\n","\n","Epoch 00046: loss improved from 1.01080 to 0.99587, saving model to weights-improvement-46-0.9959.hdf5\n","Epoch 47/50\n","871/871 [==============================] - 19s 22ms/step - loss: 0.9528\n","\n","Epoch 00047: loss improved from 0.99587 to 0.98994, saving model to weights-improvement-47-0.9899.hdf5\n","Epoch 48/50\n","871/871 [==============================] - 19s 22ms/step - loss: 0.9525\n","\n","Epoch 00048: loss improved from 0.98994 to 0.97710, saving model to weights-improvement-48-0.9771.hdf5\n","Epoch 49/50\n","871/871 [==============================] - 19s 22ms/step - loss: 0.9344\n","\n","Epoch 00049: loss improved from 0.97710 to 0.96145, saving model to weights-improvement-49-0.9614.hdf5\n","Epoch 50/50\n","871/871 [==============================] - 19s 22ms/step - loss: 0.9236\n","\n","Epoch 00050: loss improved from 0.96145 to 0.94717, saving model to weights-improvement-50-0.9472.hdf5\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f3bf266df50>"]},"metadata":{"tags":[]},"execution_count":48}]},{"cell_type":"markdown","metadata":{"id":"-TOM8C2_Y2To"},"source":["###P6.2 haciendo predicciones"]},{"cell_type":"code","metadata":{"id":"gFEPBYrxY5xq"},"source":["# elige una semilla al azar\n","start = numpy.random.randint(0, len(dataX)-1)\n","pattern = dataX[start]\n","print (\"Semilla:\")\n","print (\"\\\"\" + \" \".join([int_to_char[value] for value in pattern])+\"\\\"\")\n","# generación de caracteres\n","for i in range(1000):\n","\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n","\tx = x / float(n_vocab)\n","\tprediction = model.predict(x, verbose=0)\n","\tindex = numpy.argmax(prediction)\n","\tresult = int_to_char[index]\n","\tseq_in = [int_to_char[value] for value in pattern]\n","\tsys.stdout.write(result)\n","\tpattern.append(index)\n","\tpattern = pattern[1:len(pattern)]\n","print (\"\\nDone.\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Dz7aR7_eiYGg"},"source":["##P7. exportar modelo RNN"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tU7_ao0Ciibo","executionInfo":{"status":"ok","timestamp":1622500072815,"user_tz":300,"elapsed":3367,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"596d0ff6-72d5-48d9-f689-b693ccaaf5e0"},"source":["!pip install h5py"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (3.1.0)\n","Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py) (1.5.2)\n","Requirement already satisfied: numpy>=1.14.5; python_version == \"3.7\" in /usr/local/lib/python3.7/dist-packages (from h5py) (1.19.5)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rbuFNARNisdA","executionInfo":{"status":"ok","timestamp":1622500500948,"user_tz":300,"elapsed":212,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"3b123e4c-3ee0-4ab1-abf6-ec822b06ce06"},"source":["from keras.models import model_from_json\n","import os\n","# Serializamos el modelo en forma JSON\n","model_json = model.to_json()\n","with open(\"modelRNN_cuentos.json\", \"w\") as json_file:\n","    json_file.write(model_json)\n","# serialize weights to HDF5\n","model.save_weights(\"/content/modeloRNN_cuentosPesos.hdf5\")\n","model.save('modelRNN_cuentos_v_h5.h5')\n","print(\"modelo salvado en disco\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["modelo salvado en disco\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FshwyfFykB_4"},"source":["###P7.1 cargando un modelo"]},{"cell_type":"code","metadata":{"id":"X2BD6XFKkEmg"},"source":["# Recrea exactamente el mismo modelo solo desde el archivo\n","new_model = keras.models.load_model('/content/modelRNN_cuentos_v_h5.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bjz0OYUYlO2B","executionInfo":{"status":"ok","timestamp":1622501076929,"user_tz":300,"elapsed":188,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"6f9bfd2d-5a1f-4aaa-ab5a-5ca0e29e5b69"},"source":["chars = sorted(list(set(\"comiendo una manzana\")))\n","char_to_int = dict((c, i) for i, c in enumerate(chars))\n","n_chars = len(raw_text)\n","n_vocab = len(chars)\n","print(\"En total hay %d caracteres, y el diccionario tiene un tamaño de %d caracteres.\" % (n_chars, n_vocab))\n","pattern = dataX[5]\n","print(pattern)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["En total hay 55827 caracteres, y el diccionario tiene un tamaño de 11 caracteres.\n","[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 18, 16, 31, 20, 33, 36, 18, 24, 35, 16, 2, 33, 30, 25, 16, 1, 0, 23, 16, 17, 50, 16, 2, 36, 29, 16, 2, 37, 20, 41, 2, 36, 29, 16, 2, 19, 36, 27, 18, 20, 2, 29, 24, 51, 16, 2, 32, 36, 20, 2, 32, 36, 20, 33, 50, 16, 2, 28, 36, 18, 23, 30, 2, 16, 2, 34, 36, 2, 28, 16, 19, 33, 20, 2, 40, 2, 16, 2, 34, 36, 2, 16, 17, 36]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P5z_PSwlkoGg","executionInfo":{"status":"ok","timestamp":1622500663951,"user_tz":300,"elapsed":37810,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"45395bc3-0a94-41dc-d597-4ab05158e8b8"},"source":["start = numpy.random.randint(0, len(dataX)-1)\n","pattern = dataX[start]\n","print (\"Semilla:\")\n","print (\"\\\"\" + \" \".join([int_to_char[value] for value in pattern])+\"\\\"\")\n","# generación de caracteres\n","for i in range(1000):\n","\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n","\tx = x / float(n_vocab)\n","\tprediction = new_model.predict(x, verbose=0)\n","\tindex = numpy.argmax(prediction)\n","\tresult = int_to_char[index]\n","\tseq_in = [int_to_char[value] for value in pattern]\n","\tsys.stdout.write(result)\n","\tpattern.append(index)\n","\tpattern = pattern[1:len(pattern)]\n","print (\"\\nDone.\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Semilla:\n","\"n t e m p l a r   l a s   f l o r e s ,   q u e   c o m e n z a b a n   a   l l e n a r l o   t o d o .   a l l í   v i o   e n   e l   e s t a n q u e   d o s   d e   a q u e l l o s   p á j a r o s\"\n"," sue a la belle y con la boca abierta, lus amlgos de la casa de los piratas, el pey y el gato com su camino de la casa de su harfio, el príncipe juan, pirocho y la reñora darling se quedó hacia ella.\n","y se precó ticme que el cartillo y se puedó hacia la casa de su harta que se encontraban en el estuvendo conmigo y sodos que el carciici y se puedó hacia ella.\n","el patito se sintió delta en palacio, pero el hombre de jengibre corrió más rápido. en la cocina de la casa de los piratas, el peys de noche y la reñora darling se quedó hacia la casa de los piratas,\n","una teca a tu padre la boca abierta dl la casa y algo suppirar y al canbio, estaba muy bueno y poder vup hijas de podenas del príncipe pue al verla. se acuirtió cnn un cama y deseruer a la princesa y lls piratas a la princesa y la peianta de la casa de los piratas dontarcados y acabó por ella. pero se enco lueha a uu paradi y comenzaron que se encontraba\n","Done.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5X8cLamkWi52"},"source":["\n","\n","---\n","\n","\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"eHu5fIzX9Xlp"},"source":["#Ejemplo 3: generar texto de cuentos, usando Keras"]},{"cell_type":"markdown","metadata":{"id":"O5WVmMwYt7Uk"},"source":["##P0. importar librerias"]},{"cell_type":"code","metadata":{"id":"tGa1tvf5t5r4","executionInfo":{"status":"ok","timestamp":1622508539530,"user_tz":300,"elapsed":221,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}}},"source":["import tensorflow as tf\n","import numpy as np\n","import os\n","import time\n","import sys"],"execution_count":50,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9Ot0vNyP9jlQ"},"source":["##P0. Descarga y preprocesado de los datos"]},{"cell_type":"code","metadata":{"id":"6PETkDFl3Mff","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622508620262,"user_tz":300,"elapsed":822,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"1ae31de0-6ee2-4780-86f3-aa031bc3baea"},"source":["fileDL= tf.keras.utils.get_file('LasMinasDelReySalomon.txt','https://raw.githubusercontent.com/carlos-paezf/Deep_Learning/master/Segundo_Corte/PDF_to_TXT/LasMinasDelReySalomon.txt')\n","texto = open(fileDL, 'rb').read().decode(encoding='latin-1')"],"execution_count":51,"outputs":[{"output_type":"stream","text":["Downloading data from https://raw.githubusercontent.com/carlos-paezf/Deep_Learning/master/Segundo_Corte/PDF_to_TXT/LasMinasDelReySalomon.txt\n","516096/515495 [==============================] - 0s 0us/step\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"i-Qr24Chypjd"},"source":["##P1. entendiendo el texto"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TpxHpVkcys57","executionInfo":{"status":"ok","timestamp":1622508629041,"user_tz":300,"elapsed":213,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"d41c22ab-1e99-481c-c975-fb2a876a2956"},"source":["print('el texto tiene longitud de:{} caracteres'. format(len(texto)))\n","vocab = sorted(set(texto))\n","print('el texto esta compuesto de estos :{} caracteres'. format(len(vocab)))\n","print(vocab)"],"execution_count":52,"outputs":[{"output_type":"stream","text":["el texto tiene longitud de:515495 caracteres\n","el texto esta compuesto de estos :93 caracteres\n","['\\n', ' ', '!', '\"', '&', '(', ')', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', '\\\\', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '\\x80', '\\x81', '\\x9c', '¡', '©', '\\xad', '±', '³', 'º', '¼', '¿', 'Â', 'Ã', 'â']\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xPUI-QIDy7Mm"},"source":["##P2. pasar el texto a números\n","\n","---\n","as redes neuronales solo procesan valores numéricos, no letras, por tanto tenemos que traducir los caracteres a representación numérica. Para ello crearemos dos “tablas de traducción”: una de caracteres a números y otra de números a caracteres"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YUZb1tLVzIke","executionInfo":{"status":"ok","timestamp":1622508691997,"user_tz":300,"elapsed":222,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"e9b0e589-b60d-4ec4-aed1-451e3ae5f302"},"source":["char2idx = {u:i for i, u in enumerate(vocab)} # asignamos un número a cada vocablo\n","idx2char = np.array(vocab)\n","#-----------revisando las conversiones\n","#for char,_ in zip(char2idx, range(len(vocab))):\n","#    print(' {:4s}: {:3d},'.format(repr(char),char2idx[char]))\n","\n","#pasamos todo el texto a números\n","texto_como_entero= np.array([char2idx[c] for c in texto])\n","print('texto: {}'.format(repr(texto[:100])))\n","print('{}'.format(repr(texto_como_entero[:100])))"],"execution_count":53,"outputs":[{"output_type":"stream","text":["texto: ' \\n \\n \\n \\n \\n \\n \\n \\n  \\n \\nHenry R. Haggard \\n \\n \\n \\n \\n \\n \\nLas minas del Rey SalomÃ³n \\n   \\n  \\n  \\n   \\n   \\n   '\n","array([ 1,  0,  1,  0,  1,  0,  1,  0,  1,  0,  1,  0,  1,  0,  1,  0,  1,\n","        1,  0,  1,  0, 31, 57, 66, 70, 77,  1, 41,  9,  1, 31, 53, 59, 59,\n","       53, 70, 56,  1,  0,  1,  0,  1,  0,  1,  0,  1,  0,  1,  0,  1,  0,\n","       35, 53, 71,  1, 65, 61, 66, 53, 71,  1, 56, 57, 64,  1, 41, 57, 77,\n","        1, 42, 53, 64, 67, 65, 91, 86, 66,  1,  0,  1,  1,  1,  0,  1,  1,\n","        0,  1,  1,  0,  1,  1,  1,  0,  1,  1,  1,  0,  1,  1,  1])\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"kIT7JzLG4LIs"},"source":["##P3. preparar los datos para ser usados en la RNN"]},{"cell_type":"code","metadata":{"id":"ky_cT7xN4OiO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622508710044,"user_tz":300,"elapsed":251,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"7ac255f8-04b3-4dd3-9677-c0ae85416c29"},"source":["char_dataset= tf.data.Dataset.from_tensor_slices(texto_como_entero)\n","#cantidad de secuencia de caracteres\n","secu_length=150\n","#creamos secuencias de maximo 100 caractereres\n","secuencias= char_dataset.batch(secu_length+1, drop_remainder=True)\n","for item in secuencias.take(10):\n","  print(repr(''.join(idx2char[item.numpy()])))"],"execution_count":54,"outputs":[{"output_type":"stream","text":["' \\n \\n \\n \\n \\n \\n \\n \\n  \\n \\nHenry R. Haggard \\n \\n \\n \\n \\n \\n \\nLas minas del Rey SalomÃ³n \\n   \\n  \\n  \\n   \\n   \\n    IntroducciÃ³n \\n   \\n   \\n    Ahora que este libro es'\n","'tÃ¡ impreso y a punto de salir al mundo, ejerce sobre mÃ\\xad un \\nenorme peso la conciencia de sus defectos, tanto de estilo como de contenido. En lo \\nrefe'\n","'rente a este Ãºltimo, sÃ³lo puedo decir que no pretende ser una relaciÃ³n exhaustiva de \\ntodo lo que vimos e hicimos. Hay muchas cosas concernientes a '\n","'nuestro viaje a \\nKukuanalandia en las que me hubiese gustado explayarme y a las que, de hecho, apenas \\naludo. Entre ellas se encuentran las curiosas le'\n","'yendas que recogÃ\\xad sobre las armaduras \\nque nos salvaron de la muerte en la gran batalla de Loo, y tambiÃ©n sobre los Silenciosos \\no colosos de la entr'\n","'ada de la cueva de estalactitas. Por otra parte, si me hubiera dejado \\nllevar por mis inclinaciones, me habrÃ\\xada gustado ahondar en las diferencias, alg'\n","'unas de \\nlas cuales me resultan muy sugestivas, entre los dialectos zulÃº y kukuana. Asimismo, \\ntambiÃ©n se hubieran podido dedicar unas cuantas pÃ¡gin'\n","'as de provecho al estudio de la \\nflora y la fauna indÃ\\xadgenas de Kukuanalandia1. \\n  Pero aÃºn queda un tema muy interesante, por cierto, y al que, de he'\n","'cho, sÃ³lo se alude \\nde forma fortuita: el magnÃ\\xadfico sistema de organizaciÃ³n militar imperante en ese paÃ\\xads \\nque, en mi opiniÃ³n, es muy superior al '\n","'instaurado por Chaka en Zululandia, en cuanto \\nque permite una movilizaciÃ³n mÃ¡s rÃ¡pida, y no precisa del empleo del pernicioso \\nsistema de celibato '\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Xz5cEwf6_bpv"},"source":["###P3.1 separar los datos en agrupamientos (batches)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-l6Tobzz7hww","executionInfo":{"status":"ok","timestamp":1622508737921,"user_tz":300,"elapsed":226,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"fb1c0e49-fd4e-417a-dd24-daf3a411b9c7"},"source":["#funcion para obtener el conjunto de datos de trainning\n","def split_input_target(chunk):\n","  input_text = chunk[:-1]\n","  target_text= chunk[1:]\n","  return input_text, target_text\n","\n","dataset  = secuencias.map(split_input_target)\n","#el dataset contiene un conjunto de parejas de secuencia de texto\n","#(con la representación numérica de los caracteres), donde el \n","#primer componente de la pareja contiene un paquete con una secuencia \n","#de 100 caracteres del texto original y la segunda su correspondiente salida, \n","#también de 100 caracteres. )\n","for input_example, target_example in dataset.take(1):\n","  print('input data: ', repr(''.join(idx2char[input_example.numpy()])))\n","  print('Target data: ', repr(''.join(idx2char[target_example.numpy()])))"],"execution_count":55,"outputs":[{"output_type":"stream","text":["input data:  ' \\n \\n \\n \\n \\n \\n \\n \\n  \\n \\nHenry R. Haggard \\n \\n \\n \\n \\n \\n \\nLas minas del Rey SalomÃ³n \\n   \\n  \\n  \\n   \\n   \\n    IntroducciÃ³n \\n   \\n   \\n    Ahora que este libro e'\n","Target data:  '\\n \\n \\n \\n \\n \\n \\n \\n  \\n \\nHenry R. Haggard \\n \\n \\n \\n \\n \\n \\nLas minas del Rey SalomÃ³n \\n   \\n  \\n  \\n   \\n   \\n    IntroducciÃ³n \\n   \\n   \\n    Ahora que este libro es'\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8UM54Sfe9x80","executionInfo":{"status":"ok","timestamp":1622508744532,"user_tz":300,"elapsed":208,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"5f69823c-7676-4695-c2a9-9aace4c17264"},"source":["#imprimimos el tensor del dataset\n","print(dataset)\n","#Hyper-Parametros para entrenamiento  de una rede neuronal \n","#   -los datos se agrupan en batch\n","BATCH_SIZE= 64\n","#    -Tamaño de memoria disponible \n","BUFFER_SIZE=10000\n","dataset= dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n","print (dataset)\n","#En el tensor dataset disponemos los datos de entrenamiento\n","#con agrupamienttos (batches) compuestos de 64 parejas de secuencias \n","#de 100 integers de 64 bits que representan el carácter correspondiente \n","#en el vocabulario."],"execution_count":56,"outputs":[{"output_type":"stream","text":["<MapDataset shapes: ((150,), (150,)), types: (tf.int64, tf.int64)>\n","<BatchDataset shapes: ((64, 150), (64, 150)), types: (tf.int64, tf.int64)>\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"kDFFru4s_jon"},"source":["##P4.Construcción del modelo RNN\n","\n","---\n","Para construir el modelo usaremos tf.keras.Sequential. Usaremos una versión mínima de RNN, que contenga solo una capa LSTM y 3 capas.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ox_5lKZh_qUN","executionInfo":{"status":"ok","timestamp":1622508803567,"user_tz":300,"elapsed":481,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"65c1afe2-238a-4427-fc06-dbbc9ddb3486"},"source":["def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n","  #creando el modelo\n","  model = tf.keras.Sequential([\n","    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n","                              batch_input_shape=[batch_size, None]),\n","    tf.keras.layers.LSTM(rnn_units,\n","                         return_sequences=True,\n","                         stateful=True,\n","                         recurrent_initializer='glorot_uniform'),\n","    tf.keras.layers.Dense(vocab_size)                               \n","  ])\n","  return model\n","vocab_size= len(vocab)\n","#dimensiones de los vectores que tendrá la capa.\n","embedding_dim= 256\n","#cantidad de neuronas\n","rnn_units=1024\n","#creamos nuestra red neuronal RNN\n","model=build_model(vocab_size=vocab_size,\n","                  embedding_dim=embedding_dim,\n","                  rnn_units=rnn_units,\n","                  batch_size=BATCH_SIZE)\n","#summary()para visualizar la estructura del modelo\n","model.summary()\n","#resultados=\n","#    -La capa LSTM consta más de 5 millones de parametros)"],"execution_count":57,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (64, None, 256)           23808     \n","_________________________________________________________________\n","lstm (LSTM)                  (64, None, 1024)          5246976   \n","_________________________________________________________________\n","dense (Dense)                (64, None, 93)            95325     \n","=================================================================\n","Total params: 5,366,109\n","Trainable params: 5,366,109\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qK5LScoLEdlu"},"source":["##P4. Entrenando la RNN"]},{"cell_type":"code","metadata":{"id":"nxBZdhbJFAKM","executionInfo":{"status":"ok","timestamp":1622508832886,"user_tz":300,"elapsed":235,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}}},"source":["#como es un problema de clasificación estándar \n","#para el que debemos definir la función de Lossy el optimizador.\n","def loss(labels, logits):\n","  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n","\n","#En cuanto al optimizador usaremos tf.keras.optimizers.Adam \n","#con los argumentos por defecto del optimizador Adam.  \n","model.compile(optimizer='adam',loss=loss)"],"execution_count":58,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dPnll1ubFvZO"},"source":["###P4.1 Creando chekpoints\n","\n","---\n","una técnica de tolerancia de fallos para procesos cuyo tiempo de ejecución es muy largo. La idea es guardar una instantánea del estado del sistema periódicamente para recuperar desde ese punto la ejecución en caso de fallo del sistema.\n"]},{"cell_type":"code","metadata":{"id":"XbeXxiWLF5hN","executionInfo":{"status":"ok","timestamp":1622508854615,"user_tz":300,"elapsed":604,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}}},"source":["checkpoint_dir='/content/trainning_checkpointsCarlos'\n","checkpoint_prefix= os.path.join(checkpoint_dir,\"ckpt_{epoch}\")\n","\n","checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n","    filepath=checkpoint_prefix,\n","    save_weights_only=True\n",")"],"execution_count":59,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"trmMLMjxGjuP"},"source":["###P4.2 entrenando"]},{"cell_type":"code","metadata":{"id":"jcLIbeJjGmDF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622509115658,"user_tz":300,"elapsed":250251,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"ee64a861-8beb-445a-d6a9-275b3b793591"},"source":["EPOCHS=50\n","history=model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])\n","#model.fit(X, y, epochs=50, batch_size=64, callbacks=callbacks_list)"],"execution_count":60,"outputs":[{"output_type":"stream","text":["Epoch 1/50\n","53/53 [==============================] - 6s 79ms/step - loss: 3.0701\n","Epoch 2/50\n","53/53 [==============================] - 5s 79ms/step - loss: 2.4758\n","Epoch 3/50\n","53/53 [==============================] - 5s 78ms/step - loss: 2.1997\n","Epoch 4/50\n","53/53 [==============================] - 5s 79ms/step - loss: 2.0662\n","Epoch 5/50\n","53/53 [==============================] - 5s 79ms/step - loss: 1.9558\n","Epoch 6/50\n","53/53 [==============================] - 5s 79ms/step - loss: 1.8547\n","Epoch 7/50\n","53/53 [==============================] - 5s 79ms/step - loss: 1.7624\n","Epoch 8/50\n","53/53 [==============================] - 5s 79ms/step - loss: 1.6818\n","Epoch 9/50\n","53/53 [==============================] - 5s 79ms/step - loss: 1.6079\n","Epoch 10/50\n","53/53 [==============================] - 5s 80ms/step - loss: 1.5441\n","Epoch 11/50\n","53/53 [==============================] - 5s 80ms/step - loss: 1.4855\n","Epoch 12/50\n","53/53 [==============================] - 5s 80ms/step - loss: 1.4368\n","Epoch 13/50\n","53/53 [==============================] - 5s 79ms/step - loss: 1.3924\n","Epoch 14/50\n","53/53 [==============================] - 5s 79ms/step - loss: 1.3544\n","Epoch 15/50\n","53/53 [==============================] - 5s 79ms/step - loss: 1.3203\n","Epoch 16/50\n","53/53 [==============================] - 5s 80ms/step - loss: 1.2895\n","Epoch 17/50\n","53/53 [==============================] - 5s 79ms/step - loss: 1.2594\n","Epoch 18/50\n","53/53 [==============================] - 5s 80ms/step - loss: 1.2301\n","Epoch 19/50\n","53/53 [==============================] - 5s 79ms/step - loss: 1.2038\n","Epoch 20/50\n","53/53 [==============================] - 5s 79ms/step - loss: 1.1779\n","Epoch 21/50\n","53/53 [==============================] - 5s 79ms/step - loss: 1.1525\n","Epoch 22/50\n","53/53 [==============================] - 5s 79ms/step - loss: 1.1291\n","Epoch 23/50\n","53/53 [==============================] - 5s 79ms/step - loss: 1.1043\n","Epoch 24/50\n","53/53 [==============================] - 5s 79ms/step - loss: 1.0837\n","Epoch 25/50\n","53/53 [==============================] - 5s 79ms/step - loss: 1.0594\n","Epoch 26/50\n","53/53 [==============================] - 5s 79ms/step - loss: 1.0382\n","Epoch 27/50\n","53/53 [==============================] - 5s 79ms/step - loss: 1.0143\n","Epoch 28/50\n","53/53 [==============================] - 5s 79ms/step - loss: 0.9921\n","Epoch 29/50\n","53/53 [==============================] - 5s 79ms/step - loss: 0.9670\n","Epoch 30/50\n","53/53 [==============================] - 5s 79ms/step - loss: 0.9434\n","Epoch 31/50\n","53/53 [==============================] - 5s 79ms/step - loss: 0.9192\n","Epoch 32/50\n","53/53 [==============================] - 5s 79ms/step - loss: 0.8937\n","Epoch 33/50\n","53/53 [==============================] - 5s 79ms/step - loss: 0.8696\n","Epoch 34/50\n","53/53 [==============================] - 5s 79ms/step - loss: 0.8436\n","Epoch 35/50\n","53/53 [==============================] - 5s 79ms/step - loss: 0.8171\n","Epoch 36/50\n","53/53 [==============================] - 5s 80ms/step - loss: 0.7915\n","Epoch 37/50\n","53/53 [==============================] - 5s 80ms/step - loss: 0.7652\n","Epoch 38/50\n","53/53 [==============================] - 5s 79ms/step - loss: 0.7375\n","Epoch 39/50\n","53/53 [==============================] - 5s 80ms/step - loss: 0.7122\n","Epoch 40/50\n","53/53 [==============================] - 5s 79ms/step - loss: 0.6857\n","Epoch 41/50\n","53/53 [==============================] - 5s 79ms/step - loss: 0.6615\n","Epoch 42/50\n","53/53 [==============================] - 5s 80ms/step - loss: 0.6367\n","Epoch 43/50\n","53/53 [==============================] - 5s 79ms/step - loss: 0.6126\n","Epoch 44/50\n","53/53 [==============================] - 5s 80ms/step - loss: 0.5861\n","Epoch 45/50\n","53/53 [==============================] - 5s 79ms/step - loss: 0.5642\n","Epoch 46/50\n","53/53 [==============================] - 5s 80ms/step - loss: 0.5421\n","Epoch 47/50\n","53/53 [==============================] - 5s 80ms/step - loss: 0.5200\n","Epoch 48/50\n","53/53 [==============================] - 5s 80ms/step - loss: 0.5012\n","Epoch 49/50\n","53/53 [==============================] - 5s 80ms/step - loss: 0.4828\n","Epoch 50/50\n","53/53 [==============================] - 5s 80ms/step - loss: 0.4644\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FnIbqMyqzrWU"},"source":["##P5. Generando texto nuevo usando la RNN"]},{"cell_type":"code","metadata":{"id":"1vGr7GvUzwxg","executionInfo":{"status":"ok","timestamp":1622509139976,"user_tz":300,"elapsed":513,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}}},"source":["model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n","model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n","model.build(tf.TensorShape([1,None]))"],"execution_count":61,"outputs":[]},{"cell_type":"code","metadata":{"id":"CvoSiWWp2_H-","executionInfo":{"status":"ok","timestamp":1622509155017,"user_tz":300,"elapsed":210,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}}},"source":["#funcion para generar texto\n","def generate_text(model, start_string):\n","  #definimos cuantos tensores\n","  num_generate=500\n","  #convertimos el texto en números\n","  input_eval=[char2idx[s] for s in start_string]\n","  input_eval= tf.expand_dims (input_eval,0)\n","  text_generated = []\n","\n","  temperature = 0.5  \n","  #entre más alta la temperatura más creatividad al modelo, pero tambien\n","  #más errores ortograficos.\n","  model.reset_states()\n","  #bucle para generar caracteres, mediante predicciones\n","  for i in range(num_generate):\n","    predictions = model(input_eval)\n","    predictions = tf.squeeze(predictions, 0)\n","    predictions = predictions / temperature\n","    predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n","    input_eval= tf.expand_dims([predicted_id],0)\n","    text_generated.append (idx2char[predicted_id])\n","  \n","  return (start_string+ ''.join(text_generated))\n"],"execution_count":62,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZFfQ5EiP4ghF"},"source":["###P5.1 generando texto "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BkLdbX724kBy","executionInfo":{"status":"ok","timestamp":1622509236087,"user_tz":300,"elapsed":2585,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"df4664a0-3277-46bb-a33d-6bc144a7fd0b"},"source":["print(generate_text(model, start_string=u\"estirpe britanica\"))"],"execution_count":66,"outputs":[{"output_type":"stream","text":["estirpe britanicador \n","en la atroumizado autor inversabe el foso de la maÃ±ana, \n","que el regimiento terrible no me gusta falla no podÃ­amos distinguir las cazadoras \n","de todos los hombres blancos a la mandÃ­bula con un hombre alto, de mayer, es de su parte, si es que \n","llegasticio estÃ¡bamos lispuas por su tipo con un suspiro de alivio, y \n","no podÃ­amos seguir por allÃ­, a menos que debÃ­amos peser la amplia avenida cuya \n","con una cabaÃ±a al que comercial atrÃ¡s, fero no podÃ­amos \n","recibir la larga y aplanada su filtr\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"T-3PF45LpJBS"},"source":["##P6.exportando modelo"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5_BJSb-7pL7B","executionInfo":{"status":"ok","timestamp":1622502315077,"user_tz":300,"elapsed":202,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"a64ada82-f7ca-4567-e7eb-ac912d264dca"},"source":["from keras.models import model_from_json\n","import os\n","# Serializamos el modelo en forma JSON\n","model_json = model.to_json()\n","with open(\"modelRNN_cuentosV2.json\", \"w\") as json_file:\n","    json_file.write(model_json)\n","# serialize weights to HDF5\n","model.save_weights(\"/content/modelRNN_cuentosV2_pesos.hdf5\")\n","model.save('modelRNN_cuentosV2.h5')\n","print(\"modelo salvado en disco\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","modelo salvado en disco\n"],"name":"stdout"}]}]}