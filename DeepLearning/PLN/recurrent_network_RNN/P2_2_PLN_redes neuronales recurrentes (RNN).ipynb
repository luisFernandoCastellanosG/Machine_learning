{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"P2_2_PLN_redes neuronales recurrentes (RNN).ipynb","provenance":[],"collapsed_sections":["4h3kjfw4XikQ","FczzMAAEX-6h","CoKm0kDwY5XG","9R9T2vJ6ZU9t","zGLMqyQvWRRv","-TOM8C2_Y2To","FshwyfFykB_4","Xz5cEwf6_bpv","dPnll1ubFvZO","trmMLMjxGjuP","ZFfQ5EiP4ghF"],"toc_visible":true,"authorship_tag":"ABX9TyMcqXSHEvdFhn/D65yQzlPp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"w8jPcr-tb-a5"},"source":["#P0. Introducción -PLN\n","\n","---\n","\n","En la creación de redes neuronales necesitamos dos tipos de IA, para reconocer patrones o generar nuevos:\n","\n","*   Las que no tienen memoria, identifica el patrón y ya!...ejemplo las de visión artificial\n","*   Las de memoria corta (Long Short Term Memory)...PLN\n","*   Las que requieren mucha memoria (aprenden casi todo...BERT)...PLN y visión artificial.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"NyasC25K4L-Y"},"source":["**Caso de estudio: generación de texto**\n","\n","---\n","\n","\n","Cualquier dato que se necesite procesar (sonido, imágenes, texto) primero debe ser convertido en un tensor numérico, un paso llamado “vectorización” (One-hot Encoding y WordEmbedding) de datos (y en nuestro ejemplo previamente las letras deben ser pasadas a valores numéricos "]},{"cell_type":"markdown","metadata":{"id":"u1OVaNED56Fz"},"source":["Para este ejemplo usaremos “*Character level language model*” propuesto por Andrej Karpathy en su artículo \"*The Unreasonable Effectiveness of Recurrent Neural Networks*\"(y parcialmente basado en su implementado en el tutorial \"*Generate text with an RNN*\" de la web de TensorFlow:\n","\n","Consiste en darle a la RNN una palabra y se le pide que modele la distribución de probabilidad del siguiente carácter que le correspondería a la secuencia de caracteres anteriores:\n","\n","Como ejemplo, supongamos que solo tenemos un vocabulario de cuatro letras posibles [“a”,”h”,”l”,”o”], y queremos entrenar a una RNN en la secuencia de entrenamiento “hola”. Esta secuencia de entrenamiento es, de hecho, una fuente de 3 ejemplos de entrenamiento por separado: La probabilidad de “o” debería ser verosímil dada el contexto de “h”, “l” debería ser verosímil en el contexto de “ho”, y finalmente “a” debería ser también verosímil dado el contexto de “hol”.\n","\n","\n","---\n","https://unipython.com/generacion-de-textos-con-inteligencia-artificial/\n"]},{"cell_type":"markdown","metadata":{"id":"k6zNNLvrPR1f"},"source":["#EJEMPLO 1: Prediciendo un texto (cuento los tres cerditos)."]},{"cell_type":"markdown","metadata":{"id":"MVxWwESyPWDg"},"source":["##P0. importando librerias"]},{"cell_type":"markdown","metadata":{"id":"Vl0r6XTg4Jj7"},"source":["###Librerias genericas"]},{"cell_type":"code","metadata":{"id":"P-gVYOjJ4h_W"},"source":["!pip list"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ty9f5o4hHirl"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"97eE8L5n4dxZ","executionInfo":{"status":"ok","timestamp":1635986970596,"user_tz":300,"elapsed":221,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}}},"source":["import requests\n","import io\n","import os\n","\n","import numpy as np\n","import sys\n","\n","#librerías para graficar\n","import matplotlib.pyplot as plt\n","                 \n","plt.rcParams['figure.figsize'] = (16, 9)  #ver graficas grandes \n","plt.style.use('ggplot')\n","#guardar las imagenes y tablas en el cuaderno de jupyter\n","%matplotlib inline "],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IQc-WNUY5QhI"},"source":["###librerias para DL (Deep Learning)"]},{"cell_type":"code","metadata":{"id":"gcCanSaNPY4Y","executionInfo":{"status":"ok","timestamp":1635986986240,"user_tz":300,"elapsed":1959,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}}},"source":["import tensorflow as tf"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ABOLhv9Y5Fuf","executionInfo":{"status":"ok","timestamp":1635986991209,"user_tz":300,"elapsed":230,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"98e17002-6c95-43da-8c97-7fc9936122d2"},"source":["print(\"Version: \", tf.__version__)\n","print(\"Eager mode: \", tf.executing_eagerly())\n","print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Version:  2.6.0\n","Eager mode:  True\n","GPU is available\n"]}]},{"cell_type":"markdown","metadata":{"id":"Tkeq57R55V-W"},"source":["###Activando la GPU\n","\n","---\n","Logra aumentar la velocidad de entrenamiento en un 600% en PLN (RNN) y un 1000% en visión por computadores (CNN)\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vieZASeN5KHd","executionInfo":{"status":"ok","timestamp":1635978219933,"user_tz":300,"elapsed":321,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"ff2b6f2a-9121-470f-9cdd-6356441eca3a"},"source":["tf.device('/cpu:0')# OJO: esto es para que tensorflow utilice la GPU (aumenta la velocidad de entrenamiento en un 600%) "],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.eager.context._EagerDeviceContext at 0x7f0cb01a7eb0>"]},"metadata":{},"execution_count":37}]},{"cell_type":"markdown","metadata":{"id":"JjQUc0jjQVLR"},"source":["##P1. Descarga y preprocesado de los datos"]},{"cell_type":"code","metadata":{"id":"2d5wzxaBQW40","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635987180083,"user_tz":300,"elapsed":272,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"d82e779b-276d-4c34-9b80-3a9f429e010c"},"source":["fileUrl     ='https://raw.githubusercontent.com/luisFernandoCastellanosG/Machine_learning/master/DeepLearning/PLN/Datasets/Panel_Txt_Files/Tres_cerditos.txt'\n","fileContent = tf.keras.utils.get_file('Tres_cerditos.txt',fileUrl)\n","texto       = open(fileContent, 'rb').read().decode(encoding='utf-8')\n","raw_text    = texto.lower()\n","print(raw_text)"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://raw.githubusercontent.com/luisFernandoCastellanosG/Machine_learning/master/DeepLearning/PLN/Datasets/Panel_Txt_Files/Tres_cerditos.txt\n","16384/3231 [========================================================================================================================================================] - 0s 0us/step\n","había una vez tres cerditos que eran hermanos y se fueron por el mundo a conseguir fortuna. el más grande les dijo a sus hermanos que sería bueno que se pusieran a construir sus propias casas para estar protegidos. a los otros dos les pareció una buena idea, y se pusieron manos a la obra, cada uno construyó su casita.  - la mía será de paja - dijo el más pequeño-, la paja es blanda y se puede sujetar con facilidad. terminaré muy pronto y podré ir a jugar. el hermano mediano decidió que su casa sería de madera:  - puedo encontrar un montón de madera por los alrededores - explicó \n","a sus hermanos, - construiré mi casa en un santiamén con todos estos troncos y me iré también a jugar.  cuando las tres casitas estuvieron terminadas, los cerditos cantaban y bailaban en la puerta, felices por haber acabado con el problema:  -¡quién teme al lobo feroz, al lobo, al lobo!  - ¡quién teme al lobo feroz, al lobo feroz! detrás de un árbol grande apareció el lobo, rugiendo de hambre y gritando:  - cerditos, ¡me los voy a comer! cada uno se escondió en su casa, pensando que estaban a salvo, pero el lobo feroz se encaminó a la casita de paja del hermano pequeño y en la puerta aulló:  - ¡cerdito, ábreme la puerta!  - no, no, no, no te voy a abrir. - pues si no me abres... ¡soplaré y soplaré y la casita derribaré! y sopló con todas sus fuerzas, sopló y sopló y la casita de paja se vino abajo. el cerdito pequeño corrió lo más rápido que pudo y entró en la casa de madera del hermano mediano. - ¡quién teme al lobo feroz, al lobo, al lobo!  - ¡quién teme al lobo feroz, al lobo feroz! - cantaban desde dentro los cerditos.  de nuevo el lobo, más enfurecido que antes al sentirse engañado, se colocó delante de la puerta y comenzó a soplar y soplar gruñendo: - ¡cerditos, abridme la puerta! - no, no, no, no te vamos a abrir. - pues si no me abrís... \n","¡soplaré y soplaré y la casita derribaré! la madera crujió, y las paredes cayeron y los dos cerditos corrieron a refugiarse en la casa de ladrillo de su hermano mayor.  - ¡quién teme al lobo feroz, al lobo, al lobo!  - ¡quién teme al lobo feroz, al lobo feroz! - cantaban desde dentro los cerditos. el lobo estaba realmente enfadado y hambriento, y ahora deseaba comerse a los tres cerditos más que nunca, y frente a la puerta dijo:  - ¡cerditos, abridme la puerta! - no, no, no, no te vamos a abrir.  - pues si no me abrís... ¡soplaré y soplaré y la casita derribaré!  y se puso a soplar tan fuerte como el viento de invierno. sopló y sopló, pero la casita de ladrillos era muy resistente y no conseguía derribarla. decidió trepar por la pared y entrar por la chimenea. se deslizó hacia abajo... y cayó en el caldero donde el cerdito mayor estaba hirviendo sopa de nabos. escaldado y con el estómago vacío salió huyendo hacia el lago. los cerditos no lo volvieron a ver.  el mayor de ellos regañó a los otros dos por haber sido tan perezosos y poner en peligro sus propias vidas, y si algún día vais por el bosque y veis tres cerdos, sabréis que son los tres cerditos porque les gusta cantar:  - ¡quién teme al lobo feroz, al lobo, al lobo!  - ¡quién teme al lobo feroz, al lobo feroz!\n"]}]},{"cell_type":"markdown","metadata":{"id":"ikT-PEFlRc7y"},"source":["##P2. pasar el texto a números\n","\n","---\n","Sin importan el origen de la informacción (video, sonido, sensor, texto)...siempre debemos convertirlos en datos númericos.\n"]},{"cell_type":"code","metadata":{"id":"16uNdDlRRg4O","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635987235911,"user_tz":300,"elapsed":222,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"9cf591a5-c45f-46eb-eb41-6653c1c154d6"},"source":["chars = sorted(list(set(raw_text)))\n","char_to_int = dict((c, i) for i, c in enumerate(chars))\n","print(chars)\n","print(char_to_int)"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["['\\n', '\\r', ' ', '!', ',', '-', '.', ':', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'x', 'y', 'z', '¡', 'á', 'é', 'í', 'ñ', 'ó', 'ú']\n","{'\\n': 0, '\\r': 1, ' ': 2, '!': 3, ',': 4, '-': 5, '.': 6, ':': 7, 'a': 8, 'b': 9, 'c': 10, 'd': 11, 'e': 12, 'f': 13, 'g': 14, 'h': 15, 'i': 16, 'j': 17, 'l': 18, 'm': 19, 'n': 20, 'o': 21, 'p': 22, 'q': 23, 'r': 24, 's': 25, 't': 26, 'u': 27, 'v': 28, 'x': 29, 'y': 30, 'z': 31, '¡': 32, 'á': 33, 'é': 34, 'í': 35, 'ñ': 36, 'ó': 37, 'ú': 38}\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xU_SXe5JSXT0","executionInfo":{"status":"ok","timestamp":1635987292197,"user_tz":300,"elapsed":225,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"2d1da1d7-67b2-476a-c993-d53937e1a5d4"},"source":["n_chars = len(raw_text)\n","n_vocab = len(chars)\n","print(\"En total hay %d caracteres, y el diccionario tiene un tamaño de %d caracteres.\" % (n_chars, n_vocab))"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["En total hay 3141 caracteres, y el diccionario tiene un tamaño de 39 caracteres.\n"]}]},{"cell_type":"markdown","metadata":{"id":"0ucpDS5lTgKB"},"source":["###P2.1 Dividimos el texto en secuencias:\n","---\n","Dividimos el texto en estas secuencias (adrede), convertimos los caracteres a números enteros usando nuestra tabla de búsqueda que preparamos anteriormente\n","\n"]},{"cell_type":"code","metadata":{"id":"QdJi9bHtTI46"},"source":["# preparar el conjunto de datos de los pares de entrada a salida codificados como enteros\n","seq_length = 50   #largo de las secciones de texto que usaremos para entrenar\n","dataX = []\n","dataY = []\n","for i in range(0, n_chars - seq_length, 1):\n","\tprint(\"Seq(\",i,\")=\",raw_text[i:i + seq_length],\"---->\",raw_text[i + seq_length])\n","\tseq_in \t= raw_text[i:i + seq_length]         \t\t\t\t\t#secuencia de entrada\n","\tseq_out = raw_text[i + seq_length]\t\t\t\t\t\t\t\t\t\t#siguiente letra despues de la secuencia (la que el va a aprender)\n","\tdataX.append([char_to_int[char] for char in seq_in])  # convertimos cada secuencia en numeros\n","\tdataY.append(char_to_int[seq_out])\n","n_patterns = len(dataX)\n","print (\"Se generaron \",format(n_patterns) ,\" secuencias texto de un tamaño de \",seq_length,\" caracteres\" )\n","print(\"Como se ven los datos de X convertidos a números\\n\")\n","print(dataX)\n","print(\"\\nComo se ven los datos de Y convertidos a números\\n\")\n","print(dataY)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZBlU-qNzVOO7"},"source":["##P3. preparar nuestros datos de entrenamiento\n","\n","---\n","\n","\n","1.   Primero debemos transformar la lista de secuencias de entrada en la forma [muestras, pasos de tiempo, características] esperada por una red LSTM.\n","2.   Luego debemos cambiar la escala de los números enteros al rango de 0 a 1 para que los patrones sean más fáciles de aprender mediante la red LSTM que utiliza la función de activación sigmoidea de forma predeterminada.\n","3.   por ultimo necesitamos convertir los patrones de salida (caracteres individuales convertidos en enteros) en una codificación one hot. Esto es para que podamos configurar la red para predecir la probabilidad de cada uno de los 54 caracteres diferentes en el vocabulario (una representación más fácil)\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"GbY1cgrHVSjC"},"source":["#transformar la lista X de secuencias de entrada en la forma [muestras (3091), pasos de tiempo, características]\n","X = np.reshape(dataX, (n_patterns, seq_length, 1))\n","# normalizar (cambiar la escala de los números enteros al rango de 0 a 1 )\n","X = X / float(n_vocab)\n","# convertir los patrones de salida (caracteres individuales convertidos en enteros) en una codificación one hot.\n","y = np_utils.to_categorical(dataY)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ekQyJUbvWvpZ"},"source":["##P4.Construcción del modelo RNN\n","\n","---\n","definimos nuestro modelo LSTM: \n","Aquí definimos una única capa LSTM oculta con 256 unidades de memoria. La red usa deserción con una probabilidad de 20. La capa de salida es una capa densa que usa la función de activación softmax para generar una predicción de probabilidad para cada uno de los 54 caracteres entre 0 y 1.\n"]},{"cell_type":"code","metadata":{"id":"8sjIOgf8XE_g"},"source":["# define the LSTM model\n","\n","model = tf.keras.models.Sequential()\n","model.add(tf.keras.layers.LSTM(256, input_shape=(X.shape[1], X.shape[2])))    #creamos una capa con 256 unidades de memoria\n","model.add(tf.keras.layers.Dropout(0.2))\n","model.add(tf.keras.layers.Dense(y.shape[1], activation='softmax'))            #Softmax convierte un vector de valores en una distribución de probabilidad para cada uno de los 39\n","                                                                              #Softmax se utiliza a menudo como la activación para la última capa de una red de clasificación\n","#utilizamos el algoritmo de optimización de ADAM para la velocidad\n","model.compile(loss='categorical_crossentropy', optimizer='adam')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4h3kjfw4XikQ"},"source":["###P4.1 Creando chekpoints\n","\n","---\n","\n","La red es lenta de entrenar (alrededor de 300 segundos por época) teniendo activa la GPU, ASí que crearemos CHECKPOINTS (puntos de control) para registrar todos los pesos de la red para archivar cada vez que se observe una mejora en la pérdida al final de la época. Usaremos el mejor conjunto de pesos (menor pérdida) para instanciar nuestro modelo generativo en la siguiente sección"]},{"cell_type":"code","metadata":{"id":"DcvIQPOHXzYL"},"source":["# definimos  una carpeta para guardar los checkpoint\n","filepath=\"checkpoints/weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n","checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n","callbacks_list = [checkpoint]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FczzMAAEX-6h"},"source":["###P4.2 entrenando"]},{"cell_type":"code","metadata":{"id":"HPSD1VSHYAJH"},"source":["history = model.fit(X, y, epochs=1000, batch_size=128, verbose=1,callbacks=callbacks_list)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WWfRY8pPYMYp"},"source":["##P5.Generando texto con una red LSTM\n","\n","\n","---\n","Vamos a cargar el ultimo CHECKPOINT de entrenamiento y con el haremos MAGIA!!!\n"]},{"cell_type":"code","metadata":{"id":"ngH34tw2YVB6"},"source":["filename = \"/content/checkpoints/weights-improvement-899-0.0038.hdf5\"\n","model.load_weights(filename)\n","model.compile(loss='categorical_crossentropy', optimizer='adam')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CoKm0kDwY5XG"},"source":["###P5.1 mapeo inverso (números a letras)\n","creamos un mapeo inverso que podamos usar para convertir los números enteros nuevamente en caracteres para que podamos entender las predicciones"]},{"cell_type":"code","metadata":{"id":"pEuAaVxpY-ro"},"source":["int_to_char = dict((i, c) for i, c in enumerate(chars))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9R9T2vJ6ZU9t"},"source":["###P5.2 hacer predicciones\n","La forma más sencilla de utilizar el modelo Keras LSTM para hacer predicciones es comenzar primero con una secuencia semilla como entrada, generar el siguiente carácter y luego actualizar la secuencia semilla para agregar el carácter generado al final y recortar el primer carácter. Este proceso se repite mientras queramos predecir nuevos caracteres (por ejemplo, una secuencia de 1000 caracteres de longitud)."]},{"cell_type":"code","metadata":{"id":"YEJmnxm6ZenD"},"source":["# elige una semilla al azar\n","#start = numpy.random.randint(0, len(dataX)-1)\n","start =\"soy un cerdito\"\n","pattern = dataX[start]\n","print (\"Semilla:\")\n","print (\"\\\"\" + \" \".join([int_to_char[value] for value in pattern])+\"\\\"\")\n","# generación de 10000 caracteres\n","for i in range(1000):\n","\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n","\tx = x / float(n_vocab)\n","\tprediction = model.predict(x, verbose=0)\n","\tindex = numpy.argmax(prediction)\n","\tresult = int_to_char[index]\n","\tseq_in = [int_to_char[value] for value in pattern]\n","\tsys.stdout.write(result)\n","\tpattern.append(index)\n","\tpattern = pattern[1:len(pattern)]\n","print (\"\\nDone.\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"TRh4YwjBVmvx"},"source":["##P6.Mejorando la red (una LSTM más grande)"]},{"cell_type":"code","metadata":{"id":"7z5w5CleVu6j"},"source":["model = Sequential()\n","model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n","model.add(Dropout(0.2))\n","model.add(LSTM(256))                                                                #agregaremos una segunda capa. \n","model.add(Dropout(0.2))\n","model.add(Dense(y.shape[1], activation='softmax'))\n","model.compile(loss='categorical_crossentropy', optimizer='adam')\n","#cambiamos el nombre de archivo de los pesos con puntos de control para que \n","#podamos distinguir entre los pesos de esta red \n","filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zGLMqyQvWRRv"},"source":["###P6.1 mejoramos el entrenamiento\n","\n","---\n","aumentamos las epoch y disminuiremos el tamaño del lote de 128 a 64 para darle a la red más oportunidades de actualizarse y aprender.\n"]},{"cell_type":"code","metadata":{"id":"9kjWAw-JWVce"},"source":["#los tiempos de entrenamiento aumentaran al doble que en la versión anterior\n","model.fit(X, y, epochs=50, batch_size=64, callbacks=callbacks_list)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-TOM8C2_Y2To"},"source":["###P6.2 haciendo predicciones"]},{"cell_type":"code","metadata":{"id":"gFEPBYrxY5xq"},"source":["# elige una semilla al azar\n","start = numpy.random.randint(0, len(dataX)-1)\n","pattern = dataX[start]\n","print (\"Semilla:\")\n","print (\"\\\"\" + \" \".join([int_to_char[value] for value in pattern])+\"\\\"\")\n","# generación de caracteres\n","for i in range(1000):\n","\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n","\tx = x / float(n_vocab)\n","\tprediction = model.predict(x, verbose=0)\n","\tindex = numpy.argmax(prediction)\n","\tresult = int_to_char[index]\n","\tseq_in = [int_to_char[value] for value in pattern]\n","\tsys.stdout.write(result)\n","\tpattern.append(index)\n","\tpattern = pattern[1:len(pattern)]\n","print (\"\\nDone.\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Dz7aR7_eiYGg"},"source":["##P7. exportar modelo RNN"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tU7_ao0Ciibo","executionInfo":{"status":"ok","timestamp":1622500072815,"user_tz":300,"elapsed":3367,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"596d0ff6-72d5-48d9-f689-b693ccaaf5e0"},"source":["!pip install h5py"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (3.1.0)\n","Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py) (1.5.2)\n","Requirement already satisfied: numpy>=1.14.5; python_version == \"3.7\" in /usr/local/lib/python3.7/dist-packages (from h5py) (1.19.5)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rbuFNARNisdA","executionInfo":{"status":"ok","timestamp":1622500500948,"user_tz":300,"elapsed":212,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"3b123e4c-3ee0-4ab1-abf6-ec822b06ce06"},"source":["from keras.models import model_from_json\n","import os\n","# Serializamos el modelo en forma JSON\n","model_json = model.to_json()\n","with open(\"modelRNN_cuentos.json\", \"w\") as json_file:\n","    json_file.write(model_json)\n","# serialize weights to HDF5\n","model.save_weights(\"/content/modeloRNN_cuentosPesos.hdf5\")\n","model.save('modelRNN_cuentos_v_h5.h5')\n","print(\"modelo salvado en disco\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["modelo salvado en disco\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FshwyfFykB_4"},"source":["###P7.1 cargando un modelo"]},{"cell_type":"code","metadata":{"id":"X2BD6XFKkEmg"},"source":["# Recrea exactamente el mismo modelo solo desde el archivo\n","new_model = keras.models.load_model('/content/modelRNN_cuentos_v_h5.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bjz0OYUYlO2B","executionInfo":{"status":"ok","timestamp":1622501076929,"user_tz":300,"elapsed":188,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"6f9bfd2d-5a1f-4aaa-ab5a-5ca0e29e5b69"},"source":["chars = sorted(list(set(\"comiendo una manzana\")))\n","char_to_int = dict((c, i) for i, c in enumerate(chars))\n","n_chars = len(raw_text)\n","n_vocab = len(chars)\n","print(\"En total hay %d caracteres, y el diccionario tiene un tamaño de %d caracteres.\" % (n_chars, n_vocab))\n","pattern = dataX[5]\n","print(pattern)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["En total hay 55827 caracteres, y el diccionario tiene un tamaño de 11 caracteres.\n","[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 18, 16, 31, 20, 33, 36, 18, 24, 35, 16, 2, 33, 30, 25, 16, 1, 0, 23, 16, 17, 50, 16, 2, 36, 29, 16, 2, 37, 20, 41, 2, 36, 29, 16, 2, 19, 36, 27, 18, 20, 2, 29, 24, 51, 16, 2, 32, 36, 20, 2, 32, 36, 20, 33, 50, 16, 2, 28, 36, 18, 23, 30, 2, 16, 2, 34, 36, 2, 28, 16, 19, 33, 20, 2, 40, 2, 16, 2, 34, 36, 2, 16, 17, 36]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P5z_PSwlkoGg","executionInfo":{"status":"ok","timestamp":1622500663951,"user_tz":300,"elapsed":37810,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"45395bc3-0a94-41dc-d597-4ab05158e8b8"},"source":["start = numpy.random.randint(0, len(dataX)-1)\n","pattern = dataX[start]\n","print (\"Semilla:\")\n","print (\"\\\"\" + \" \".join([int_to_char[value] for value in pattern])+\"\\\"\")\n","# generación de caracteres\n","for i in range(1000):\n","\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n","\tx = x / float(n_vocab)\n","\tprediction = new_model.predict(x, verbose=0)\n","\tindex = numpy.argmax(prediction)\n","\tresult = int_to_char[index]\n","\tseq_in = [int_to_char[value] for value in pattern]\n","\tsys.stdout.write(result)\n","\tpattern.append(index)\n","\tpattern = pattern[1:len(pattern)]\n","print (\"\\nDone.\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Semilla:\n","\"n t e m p l a r   l a s   f l o r e s ,   q u e   c o m e n z a b a n   a   l l e n a r l o   t o d o .   a l l í   v i o   e n   e l   e s t a n q u e   d o s   d e   a q u e l l o s   p á j a r o s\"\n"," sue a la belle y con la boca abierta, lus amlgos de la casa de los piratas, el pey y el gato com su camino de la casa de su harfio, el príncipe juan, pirocho y la reñora darling se quedó hacia ella.\n","y se precó ticme que el cartillo y se puedó hacia la casa de su harta que se encontraban en el estuvendo conmigo y sodos que el carciici y se puedó hacia ella.\n","el patito se sintió delta en palacio, pero el hombre de jengibre corrió más rápido. en la cocina de la casa de los piratas, el peys de noche y la reñora darling se quedó hacia la casa de los piratas,\n","una teca a tu padre la boca abierta dl la casa y algo suppirar y al canbio, estaba muy bueno y poder vup hijas de podenas del príncipe pue al verla. se acuirtió cnn un cama y deseruer a la princesa y lls piratas a la princesa y la peianta de la casa de los piratas dontarcados y acabó por ella. pero se enco lueha a uu paradi y comenzaron que se encontraba\n","Done.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5X8cLamkWi52"},"source":["\n","\n","---\n","\n","\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"eHu5fIzX9Xlp"},"source":["#Ejemplo 2: generar texto de cuentos, usando Keras"]},{"cell_type":"markdown","metadata":{"id":"O5WVmMwYt7Uk"},"source":["##P0. importar librerias"]},{"cell_type":"code","metadata":{"id":"tGa1tvf5t5r4"},"source":["import tensorflow as tf\n","import numpy as np\n","import os\n","import time\n","import sys"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9Ot0vNyP9jlQ"},"source":["##P0. Descarga y preprocesado de los datos"]},{"cell_type":"code","metadata":{"id":"6PETkDFl3Mff"},"source":["fileDL= tf.keras.utils.get_file('LasMinasDelReySalomon.txt','https://raw.githubusercontent.com/luisFernandoCastellanosG/Machine_learning/master/DeepLearning/PLN/Datasets/Panel_Txt_Files/LasMinasDelReySalomon.txt')\n","texto = open(fileDL, 'rb').read().decode(encoding='utf-8')\n","texto = texto.lower()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i-Qr24Chypjd"},"source":["##P1. entendiendo el texto"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TpxHpVkcys57","executionInfo":{"status":"ok","timestamp":1635980023547,"user_tz":300,"elapsed":403,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"75c0ec8d-f662-45c2-e6fc-f3e44c3cd069"},"source":["print('el texto tiene longitud de:{} caracteres'. format(len(texto)))\n","vocab = sorted(set(texto))\n","print('el texto esta compuesto de estos :{} caracteres'. format(len(vocab)))\n","print(vocab)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["el texto tiene longitud de:505098 caracteres\n","el texto esta compuesto de estos :63 caracteres\n","['\\n', ' ', '!', '\"', '&', '(', ')', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '\\\\', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '¡', '¿', 'á', 'é', 'í', 'ñ', 'ó', 'ú', 'ü', '“']\n"]}]},{"cell_type":"markdown","metadata":{"id":"xPUI-QIDy7Mm"},"source":["##P2. pasar el texto a números\n","\n","---\n","as redes neuronales solo procesan valores numéricos, no letras, por tanto tenemos que traducir los caracteres a representación numérica. Para ello crearemos dos “tablas de traducción”: una de caracteres a números y otra de números a caracteres"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YUZb1tLVzIke","executionInfo":{"status":"ok","timestamp":1635980027520,"user_tz":300,"elapsed":805,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"042e6718-a492-4c3c-98d6-2145b73665c8"},"source":["char2idx = {u:i for i, u in enumerate(vocab)} # asignamos un número a cada vocablo\n","idx2char = np.array(vocab)\n","#-----------revisando las conversiones\n","#for char,_ in zip(char2idx, range(len(vocab))):\n","#    print(' {:4s}: {:3d},'.format(repr(char),char2idx[char]))\n","\n","#pasamos todo el texto a números\n","texto_como_entero= np.array([char2idx[c] for c in texto])\n","print('texto: {}'.format(repr(texto[:100])))\n","print('{}'.format(repr(texto_como_entero[:100])))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["texto: ' \\n \\n \\n \\n \\n \\n \\n \\n  \\n \\nhenry r. haggard \\n \\n \\n \\n \\n \\n \\nlas minas del rey salomón \\n   \\n  \\n  \\n   \\n   \\n    '\n","array([ 1,  0,  1,  0,  1,  0,  1,  0,  1,  0,  1,  0,  1,  0,  1,  0,  1,\n","        1,  0,  1,  0, 34, 31, 40, 44, 51,  1, 44,  9,  1, 34, 27, 33, 33,\n","       27, 44, 30,  1,  0,  1,  0,  1,  0,  1,  0,  1,  0,  1,  0,  1,  0,\n","       38, 27, 45,  1, 39, 35, 40, 27, 45,  1, 30, 31, 38,  1, 44, 31, 51,\n","        1, 45, 27, 38, 41, 39, 59, 40,  1,  0,  1,  1,  1,  0,  1,  1,  0,\n","        1,  1,  0,  1,  1,  1,  0,  1,  1,  1,  0,  1,  1,  1,  1])\n"]}]},{"cell_type":"markdown","metadata":{"id":"kIT7JzLG4LIs"},"source":["##P3. preparar los datos para ser usados en la RNN"]},{"cell_type":"code","metadata":{"id":"ky_cT7xN4OiO","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1635980032059,"user_tz":300,"elapsed":550,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"4342e2bb-2c6b-4f75-e509-b5436a36ef58"},"source":["char_dataset= tf.data.Dataset.from_tensor_slices(texto_como_entero)\n","#cantidad de secuencia de caracteres\n","secu_length=150\n","#creamos secuencias de maximo 100 caractereres\n","secuencias= char_dataset.batch(secu_length+1, drop_remainder=True)\n","for item in secuencias.take(10):\n","  print(repr(''.join(idx2char[item.numpy()])))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["' \\n \\n \\n \\n \\n \\n \\n \\n  \\n \\nhenry r. haggard \\n \\n \\n \\n \\n \\n \\nlas minas del rey salomón \\n   \\n  \\n  \\n   \\n   \\n    introducción \\n   \\n   \\n    ahora que este libro está'\n","' impreso y a punto de salir al mundo, ejerce sobre mí un \\nenorme peso la conciencia de sus defectos, tanto de estilo como de contenido. en lo \\nreferent'\n","'e a este último, sólo puedo decir que no pretende ser una relación exhaustiva de \\ntodo lo que vimos e hicimos. hay muchas cosas concernientes a nuestro'\n","' viaje a \\nkukuanalandia en las que me hubiese gustado explayarme y a las que, de hecho, apenas \\naludo. entre ellas se encuentran las curiosas leyendas '\n","'que recogí sobre las armaduras \\nque nos salvaron de la muerte en la gran batalla de loo, y también sobre los silenciosos \\no colosos de la entrada de la'\n","' cueva de estalactitas. por otra parte, si me hubiera dejado \\nllevar por mis inclinaciones, me habría gustado ahondar en las diferencias, algunas de \\nl'\n","'as cuales me resultan muy sugestivas, entre los dialectos zulú y kukuana. asimismo, \\ntambién se hubieran podido dedicar unas cuantas páginas de provech'\n","'o al estudio de la \\nflora y la fauna indígenas de kukuanalandia1. \\n  pero aún queda un tema muy interesante, por cierto, y al que, de hecho, sólo se al'\n","'ude \\nde forma fortuita: el magnífico sistema de organización militar imperante en ese país \\nque, en mi opinión, es muy superior al instaurado por chaka'\n","' en zululandia, en cuanto \\nque permite una movilización más rápida, y no precisa del empleo del pernicioso \\nsistema de celibato obligatorio. y, finalme'\n"]}]},{"cell_type":"markdown","metadata":{"id":"Xz5cEwf6_bpv"},"source":["###P3.1 separar los datos en agrupamientos (batches)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-l6Tobzz7hww","executionInfo":{"status":"ok","timestamp":1635980067837,"user_tz":300,"elapsed":314,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"d627479b-a237-421c-9fa7-4214a0e69ce7"},"source":["#funcion para obtener el conjunto de datos de trainning\n","def split_input_target(chunk):\n","  input_text = chunk[:-1]\n","  target_text= chunk[1:]\n","  return input_text, target_text\n","\n","dataset  = secuencias.map(split_input_target)\n","#el dataset contiene un conjunto de parejas de secuencia de texto\n","#(con la representación numérica de los caracteres), donde el \n","#primer componente de la pareja contiene un paquete con una secuencia \n","#de 100 caracteres del texto original y la segunda su correspondiente salida, \n","#también de 100 caracteres. )\n","for input_example, target_example in dataset.take(1):\n","  print('input data: ', repr(''.join(idx2char[input_example.numpy()])))\n","  print('Target data: ', repr(''.join(idx2char[target_example.numpy()])))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["input data:  ' \\n \\n \\n \\n \\n \\n \\n \\n  \\n \\nhenry r. haggard \\n \\n \\n \\n \\n \\n \\nlas minas del rey salomón \\n   \\n  \\n  \\n   \\n   \\n    introducción \\n   \\n   \\n    ahora que este libro est'\n","Target data:  '\\n \\n \\n \\n \\n \\n \\n \\n  \\n \\nhenry r. haggard \\n \\n \\n \\n \\n \\n \\nlas minas del rey salomón \\n   \\n  \\n  \\n   \\n   \\n    introducción \\n   \\n   \\n    ahora que este libro está'\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8UM54Sfe9x80","executionInfo":{"status":"ok","timestamp":1635980074999,"user_tz":300,"elapsed":5,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"920f1947-9830-48b5-fb7e-21e90c546491"},"source":["#imprimimos el tensor del dataset\n","print(dataset)\n","#Hyper-Parametros para entrenamiento  de una rede neuronal \n","#   -los datos se agrupan en batch\n","BATCH_SIZE= 64\n","#    -Tamaño de memoria disponible \n","BUFFER_SIZE=10000\n","dataset= dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n","print (dataset)\n","#En el tensor dataset disponemos los datos de entrenamiento\n","#con agrupamienttos (batches) compuestos de 64 parejas de secuencias \n","#de 100 integers de 64 bits que representan el carácter correspondiente \n","#en el vocabulario."],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<MapDataset shapes: ((150,), (150,)), types: (tf.int64, tf.int64)>\n","<BatchDataset shapes: ((64, 150), (64, 150)), types: (tf.int64, tf.int64)>\n"]}]},{"cell_type":"markdown","metadata":{"id":"kDFFru4s_jon"},"source":["##P4.Construcción del modelo RNN\n","\n","---\n","Para construir el modelo usaremos tf.keras.Sequential. Usaremos una versión mínima de RNN, que contenga solo una capa LSTM y 3 capas.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ox_5lKZh_qUN","executionInfo":{"status":"ok","timestamp":1635980084366,"user_tz":300,"elapsed":697,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"d282a291-f8cb-4592-d55a-a246f51de308"},"source":["def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n","  #creando el modelo\n","  model = tf.keras.Sequential([\n","    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n","                              batch_input_shape=[batch_size, None]),\n","    tf.keras.layers.LSTM(rnn_units,\n","                         return_sequences=True,\n","                         stateful=True,\n","                         recurrent_initializer='glorot_uniform'),\n","    tf.keras.layers.Dense(vocab_size)                               \n","  ])\n","  return model\n","vocab_size= len(vocab)\n","#dimensiones de los vectores que tendrá la capa.\n","embedding_dim= 256\n","#cantidad de neuronas\n","rnn_units=1024\n","#creamos nuestra red neuronal RNN\n","model=build_model(vocab_size=vocab_size,\n","                  embedding_dim=embedding_dim,\n","                  rnn_units=rnn_units,\n","                  batch_size=BATCH_SIZE)\n","#summary()para visualizar la estructura del modelo\n","model.summary()\n","#resultados=\n","#    -La capa LSTM consta más de 5 millones de parametros)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_3\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","embedding (Embedding)        (64, None, 256)           16128     \n","_________________________________________________________________\n","lstm_3 (LSTM)                (64, None, 1024)          5246976   \n","_________________________________________________________________\n","dense_3 (Dense)              (64, None, 63)            64575     \n","=================================================================\n","Total params: 5,327,679\n","Trainable params: 5,327,679\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","metadata":{"id":"qK5LScoLEdlu"},"source":["##P4. Entrenando la RNN"]},{"cell_type":"code","metadata":{"id":"nxBZdhbJFAKM"},"source":["#como es un problema de clasificación estándar \n","#para el que debemos definir la función de Lossy el optimizador.\n","def loss(labels, logits):\n","  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n","\n","#En cuanto al optimizador usaremos tf.keras.optimizers.Adam \n","#con los argumentos por defecto del optimizador Adam.  \n","model.compile(optimizer='adam',loss=loss)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"dPnll1ubFvZO"},"source":["###P4.1 Creando chekpoints\n","\n","---\n","una técnica de tolerancia de fallos para procesos cuyo tiempo de ejecución es muy largo. La idea es guardar una instantánea del estado del sistema periódicamente para recuperar desde ese punto la ejecución en caso de fallo del sistema.\n"]},{"cell_type":"code","metadata":{"id":"XbeXxiWLF5hN"},"source":["checkpoint_dir='/content/checkpointV2'\n","checkpoint_prefix= os.path.join(checkpoint_dir,\"ckpt_{epoch}\")\n","\n","checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n","    filepath=checkpoint_prefix,\n","    save_weights_only=True\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"trmMLMjxGjuP"},"source":["###P4.2 entrenando"]},{"cell_type":"code","metadata":{"id":"jcLIbeJjGmDF"},"source":["EPOCHS=500\n","history=model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])\n","#model.fit(X, y, epochs=50, batch_size=64, callbacks=callbacks_list)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FnIbqMyqzrWU"},"source":["##P5. Generando texto nuevo usando la RNN"]},{"cell_type":"code","metadata":{"id":"1vGr7GvUzwxg"},"source":["model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n","model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n","model.build(tf.TensorShape([1,None]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CvoSiWWp2_H-"},"source":["#funcion para generar texto\n","def generate_text(model, start_string):\n","  #definimos cuantos tensores\n","  num_generate=500\n","  #convertimos el texto en números\n","  input_eval=[char2idx[s] for s in start_string]\n","  input_eval= tf.expand_dims (input_eval,0)\n","  text_generated = []\n","\n","  temperature = 0.5  \n","  #entre más alta la temperatura más creatividad al modelo, pero tambien\n","  #más errores ortograficos.\n","  model.reset_states()\n","  #bucle para generar caracteres, mediante predicciones\n","  for i in range(num_generate):\n","    predictions = model(input_eval)\n","    predictions = tf.squeeze(predictions, 0)\n","    predictions = predictions / temperature\n","    predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n","    input_eval= tf.expand_dims([predicted_id],0)\n","    text_generated.append (idx2char[predicted_id])\n","  \n","  return (start_string+ ''.join(text_generated))\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZFfQ5EiP4ghF"},"source":["###P5.1 generando texto "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BkLdbX724kBy","executionInfo":{"status":"ok","timestamp":1622509236087,"user_tz":300,"elapsed":2585,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"df4664a0-3277-46bb-a33d-6bc144a7fd0b"},"source":["print(generate_text(model, start_string=u\"la colonia europea\"))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["estirpe britanicador \n","en la atroumizado autor inversabe el foso de la maÃ±ana, \n","que el regimiento terrible no me gusta falla no podÃ­amos distinguir las cazadoras \n","de todos los hombres blancos a la mandÃ­bula con un hombre alto, de mayer, es de su parte, si es que \n","llegasticio estÃ¡bamos lispuas por su tipo con un suspiro de alivio, y \n","no podÃ­amos seguir por allÃ­, a menos que debÃ­amos peser la amplia avenida cuya \n","con una cabaÃ±a al que comercial atrÃ¡s, fero no podÃ­amos \n","recibir la larga y aplanada su filtr\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"T-3PF45LpJBS"},"source":["##P6.exportando modelo"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5_BJSb-7pL7B","executionInfo":{"status":"ok","timestamp":1622502315077,"user_tz":300,"elapsed":202,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"a64ada82-f7ca-4567-e7eb-ac912d264dca"},"source":["from keras.models import model_from_json\n","import os\n","# Serializamos el modelo en forma JSON\n","model_json = model.to_json()\n","with open(\"modelRNN_cuentosV2.json\", \"w\") as json_file:\n","    json_file.write(model_json)\n","# serialize weights to HDF5\n","model.save_weights(\"/content/modelRNN_cuentosV2_pesos.hdf5\")\n","model.save('modelRNN_cuentosV2.h5')\n","print(\"modelo salvado en disco\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n","modelo salvado en disco\n"],"name":"stdout"}]}]}