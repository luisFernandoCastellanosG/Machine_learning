{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"P2_2_PLN_redes neuronales recurrentes (RNN).ipynb","provenance":[],"collapsed_sections":["k6zNNLvrPR1f","FshwyfFykB_4","uIkOBKGAP0y-","ZFfQ5EiP4ghF"],"mount_file_id":"1TYtgx4tMtOsiYhI5wZr-vVyMDdojfLj9","authorship_tag":"ABX9TyN2P1FyFSQpiHCOQxGxIkrr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"w8jPcr-tb-a5"},"source":["#P0. Introducción -PLN\n","\n","---\n","\n","En la creación de redes neuronales necesitamos dos tipos de IA, para reconocer patrones o generar nuevos:\n","\n","*   Las que no tienen memoria, identifica el patrón y ya!...ejemplo las de visión artificial\n","*   Las de memoria corta (Long Short Term Memory)...PLN\n","*   Las que requieren mucha memoria (aprenden casi todo...BERT)...PLN y visión artificial.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"NyasC25K4L-Y"},"source":["**Caso de estudio: generación de texto**\n","\n","---\n","\n","\n","Cualquier dato que se necesite procesar (sonido, imágenes, texto) primero debe ser convertido en un tensor numérico, un paso llamado “vectorización” (One-hot Encoding y WordEmbedding) de datos (y en nuestro ejemplo previamente las letras deben ser pasadas a valores numéricos "]},{"cell_type":"markdown","metadata":{"id":"u1OVaNED56Fz"},"source":["Para este ejemplo usaremos “*Character level language model*” propuesto por Andrej Karpathy en su artículo \"*The Unreasonable Effectiveness of Recurrent Neural Networks*\"(y parcialmente basado en su implementado en el tutorial \"*Generate text with an RNN*\" de la web de TensorFlow:\n","\n","Consiste en darle a la RNN una palabra y se le pide que modele la distribución de probabilidad del siguiente carácter que le correspondería a la secuencia de caracteres anteriores:\n","\n","Como ejemplo, supongamos que solo tenemos un vocabulario de cuatro letras posibles [“a”,”h”,”l”,”o”], y queremos entrenar a una RNN en la secuencia de entrenamiento “hola”. Esta secuencia de entrenamiento es, de hecho, una fuente de 3 ejemplos de entrenamiento por separado: La probabilidad de “o” debería ser verosímil dada el contexto de “h”, “l” debería ser verosímil en el contexto de “ho”, y finalmente “a” debería ser también verosímil dado el contexto de “hol”.\n","\n","\n","---\n","*   https://unipython.com/generacion-de-textos-con-inteligencia-artificial/\n","*    https://medium.com/analytics-vidhya/solution-to-tensorflow-2-not-using-gpu-119fb3e04daa (https://www.youtube.com/watch?v=kaQCdv46OBA&ab_channel=JeffHeaton)"]},{"cell_type":"markdown","metadata":{"id":"k6zNNLvrPR1f"},"source":["#EJEMPLO 1: Prediciendo un texto (cuento los tres cerditos)."]},{"cell_type":"code","metadata":{"id":"znb5-a_wR2Bs"},"source":["!kill -9 -1 #reiniciando la maquina virtual"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MVxWwESyPWDg"},"source":["##P0. importando librerias"]},{"cell_type":"markdown","metadata":{"id":"Vl0r6XTg4Jj7"},"source":["###Librerias genericas"]},{"cell_type":"code","metadata":{"id":"P-gVYOjJ4h_W"},"source":["!pip list"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"97eE8L5n4dxZ"},"source":["import requests\n","import io\n","import os\n","\n","import numpy as np\n","import sys\n","\n","#librerías para graficar\n","import matplotlib.pyplot as plt\n","                 \n","plt.rcParams['figure.figsize'] = (16, 9)  #ver graficas grandes \n","plt.style.use('ggplot')\n","#guardar las imagenes y tablas en el cuaderno de jupyter\n","%matplotlib inline "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IQc-WNUY5QhI"},"source":["###librerias para DL (Deep Learning)"]},{"cell_type":"code","metadata":{"id":"gcCanSaNPY4Y"},"source":["import tensorflow as tf"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ABOLhv9Y5Fuf","executionInfo":{"status":"ok","timestamp":1637116330539,"user_tz":300,"elapsed":192,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"4b78932f-bd05-4ace-af09-2296446414ee"},"source":["print(\"Version: \", tf.__version__)\n","print(\"Eager mode: \", tf.executing_eagerly())\n","print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Version:  2.7.0\n","Eager mode:  True\n","GPU is available\n"]}]},{"cell_type":"markdown","metadata":{"id":"ZcwUPBdNy8w_"},"source":["Verificando los recursos de maquina para entrenar:\n","\n","---\n","**CUDA (GPU-NVIDIA):**\n","CUDA es una plataforma de computación paralela y un modelo de programación que hace que el uso de una GPU para la computación de propósito general sea simple y elegante"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6SJ4g06UyoZR","executionInfo":{"status":"ok","timestamp":1637116334174,"user_tz":300,"elapsed":562,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"b4313fb7-a855-4e70-b949-48b23aafcb55"},"source":["print(\"-------------------------------RAM------------------------------\")\n","!cat /proc/meminfo  #cuanta memoria tenemos?\n","print(\"-----------------------------PROCESADOR-------------------------\")\n","!cat /proc/cpuinfo  # que procesador tenemos?\n","print(\"-------------------------------CUDA-----------------------------\")\n","!nvcc -V   # version de CUDA"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["-------------------------------RAM------------------------------\n","MemTotal:       13302924 kB\n","MemFree:         5359492 kB\n","MemAvailable:   11806300 kB\n","Buffers:          158832 kB\n","Cached:          6054876 kB\n","SwapCached:            0 kB\n","Active:          1648628 kB\n","Inactive:        5785084 kB\n","Active(anon):     946916 kB\n","Inactive(anon):     4576 kB\n","Active(file):     701712 kB\n","Inactive(file):  5780508 kB\n","Unevictable:           0 kB\n","Mlocked:               0 kB\n","SwapTotal:             0 kB\n","SwapFree:              0 kB\n","Dirty:               948 kB\n","Writeback:             0 kB\n","AnonPages:       1219896 kB\n","Mapped:           716384 kB\n","Shmem:              5340 kB\n","KReclaimable:     290536 kB\n","Slab:             347908 kB\n","SReclaimable:     290536 kB\n","SUnreclaim:        57372 kB\n","KernelStack:        5968 kB\n","PageTables:        11388 kB\n","NFS_Unstable:          0 kB\n","Bounce:                0 kB\n","WritebackTmp:          0 kB\n","CommitLimit:     6651460 kB\n","Committed_AS:    4670444 kB\n","VmallocTotal:   34359738367 kB\n","VmallocUsed:       47852 kB\n","VmallocChunk:          0 kB\n","Percpu:             1448 kB\n","AnonHugePages:         0 kB\n","ShmemHugePages:        0 kB\n","ShmemPmdMapped:        0 kB\n","FileHugePages:         0 kB\n","FilePmdMapped:         0 kB\n","CmaTotal:              0 kB\n","CmaFree:               0 kB\n","HugePages_Total:       0\n","HugePages_Free:        0\n","HugePages_Rsvd:        0\n","HugePages_Surp:        0\n","Hugepagesize:       2048 kB\n","Hugetlb:               0 kB\n","DirectMap4k:      252736 kB\n","DirectMap2M:     8132608 kB\n","DirectMap1G:     7340032 kB\n","-----------------------------PROCESADOR-------------------------\n","processor\t: 0\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 63\n","model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2299.998\n","cache size\t: 46080 KB\n","physical id\t: 0\n","siblings\t: 2\n","core id\t\t: 0\n","cpu cores\t: 1\n","apicid\t\t: 0\n","initial apicid\t: 0\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n","bogomips\t: 4599.99\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","processor\t: 1\n","vendor_id\t: GenuineIntel\n","cpu family\t: 6\n","model\t\t: 63\n","model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n","stepping\t: 0\n","microcode\t: 0x1\n","cpu MHz\t\t: 2299.998\n","cache size\t: 46080 KB\n","physical id\t: 0\n","siblings\t: 2\n","core id\t\t: 0\n","cpu cores\t: 1\n","apicid\t\t: 1\n","initial apicid\t: 1\n","fpu\t\t: yes\n","fpu_exception\t: yes\n","cpuid level\t: 13\n","wp\t\t: yes\n","flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 avx2 smep bmi2 erms invpcid xsaveopt arat md_clear arch_capabilities\n","bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs\n","bogomips\t: 4599.99\n","clflush size\t: 64\n","cache_alignment\t: 64\n","address sizes\t: 46 bits physical, 48 bits virtual\n","power management:\n","\n","-------------------------------CUDA-----------------------------\n","nvcc: NVIDIA (R) Cuda compiler driver\n","Copyright (c) 2005-2020 NVIDIA Corporation\n","Built on Mon_Oct_12_20:09:46_PDT_2020\n","Cuda compilation tools, release 11.1, V11.1.105\n","Build cuda_11.1.TC455_06.29190527_0\n"]}]},{"cell_type":"markdown","metadata":{"id":"Tkeq57R55V-W"},"source":["###Activando la GPU\n","\n","---\n","Logra aumentar la velocidad de entrenamiento en un 600% en PLN (RNN) y un 1000% en visión por computadores (CNN)\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vieZASeN5KHd","executionInfo":{"status":"ok","timestamp":1637116351895,"user_tz":300,"elapsed":286,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"22757aa9-eeca-4445-eda2-4dcd2735c88d"},"source":["tf.device('/GPU:0')# OJO: esto es para que tensorflow utilice la GPU (aumenta la velocidad de entrenamiento en un 600%) "],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.eager.context._EagerDeviceContext at 0x7f512205ce10>"]},"metadata":{},"execution_count":27}]},{"cell_type":"markdown","metadata":{"id":"JjQUc0jjQVLR"},"source":["\n","##P1. Descarga y preprocesado de los datos"]},{"cell_type":"code","metadata":{"id":"2d5wzxaBQW40","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637116356469,"user_tz":300,"elapsed":226,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"733447a2-e923-46fa-ce3b-f730b78206a6"},"source":["fileUrl     ='https://raw.githubusercontent.com/luisFernandoCastellanosG/Machine_learning/master/DeepLearning/PLN/Datasets/Panel_Txt_Files/Tres_cerditos.txt'\n","fileContent = tf.keras.utils.get_file('Tres_cerditos.txt',fileUrl)\n","texto       = open(fileContent, 'rb').read().decode(encoding='utf-8')\n","raw_text    = texto.lower()\n","print(raw_text)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://raw.githubusercontent.com/luisFernandoCastellanosG/Machine_learning/master/DeepLearning/PLN/Datasets/Panel_Txt_Files/Tres_cerditos.txt\n","16384/3231 [========================================================================================================================================================] - 0s 0us/step\n","había una vez tres cerditos que eran hermanos y se fueron por el mundo a conseguir fortuna. el más grande les dijo a sus hermanos que sería bueno que se pusieran a construir sus propias casas para estar protegidos. a los otros dos les pareció una buena idea, y se pusieron manos a la obra, cada uno construyó su casita.  - la mía será de paja - dijo el más pequeño-, la paja es blanda y se puede sujetar con facilidad. terminaré muy pronto y podré ir a jugar. el hermano mediano decidió que su casa sería de madera:  - puedo encontrar un montón de madera por los alrededores - explicó \n","a sus hermanos, - construiré mi casa en un santiamén con todos estos troncos y me iré también a jugar.  cuando las tres casitas estuvieron terminadas, los cerditos cantaban y bailaban en la puerta, felices por haber acabado con el problema:  -¡quién teme al lobo feroz, al lobo, al lobo!  - ¡quién teme al lobo feroz, al lobo feroz! detrás de un árbol grande apareció el lobo, rugiendo de hambre y gritando:  - cerditos, ¡me los voy a comer! cada uno se escondió en su casa, pensando que estaban a salvo, pero el lobo feroz se encaminó a la casita de paja del hermano pequeño y en la puerta aulló:  - ¡cerdito, ábreme la puerta!  - no, no, no, no te voy a abrir. - pues si no me abres... ¡soplaré y soplaré y la casita derribaré! y sopló con todas sus fuerzas, sopló y sopló y la casita de paja se vino abajo. el cerdito pequeño corrió lo más rápido que pudo y entró en la casa de madera del hermano mediano. - ¡quién teme al lobo feroz, al lobo, al lobo!  - ¡quién teme al lobo feroz, al lobo feroz! - cantaban desde dentro los cerditos.  de nuevo el lobo, más enfurecido que antes al sentirse engañado, se colocó delante de la puerta y comenzó a soplar y soplar gruñendo: - ¡cerditos, abridme la puerta! - no, no, no, no te vamos a abrir. - pues si no me abrís... \n","¡soplaré y soplaré y la casita derribaré! la madera crujió, y las paredes cayeron y los dos cerditos corrieron a refugiarse en la casa de ladrillo de su hermano mayor.  - ¡quién teme al lobo feroz, al lobo, al lobo!  - ¡quién teme al lobo feroz, al lobo feroz! - cantaban desde dentro los cerditos. el lobo estaba realmente enfadado y hambriento, y ahora deseaba comerse a los tres cerditos más que nunca, y frente a la puerta dijo:  - ¡cerditos, abridme la puerta! - no, no, no, no te vamos a abrir.  - pues si no me abrís... ¡soplaré y soplaré y la casita derribaré!  y se puso a soplar tan fuerte como el viento de invierno. sopló y sopló, pero la casita de ladrillos era muy resistente y no conseguía derribarla. decidió trepar por la pared y entrar por la chimenea. se deslizó hacia abajo... y cayó en el caldero donde el cerdito mayor estaba hirviendo sopa de nabos. escaldado y con el estómago vacío salió huyendo hacia el lago. los cerditos no lo volvieron a ver.  el mayor de ellos regañó a los otros dos por haber sido tan perezosos y poner en peligro sus propias vidas, y si algún día vais por el bosque y veis tres cerdos, sabréis que son los tres cerditos porque les gusta cantar:  - ¡quién teme al lobo feroz, al lobo, al lobo!  - ¡quién teme al lobo feroz, al lobo feroz!\n"]}]},{"cell_type":"markdown","metadata":{"id":"ikT-PEFlRc7y"},"source":["##P2. pasar el texto a números\n","\n","---\n","Sin importan el origen de la informacción (video, sonido, sensor, texto)...siempre debemos convertirlos en datos númericos.\n"]},{"cell_type":"code","metadata":{"id":"16uNdDlRRg4O","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637116359271,"user_tz":300,"elapsed":195,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"6e659676-4a62-4276-b155-29d92eb8241c"},"source":["chars = sorted(list(set(raw_text)))\n","char_to_int = dict((c, i) for i, c in enumerate(chars))\n","print(chars)\n","print(char_to_int)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["['\\n', '\\r', ' ', '!', ',', '-', '.', ':', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'x', 'y', 'z', '¡', 'á', 'é', 'í', 'ñ', 'ó', 'ú']\n","{'\\n': 0, '\\r': 1, ' ': 2, '!': 3, ',': 4, '-': 5, '.': 6, ':': 7, 'a': 8, 'b': 9, 'c': 10, 'd': 11, 'e': 12, 'f': 13, 'g': 14, 'h': 15, 'i': 16, 'j': 17, 'l': 18, 'm': 19, 'n': 20, 'o': 21, 'p': 22, 'q': 23, 'r': 24, 's': 25, 't': 26, 'u': 27, 'v': 28, 'x': 29, 'y': 30, 'z': 31, '¡': 32, 'á': 33, 'é': 34, 'í': 35, 'ñ': 36, 'ó': 37, 'ú': 38}\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xU_SXe5JSXT0","executionInfo":{"status":"ok","timestamp":1637116361519,"user_tz":300,"elapsed":260,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"ebca3863-c71d-4722-ac7b-3e607328fd7f"},"source":["n_chars = len(raw_text)\n","n_vocab = len(chars)\n","print(\"En total hay %d caracteres, y el diccionario tiene un tamaño de %d caracteres.\" % (n_chars, n_vocab))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["En total hay 3141 caracteres, y el diccionario tiene un tamaño de 39 caracteres.\n"]}]},{"cell_type":"markdown","metadata":{"id":"0ucpDS5lTgKB"},"source":["###P2.1 Dividimos el texto en secuencias:\n","---\n","Dividimos el texto en estas secuencias (adrede), convertimos los caracteres a números enteros usando nuestra tabla de búsqueda que preparamos anteriormente\n","\n"]},{"cell_type":"code","metadata":{"id":"QdJi9bHtTI46"},"source":["# preparar el conjunto de datos de los pares de entrada a salida codificados como enteros\n","seq_length = 50   #largo de las secciones de texto que usaremos para entrenar\n","dataX = []\n","dataY = []\n","for i in range(0, n_chars - seq_length, 1):\n","\tprint(\"Seq(\",i,\")=\",raw_text[i:i + seq_length],\"---->\",raw_text[i + seq_length])\n","\tseq_in \t= raw_text[i:i + seq_length]         \t\t\t\t\t#secuencia de entrada\n","\tseq_out = raw_text[i + seq_length]\t\t\t\t\t\t\t\t\t\t#siguiente letra despues de la secuencia (la que el va a aprender)\n","\tdataX.append([char_to_int[char] for char in seq_in])  # convertimos cada secuencia en numeros\n","\tdataY.append(char_to_int[seq_out])\n","n_patterns = len(dataX)\n","print (\"Se generaron \",format(n_patterns) ,\" secuencias texto de un tamaño de \",seq_length,\" caracteres\" )\n","print(\"Como se ven los datos de X convertidos a números\\n\")\n","print(dataX)\n","print(\"\\nComo se ven los datos de Y convertidos a números\\n\")\n","print(dataY)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZBlU-qNzVOO7"},"source":["##P3. preparar nuestros datos de entrenamiento\n","\n","---\n","\n","\n","1.   Primero debemos transformar la lista de secuencias de entrada en la forma [muestras, pasos de tiempo, características] esperada por una red LSTM.\n","2.   Luego debemos cambiar la escala de los números enteros al rango de 0 a 1 para que los patrones sean más fáciles de aprender mediante la red LSTM que utiliza la función de activación sigmoidea de forma predeterminada.\n","3.   por ultimo necesitamos convertir los patrones de salida (caracteres individuales convertidos en enteros) en una codificación one hot. Esto es para que podamos configurar la red para predecir la probabilidad de cada uno de los 54 caracteres diferentes en el vocabulario (una representación más fácil)\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"GbY1cgrHVSjC"},"source":["#transformar la lista X de secuencias de entrada en la forma [muestras (3091), pasos de tiempo, características]\n","X = np.reshape(dataX, (n_patterns, seq_length, 1))\n","# normalizar (cambiar la escala de los números enteros al rango de 0 a 1 )\n","X = X / float(n_vocab)\n","# convertir los patrones de salida (caracteres individuales convertidos en enteros) en una codificación one hot.\n","y = tf.keras.utils.to_categorical(dataY)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ekQyJUbvWvpZ"},"source":["##P4.Construcción del modelo RNN\n","\n","---\n","definimos nuestro modelo LSTM: \n","Aquí definimos una única capa LSTM oculta con 256 unidades de memoria. La red usa deserción con una probabilidad de 20. La capa de salida es una capa densa que usa la función de activación softmax para generar una predicción de probabilidad para cada uno de los 54 caracteres entre 0 y 1.\n"]},{"cell_type":"code","metadata":{"id":"8sjIOgf8XE_g"},"source":["# define the LSTM model\n","\n","model = tf.keras.models.Sequential()\n","model.add(tf.keras.layers.LSTM(256, input_shape=(X.shape[1], X.shape[2])))    #creamos una capa con 256 unidades de memoria\n","model.add(tf.keras.layers.Dropout(0.2))\n","model.add(tf.keras.layers.Dense(y.shape[1], activation='softmax'))            #Softmax convierte un vector de valores en una distribución de probabilidad para cada uno de los 39\n","                                                                              #Softmax se utiliza a menudo como la activación para la última capa de una red de clasificación\n","#utilizamos el algoritmo de optimización de ADAM para la velocidad\n","model.compile(loss='categorical_crossentropy', optimizer='adam')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4h3kjfw4XikQ"},"source":["###P4.1 Creando chekpoints\n","\n","---\n","\n","La red es lenta de entrenar (alrededor de 300 segundos por época) teniendo activa la GPU, ASí que crearemos CHECKPOINTS (puntos de control) para registrar todos los pesos de la red para archivar cada vez que se observe una mejora en la pérdida al final de la época. Usaremos el mejor conjunto de pesos (menor pérdida) para instanciar nuestro modelo generativo en la siguiente sección"]},{"cell_type":"code","metadata":{"id":"DcvIQPOHXzYL"},"source":["# definimos  una carpeta para guardar los checkpoint\n","filepath=\"checkpoints/weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n","checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n","callbacks_list = [checkpoint]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FczzMAAEX-6h"},"source":["###P4.2 entrenando"]},{"cell_type":"code","metadata":{"id":"HPSD1VSHYAJH"},"source":["history = model.fit(X, y, epochs=1000, batch_size=128, verbose=1,callbacks=callbacks_list)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WWfRY8pPYMYp"},"source":["##P5.Generando texto con una red LSTM\n","\n","\n","---\n","Vamos a cargar el ultimo CHECKPOINT de entrenamiento y con el haremos MAGIA!!!\n"]},{"cell_type":"code","metadata":{"id":"ngH34tw2YVB6"},"source":["filename = \"/content/checkpoints/weights-improvement-940-0.0035.hdf5\"\n","model.load_weights(filename)\n","model.compile(loss='categorical_crossentropy', optimizer='adam')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CoKm0kDwY5XG"},"source":["###P5.1 mapeo inverso (números a letras)\n","creamos un mapeo inverso que podamos usar para convertir los números enteros nuevamente en caracteres para que podamos entender las predicciones"]},{"cell_type":"code","metadata":{"id":"pEuAaVxpY-ro"},"source":["int_to_char = dict((i, c) for i, c in enumerate(chars))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9R9T2vJ6ZU9t"},"source":["###P5.2 hacer predicciones\n","La forma más sencilla de utilizar el modelo Keras LSTM para hacer predicciones es comenzar primero con una secuencia semilla como entrada, generar el siguiente carácter y luego actualizar la secuencia semilla para agregar el carácter generado al final y recortar el primer carácter. Este proceso se repite mientras queramos predecir nuevos caracteres (por ejemplo, una secuencia de 1000 caracteres de longitud)."]},{"cell_type":"code","metadata":{"id":"YEJmnxm6ZenD","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636418326400,"user_tz":300,"elapsed":45964,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"88615165-ad29-4ace-a667-56cfa944c24e"},"source":["# elige una semilla al azar\n","start = np.random.randint(0, len(dataX)-1)\n","pattern = dataX[start]\n","print (\"Semilla:\")\n","print (\"\\\"\" + \" \".join([int_to_char[value] for value in pattern])+\"\\\"\")\n","# generación de 10000 caracteres\n","for i in range(1000):\n","\tx = np.reshape(pattern, (1, len(pattern), 1))\n","\tx = x / float(n_vocab)\n","\tprediction = model.predict(x, verbose=0)\n","\tindex = np.argmax(prediction)\n","\tresult = int_to_char[index]\n","\tseq_in = [int_to_char[value] for value in pattern]\n","\tsys.stdout.write(result)\n","\tpattern.append(index)\n","\tpattern = pattern[1:len(pattern)]\n","print (\"\\nDone.\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Semilla:\n","\"v e z   t r e s   c e r d i t o s   q u e   e r a n   h e r m a n o s   y   s e   f u e r o n   p o\"\n","r el mundo a conseguir fortuna. el más grande les dijo a sus hermanos que sería bueno que se pusieran a construir sus propias casas para estar protegidos. a los otros dos les pareció una buena idea, y se pusieron manos a la obra, cada uno construyó su casita.  - la mía será de paja - dijo el más pequeño-, la paja es blanda y se puede sujetar con facilidad. terminaré muy pronto y podré ir a jugar. el hermano mediano decidió que su casa sería de madera:  - puedo encontrar un montón de madera por los alrededores - explicó \n","a sus hermanos, - construiré mi casa en un santiamén con todos estos troncos y me iré también a jugar.  cuando las tres casitas estuvieron terminadas, los cerditos cantaban y bailaban en la puerta, felices por haber acabado con el problema:  -¡quién teme al lobo feroz, al lobo, al lobo!  - ¡quién teme al lobo feroz, al lobo feroz! - cantaban desde dentro los cerditos.  de nuevo el lobo, más enfurecido que antes al sentirse engañado, se colocó delante de la puerta y com\n","Done.\n"]}]},{"cell_type":"markdown","metadata":{"id":"TRh4YwjBVmvx"},"source":["##P6.Mejorando la red (una LSTM más grande)"]},{"cell_type":"code","metadata":{"id":"7z5w5CleVu6j"},"source":["model = tf.keras.models.Sequential()\n","model.add(tf.keras.layers.LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n","model.add(tf.keras.layers.Dropout(0.2))\n","model.add(tf.keras.layers.LSTM(256))                                                                #agregaremos una segunda capa. \n","model.add(tf.keras.layers.Dropout(0.2))\n","model.add(tf.keras.layers.Dense(y.shape[1], activation='softmax'))\n","\n","\n","model.compile(loss='categorical_crossentropy', optimizer='adam')\n","#cambiamos el nombre de archivo de los pesos con puntos de control para que \n","#podamos distinguir entre los pesos de esta red \n","filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zGLMqyQvWRRv"},"source":["###P6.1 mejoramos el entrenamiento\n","\n","---\n","aumentamos las epoch y disminuiremos el tamaño del lote de 128 a 64 para darle a la red más oportunidades de actualizarse y aprender.\n"]},{"cell_type":"code","metadata":{"id":"9kjWAw-JWVce"},"source":["#los tiempos de entrenamiento aumentaran al doble que en la versión anterior\n","model.fit(X, y, epochs=50, batch_size=32, callbacks=callbacks_list)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-TOM8C2_Y2To"},"source":["###P6.2 haciendo predicciones"]},{"cell_type":"code","metadata":{"id":"gFEPBYrxY5xq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1636419000907,"user_tz":300,"elapsed":54679,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"e9b78448-ce76-4cd0-8a1f-b429acb879cb"},"source":["# elige una semilla al azar\n","start = np.random.randint(0, len(dataX)-1)\n","pattern = dataX[start]\n","print (\"Semilla:\")\n","print (\"\\\"\" + \" \".join([int_to_char[value] for value in pattern])+\"\\\"\")\n","# generación de caracteres\n","for i in range(1000):\n","\tx = np.reshape(pattern, (1, len(pattern), 1))\n","\tx = x / float(n_vocab)\n","\tprediction = model.predict(x, verbose=0)\n","\tindex = np.argmax(prediction)\n","\tresult = int_to_char[index]\n","\tseq_in = [int_to_char[value] for value in pattern]\n","\tsys.stdout.write(result)\n","\tpattern.append(index)\n","\tpattern = pattern[1:len(pattern)]\n","print (\"\\nDone.\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Semilla:\n","\"  \r \n"," a   s u s   h e r m a n o s ,   -   c o n s t r u i r é   m i   c a s a   e n   u n   s a n t\"\n","iamén con todos estos troncos y me iré también a jugar.  cuando las tres casitas estuvieron terminadas, los cerditos cantaban y bailaban en la puerta, felices por haber acabado con el problema:  -¡quién teme al lobo feroz, al lobo, al lobo!  - ¡quién teme al lobo feroz, al lobo feroz! - cantaban desde dentro los cerditos.  de nuevo el lobo, más enfurecido que antes al sentirse engañado, se colocó delante de la puerta y comenzó a soplar y soplar gruñendo: - ¡cerditos, abridme la puerta! - no, no, no, no te vamos a abrir.    pues si no me abrís... ¡soplaré y soplaré y la casita derribaré! y sopló con todas sus fuerzas, sopló y sopló,y la casita de paja se vino abajo. el cerdito pequeño corrió lo más rápido que pudo y entró en la casa de madera del hermano mediano. - ¡quién teme al lobo feroz, al lobo, al lobo!  - ¡quién teme al lobo feroz, al lobo feroz! - cantaban desde dentro los cerditos.  de nuevo el lobo, más enfurecido que antes al sentirse engañado, se colocó delante de la puerta \n","Done.\n"]}]},{"cell_type":"markdown","metadata":{"id":"Dz7aR7_eiYGg"},"source":["##P7. exportar modelo RNN"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tU7_ao0Ciibo","executionInfo":{"status":"ok","timestamp":1622500072815,"user_tz":300,"elapsed":3367,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"596d0ff6-72d5-48d9-f689-b693ccaaf5e0"},"source":["!pip install h5py"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (3.1.0)\n","Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from h5py) (1.5.2)\n","Requirement already satisfied: numpy>=1.14.5; python_version == \"3.7\" in /usr/local/lib/python3.7/dist-packages (from h5py) (1.19.5)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rbuFNARNisdA","executionInfo":{"status":"ok","timestamp":1622500500948,"user_tz":300,"elapsed":212,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"3b123e4c-3ee0-4ab1-abf6-ec822b06ce06"},"source":["from keras.models import model_from_json\n","import os\n","# Serializamos el modelo en forma JSON\n","model_json = model.to_json()\n","with open(\"modelRNN_cuentos.json\", \"w\") as json_file:\n","    json_file.write(model_json)\n","# serialize weights to HDF5\n","model.save_weights(\"/content/modeloRNN_cuentosPesos.hdf5\")\n","model.save('modelRNN_cuentos_v_h5.h5')\n","print(\"modelo salvado en disco\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["modelo salvado en disco\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"FshwyfFykB_4"},"source":["###P7.1 cargando un modelo"]},{"cell_type":"code","metadata":{"id":"X2BD6XFKkEmg"},"source":["# Recrea exactamente el mismo modelo solo desde el archivo\n","new_model = keras.models.load_model('/content/modelRNN_cuentos_v_h5.h5')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bjz0OYUYlO2B","executionInfo":{"status":"ok","timestamp":1622501076929,"user_tz":300,"elapsed":188,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"6f9bfd2d-5a1f-4aaa-ab5a-5ca0e29e5b69"},"source":["chars = sorted(list(set(\"comiendo una manzana\")))\n","char_to_int = dict((c, i) for i, c in enumerate(chars))\n","n_chars = len(raw_text)\n","n_vocab = len(chars)\n","print(\"En total hay %d caracteres, y el diccionario tiene un tamaño de %d caracteres.\" % (n_chars, n_vocab))\n","pattern = dataX[5]\n","print(pattern)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["En total hay 55827 caracteres, y el diccionario tiene un tamaño de 11 caracteres.\n","[6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 18, 16, 31, 20, 33, 36, 18, 24, 35, 16, 2, 33, 30, 25, 16, 1, 0, 23, 16, 17, 50, 16, 2, 36, 29, 16, 2, 37, 20, 41, 2, 36, 29, 16, 2, 19, 36, 27, 18, 20, 2, 29, 24, 51, 16, 2, 32, 36, 20, 2, 32, 36, 20, 33, 50, 16, 2, 28, 36, 18, 23, 30, 2, 16, 2, 34, 36, 2, 28, 16, 19, 33, 20, 2, 40, 2, 16, 2, 34, 36, 2, 16, 17, 36]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P5z_PSwlkoGg","executionInfo":{"status":"ok","timestamp":1622500663951,"user_tz":300,"elapsed":37810,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"45395bc3-0a94-41dc-d597-4ab05158e8b8"},"source":["start = numpy.random.randint(0, len(dataX)-1)\n","pattern = dataX[start]\n","print (\"Semilla:\")\n","print (\"\\\"\" + \" \".join([int_to_char[value] for value in pattern])+\"\\\"\")\n","# generación de caracteres\n","for i in range(1000):\n","\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n","\tx = x / float(n_vocab)\n","\tprediction = new_model.predict(x, verbose=0)\n","\tindex = numpy.argmax(prediction)\n","\tresult = int_to_char[index]\n","\tseq_in = [int_to_char[value] for value in pattern]\n","\tsys.stdout.write(result)\n","\tpattern.append(index)\n","\tpattern = pattern[1:len(pattern)]\n","print (\"\\nDone.\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Semilla:\n","\"n t e m p l a r   l a s   f l o r e s ,   q u e   c o m e n z a b a n   a   l l e n a r l o   t o d o .   a l l í   v i o   e n   e l   e s t a n q u e   d o s   d e   a q u e l l o s   p á j a r o s\"\n"," sue a la belle y con la boca abierta, lus amlgos de la casa de los piratas, el pey y el gato com su camino de la casa de su harfio, el príncipe juan, pirocho y la reñora darling se quedó hacia ella.\n","y se precó ticme que el cartillo y se puedó hacia la casa de su harta que se encontraban en el estuvendo conmigo y sodos que el carciici y se puedó hacia ella.\n","el patito se sintió delta en palacio, pero el hombre de jengibre corrió más rápido. en la cocina de la casa de los piratas, el peys de noche y la reñora darling se quedó hacia la casa de los piratas,\n","una teca a tu padre la boca abierta dl la casa y algo suppirar y al canbio, estaba muy bueno y poder vup hijas de podenas del príncipe pue al verla. se acuirtió cnn un cama y deseruer a la princesa y lls piratas a la princesa y la peianta de la casa de los piratas dontarcados y acabó por ella. pero se enco lueha a uu paradi y comenzaron que se encontraba\n","Done.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5X8cLamkWi52"},"source":["\n","\n","---\n","\n","\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"eHu5fIzX9Xlp"},"source":["#Ejemplo 2: generar texto de cuentos, usando Keras"]},{"cell_type":"markdown","metadata":{"id":"O5WVmMwYt7Uk"},"source":["##P0. importar librerias"]},{"cell_type":"code","metadata":{"id":"CJdVpcLu7R7y"},"source":["!pip install tensorflow-gpu"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tGa1tvf5t5r4","executionInfo":{"status":"ok","timestamp":1637177114004,"user_tz":300,"elapsed":2910,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}}},"source":["import tensorflow as tf\n","import numpy as np\n","import os\n","import time\n","import sys"],"execution_count":1,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZYzaL8aex1Lz"},"source":["uso de GPU para entrenar en tensorflow\n","\n","---\n","https://medium.com/analytics-vidhya/solution-to-tensorflow-2-not-using-gpu-119fb3e04daa\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DXlRSrBJrK9T","executionInfo":{"status":"ok","timestamp":1637177135288,"user_tz":300,"elapsed":896,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"5d2468a5-cdc3-4895-f3a0-80b07384ac56"},"source":["print(\"Version: \", tf.__version__)\n","#print(\"Eager mode: \", tf.executing_eagerly())\n","print(\"GPU esta\", \"disponible\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")\n","print(\"Dispositivos disponibles: \", tf.config.list_physical_devices())"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Version:  2.7.0\n","GPU esta disponible\n","Dispositivos disponibles:  [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E9E2ihO2rLjM","executionInfo":{"status":"ok","timestamp":1637177145956,"user_tz":300,"elapsed":351,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"92ef632b-1214-4602-eea6-3786a0e611d3"},"source":["#tf.device('/gpu:0') #activando la CPU\n","tf.device('/GPU:0') #activando la GPU "],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.eager.context._EagerDeviceContext at 0x7fa2b6876730>"]},"metadata":{},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"9Ot0vNyP9jlQ"},"source":["##P0. Descarga y preprocesado de los datos"]},{"cell_type":"code","metadata":{"id":"6PETkDFl3Mff","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637177225930,"user_tz":300,"elapsed":609,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"18e46bbb-3879-4f47-81db-0b012afdf6ce"},"source":["fileDL= tf.keras.utils.get_file('LasMinasDelReySalomon.txt','https://raw.githubusercontent.com/luisFernandoCastellanosG/Machine_learning/master/DeepLearning/PLN/Datasets/Panel_Txt_Files/LasMinasDelReySalomon.txt')\n","texto = open(fileDL, 'rb').read().decode(encoding='utf-8')\n","texto = texto.lower()"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://raw.githubusercontent.com/luisFernandoCastellanosG/Machine_learning/master/DeepLearning/PLN/Datasets/Panel_Txt_Files/LasMinasDelReySalomon.txt\n","516096/515495 [==============================] - 0s 0us/step\n","524288/515495 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"markdown","metadata":{"id":"i-Qr24Chypjd"},"source":["##P1. entendiendo el texto"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TpxHpVkcys57","executionInfo":{"status":"ok","timestamp":1637177236686,"user_tz":300,"elapsed":445,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"f425666f-17b1-4b56-838c-3956e8afb492"},"source":["print('el texto tiene longitud de:{} caracteres'. format(len(texto)))\n","vocab = sorted(set(texto))\n","print('el texto esta compuesto de estos :{} caracteres'. format(len(vocab)))\n","print(vocab)"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["el texto tiene longitud de:505098 caracteres\n","el texto esta compuesto de estos :63 caracteres\n","['\\n', ' ', '!', '\"', '&', '(', ')', ',', '-', '.', '/', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', ';', '?', '\\\\', '_', '`', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '¡', '¿', 'á', 'é', 'í', 'ñ', 'ó', 'ú', 'ü', '“']\n"]}]},{"cell_type":"markdown","metadata":{"id":"xPUI-QIDy7Mm"},"source":["##P2. pasar el texto a números\n","\n","---\n","as redes neuronales solo procesan valores numéricos, no letras, por tanto tenemos que traducir los caracteres a representación numérica. Para ello crearemos dos “tablas de traducción”: una de caracteres a números y otra de números a caracteres"]},{"cell_type":"code","metadata":{"id":"YUZb1tLVzIke","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1637177244773,"user_tz":300,"elapsed":498,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"ccaa9d4c-e515-40e0-b284-811b8342ca98"},"source":["char2idx = {u:i for i, u in enumerate(vocab)} # asignamos un número a cada vocablo\n","idx2char = np.array(vocab)\n","#-----------revisando las conversiones\n","#for char,_ in zip(char2idx, range(len(vocab))):\n","#    print(' {:4s}: {:3d},'.format(repr(char),char2idx[char]))\n","\n","#pasamos todo el texto a números\n","texto_como_entero= np.array([char2idx[c] for c in texto])\n","print('texto: {}'.format(repr(texto[:100])))\n","print('{}'.format(repr(texto_como_entero[:100])))"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["texto: ' \\n \\n \\n \\n \\n \\n \\n \\n  \\n \\nhenry r. haggard \\n \\n \\n \\n \\n \\n \\nlas minas del rey salomón \\n   \\n  \\n  \\n   \\n   \\n    '\n","array([ 1,  0,  1,  0,  1,  0,  1,  0,  1,  0,  1,  0,  1,  0,  1,  0,  1,\n","        1,  0,  1,  0, 34, 31, 40, 44, 51,  1, 44,  9,  1, 34, 27, 33, 33,\n","       27, 44, 30,  1,  0,  1,  0,  1,  0,  1,  0,  1,  0,  1,  0,  1,  0,\n","       38, 27, 45,  1, 39, 35, 40, 27, 45,  1, 30, 31, 38,  1, 44, 31, 51,\n","        1, 45, 27, 38, 41, 39, 59, 40,  1,  0,  1,  1,  1,  0,  1,  1,  0,\n","        1,  1,  0,  1,  1,  1,  0,  1,  1,  1,  0,  1,  1,  1,  1])\n"]}]},{"cell_type":"markdown","metadata":{"id":"kIT7JzLG4LIs"},"source":["##P3. preparar los datos para ser usados en la RNN"]},{"cell_type":"code","metadata":{"id":"ky_cT7xN4OiO"},"source":["char_dataset= tf.data.Dataset.from_tensor_slices(texto_como_entero)\n","#cantidad de secuencia de caracteres\n","secu_length=150\n","#creamos secuencias de maximo 100 caractereres\n","secuencias= char_dataset.batch(secu_length+1, drop_remainder=True)\n","for item in secuencias.take(10):\n","  print(repr(''.join(idx2char[item.numpy()])))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Xz5cEwf6_bpv"},"source":["###P3.1 separar los datos en agrupamientos (batches)"]},{"cell_type":"code","metadata":{"id":"-l6Tobzz7hww"},"source":["#funcion para obtener el conjunto de datos de trainning\n","def split_input_target(chunk):\n","  input_text = chunk[:-1]\n","  target_text= chunk[1:]\n","  return input_text, target_text\n","\n","dataset  = secuencias.map(split_input_target)\n","#el dataset contiene un conjunto de parejas de secuencia de texto\n","#(con la representación numérica de los caracteres), donde el \n","#primer componente de la pareja contiene un paquete con una secuencia \n","#de 100 caracteres del texto original y la segunda su correspondiente salida, \n","#también de 100 caracteres. )\n","for input_example, target_example in dataset.take(1):\n","  print('input data: ', repr(''.join(idx2char[input_example.numpy()])))\n","  print('Target data: ', repr(''.join(idx2char[target_example.numpy()])))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8UM54Sfe9x80","executionInfo":{"status":"ok","timestamp":1637177273917,"user_tz":300,"elapsed":485,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"e97beab5-3b8a-4dcb-e297-19458c115f30"},"source":["#imprimimos el tensor del dataset\n","print(dataset)\n","#Hyper-Parametros para entrenamiento  de una rede neuronal \n","#   -los datos se agrupan en batch\n","BATCH_SIZE= 64\n","#    -Tamaño de memoria disponible \n","BUFFER_SIZE=10000\n","dataset= dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n","print (dataset)\n","#En el tensor dataset disponemos los datos de entrenamiento\n","#con agrupamienttos (batches) compuestos de 64 parejas de secuencias \n","#de 100 integers de 64 bits que representan el carácter correspondiente \n","#en el vocabulario."],"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["<MapDataset shapes: ((150,), (150,)), types: (tf.int64, tf.int64)>\n","<BatchDataset shapes: ((64, 150), (64, 150)), types: (tf.int64, tf.int64)>\n"]}]},{"cell_type":"markdown","metadata":{"id":"kDFFru4s_jon"},"source":["##P4.Construcción del modelo RNN\n","\n","---\n","Para construir el modelo usaremos tf.keras.Sequential. Usaremos una versión mínima de RNN, que contenga solo una capa LSTM y 3 capas.\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ox_5lKZh_qUN","executionInfo":{"status":"ok","timestamp":1637183314694,"user_tz":300,"elapsed":556,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"a724c847-9011-42ba-a543-a645acff261c"},"source":["#como es un problema de clasificación estándar \n","#para el que debemos definir la función de Lossy el optimizador.\n","def lossy(labels, logits):\n","  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n","\n","def create_model(vocab_size, embedding_dim, rnn_units, batch_size):\n","  #creando el modelo\n","  model = tf.keras.Sequential([\n","    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n","                              batch_input_shape=[batch_size, None]),\n","    tf.keras.layers.LSTM(rnn_units,\n","                         return_sequences=True,\n","                         stateful=True,\n","                         recurrent_initializer='glorot_uniform'),\n","    tf.keras.layers.Dense(vocab_size)                               \n","  ])\n","  #En cuanto al optimizador usaremos tf.keras.optimizers.Adam \n","  #con los argumentos por defecto del optimizador Adam. \n","  model.compile(optimizer='adam',\n","              loss=lossy,\n","              metrics=['accuracy'])\n","  return model\n","vocab_size= len(vocab)\n","#dimensiones de los vectores que tendrá la capa.\n","embedding_dim= 256\n","#cantidad de neuronas\n","rnn_units=1024\n","#creamos nuestra red neuronal RNN\n","model=create_model(vocab_size   =vocab_size,\n","                  embedding_dim =embedding_dim,\n","                  rnn_units     =rnn_units,\n","                  batch_size    =BATCH_SIZE)\n","#summary()para visualizar la estructura del modelo\n","model.summary()\n","#resultados=  -La capa LSTM consta más de 5 millones de parametros)"],"execution_count":74,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_16\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_16 (Embedding)    (64, None, 256)           16128     \n","                                                                 \n"," lstm_16 (LSTM)              (64, None, 1024)          5246976   \n","                                                                 \n"," dense_16 (Dense)            (64, None, 63)            64575     \n","                                                                 \n","=================================================================\n","Total params: 5,327,679\n","Trainable params: 5,327,679\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}]},{"cell_type":"markdown","metadata":{"id":"dPnll1ubFvZO"},"source":["###P4.1 Creando chekpoints\n","\n","---\n","una técnica de tolerancia de fallos para procesos cuyo tiempo de ejecución es muy largo. La idea es guardar una instantánea del estado del sistema periódicamente para recuperar desde ese punto la ejecución en caso de fallo del sistema.\n","\n","---\n","los crearemos en google drive para mejorar la capacidad de reentrenamiento de la red\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L24WhqeauMWk","executionInfo":{"status":"ok","timestamp":1637177397137,"user_tz":300,"elapsed":113256,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"1036649d-e2d4-40c1-839f-5fc6b855e3bd"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","metadata":{"id":"XbeXxiWLF5hN","colab":{"base_uri":"https://localhost:8080/","height":53},"executionInfo":{"status":"ok","timestamp":1637183605693,"user_tz":300,"elapsed":445,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"e6a96b5f-5e3f-4e31-993c-e5196dee4654"},"source":["checkpoint_dir='/content/gdrive/MyDrive/Colab Notebooks/P2_Deep_Learning/PLN/Redes neuronales recurrentes (RNN)/checkpointsV3/'\n","checkpoint_prefix= os.path.join(checkpoint_dir,\"cp_{epoch:04d}.ckpt\")\n","\n","\n","cp_callback=tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix,\n","                                               monitor='loss',\n","                                               verbose=1,\n","                                               save_weights_only=True,\n","                                               save_best_only=True,\n","                                               mode='auto')\n"],"execution_count":78,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_prefix, \\n                                                 save_best_only=True, \\n                                                 save_weights_only=True, \\n                                                 verbose=1)'"]},"metadata":{},"execution_count":78}]},{"cell_type":"markdown","metadata":{"id":"trmMLMjxGjuP"},"source":["###P4.2 entrenando"]},{"cell_type":"markdown","metadata":{"id":"LPXvQuLrQEAF"},"source":["####P4.2a entrenando para usar chekpoints"]},{"cell_type":"code","metadata":{"id":"9l5cnXgLQI7H"},"source":["EPOCHS=10\n","history=model.fit(dataset, \n","                  epochs=EPOCHS, \n","                  verbose=1,\n","                  callbacks=[cp_callback])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"URtG1ZI0L99C"},"source":["\n","#####4.2a-1 entrenando desde un checkpoint\n","\n","---\n","Desde la carpeta que optamos guardar los checkpoints\n","\n","*   el archivo .data es el archivo que contiene nuestras variables de entrenamiento y vamos a ir tras él.\n","*   el archivo checkpoint, simplemente mantiene un registro de los últimos archivos de punto de control guardados\n","\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8o4h9cq8ac68","executionInfo":{"status":"ok","timestamp":1637184188696,"user_tz":300,"elapsed":950,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"983ea428-1e23-49cd-ba18-f0eb34776ebe"},"source":["#creamos un modelo con iguales caracteristicas al 1° modelo\n","model2=create_model(vocab_size   =vocab_size,\n","                  embedding_dim =embedding_dim,\n","                  rnn_units     =rnn_units,\n","                  batch_size    =BATCH_SIZE)\n","\n","#buscamos el ultimo checkpoint de entrenamiento\n","latest = tf.train.latest_checkpoint(checkpoint_dir)\n","print(latest)"],"execution_count":80,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/Colab Notebooks/P2_Deep_Learning/PLN/Redes neuronales recurrentes (RNN)/checkpointsV3/cp_0030.ckpt\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CGZCz4W3lkWa","executionInfo":{"status":"ok","timestamp":1637185856233,"user_tz":300,"elapsed":521003,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"f8fd4d8b-64ae-44f8-bc59-4a3721fd0832"},"source":["# cargamos los pesos al nuevo modelo (estos valores tienes una variación de un 10%)\n","model2.load_weights(latest)\n","# continuamos el entrenamiento desde el checkpoint en que quedamos\n","history_V2=model2.fit(dataset, \n","                    epochs=100, \n","                    verbose=1,\n","                    callbacks=[cp_callback])"],"execution_count":81,"outputs":[{"output_type":"stream","name":"stdout","text":["52/52 [==============================] - ETA: 0s - loss: 0.1592 - accuracy: 0.9704\n","Epoch 00069: loss improved from 0.15941 to 0.15917, saving model to /content/gdrive/MyDrive/Colab Notebooks/P2_Deep_Learning/PLN/Redes neuronales recurrentes (RNN)/checkpointsV3/cp_0069.ckpt\n","52/52 [==============================] - 14s 247ms/step - loss: 0.1592 - accuracy: 0.9704\n","Epoch 70/100\n","52/52 [==============================] - ETA: 0s - loss: 0.1612 - accuracy: 0.9702\n","Epoch 00070: loss did not improve from 0.15917\n","52/52 [==============================] - 13s 240ms/step - loss: 0.1612 - accuracy: 0.9702\n","Epoch 71/100\n","52/52 [==============================] - ETA: 0s - loss: 0.1610 - accuracy: 0.9702\n","Epoch 00071: loss did not improve from 0.15917\n","52/52 [==============================] - 13s 241ms/step - loss: 0.1610 - accuracy: 0.9702\n","Epoch 72/100\n","52/52 [==============================] - ETA: 0s - loss: 0.1605 - accuracy: 0.9703\n","Epoch 00072: loss did not improve from 0.15917\n","52/52 [==============================] - 13s 240ms/step - loss: 0.1605 - accuracy: 0.9703\n","Epoch 73/100\n","52/52 [==============================] - ETA: 0s - loss: 0.1607 - accuracy: 0.9706\n","Epoch 00073: loss did not improve from 0.15917\n","52/52 [==============================] - 13s 241ms/step - loss: 0.1607 - accuracy: 0.9706\n","Epoch 74/100\n","52/52 [==============================] - ETA: 0s - loss: 0.1604 - accuracy: 0.9704\n","Epoch 00074: loss did not improve from 0.15917\n","52/52 [==============================] - 13s 243ms/step - loss: 0.1604 - accuracy: 0.9704\n","Epoch 75/100\n","52/52 [==============================] - ETA: 0s - loss: 0.1583 - accuracy: 0.9705\n","Epoch 00075: loss improved from 0.15917 to 0.15834, saving model to /content/gdrive/MyDrive/Colab Notebooks/P2_Deep_Learning/PLN/Redes neuronales recurrentes (RNN)/checkpointsV3/cp_0075.ckpt\n","52/52 [==============================] - 14s 246ms/step - loss: 0.1583 - accuracy: 0.9705\n","Epoch 76/100\n","52/52 [==============================] - ETA: 0s - loss: 0.1582 - accuracy: 0.9709\n","Epoch 00076: loss improved from 0.15834 to 0.15816, saving model to /content/gdrive/MyDrive/Colab Notebooks/P2_Deep_Learning/PLN/Redes neuronales recurrentes (RNN)/checkpointsV3/cp_0076.ckpt\n","52/52 [==============================] - 14s 248ms/step - loss: 0.1582 - accuracy: 0.9709\n","Epoch 77/100\n","52/52 [==============================] - ETA: 0s - loss: 0.1566 - accuracy: 0.9711\n","Epoch 00077: loss improved from 0.15816 to 0.15662, saving model to /content/gdrive/MyDrive/Colab Notebooks/P2_Deep_Learning/PLN/Redes neuronales recurrentes (RNN)/checkpointsV3/cp_0077.ckpt\n","52/52 [==============================] - 14s 247ms/step - loss: 0.1566 - accuracy: 0.9711\n","Epoch 78/100\n","52/52 [==============================] - ETA: 0s - loss: 0.1551 - accuracy: 0.9715\n","Epoch 00078: loss improved from 0.15662 to 0.15514, saving model to /content/gdrive/MyDrive/Colab Notebooks/P2_Deep_Learning/PLN/Redes neuronales recurrentes (RNN)/checkpointsV3/cp_0078.ckpt\n","52/52 [==============================] - 14s 249ms/step - loss: 0.1551 - accuracy: 0.9715\n","Epoch 79/100\n","52/52 [==============================] - ETA: 0s - loss: 0.1567 - accuracy: 0.9710\n","Epoch 00079: loss did not improve from 0.15514\n","52/52 [==============================] - 13s 241ms/step - loss: 0.1567 - accuracy: 0.9710\n","Epoch 80/100\n","52/52 [==============================] - ETA: 0s - loss: 0.1556 - accuracy: 0.9714\n","Epoch 00080: loss did not improve from 0.15514\n","52/52 [==============================] - 13s 242ms/step - loss: 0.1556 - accuracy: 0.9714\n","Epoch 81/100\n","52/52 [==============================] - ETA: 0s - loss: 0.1560 - accuracy: 0.9715\n","Epoch 00081: loss did not improve from 0.15514\n","52/52 [==============================] - 13s 242ms/step - loss: 0.1560 - accuracy: 0.9715\n","Epoch 82/100\n","52/52 [==============================] - ETA: 0s - loss: 0.1542 - accuracy: 0.9715\n","Epoch 00082: loss improved from 0.15514 to 0.15422, saving model to /content/gdrive/MyDrive/Colab Notebooks/P2_Deep_Learning/PLN/Redes neuronales recurrentes (RNN)/checkpointsV3/cp_0082.ckpt\n","52/52 [==============================] - 14s 246ms/step - loss: 0.1542 - accuracy: 0.9715\n","Epoch 83/100\n","52/52 [==============================] - ETA: 0s - loss: 0.1551 - accuracy: 0.9713\n","Epoch 00083: loss did not improve from 0.15422\n","52/52 [==============================] - 14s 243ms/step - loss: 0.1551 - accuracy: 0.9713\n","Epoch 84/100\n","52/52 [==============================] - ETA: 0s - loss: 0.1520 - accuracy: 0.9718\n","Epoch 00084: loss improved from 0.15422 to 0.15204, saving model to /content/gdrive/MyDrive/Colab Notebooks/P2_Deep_Learning/PLN/Redes neuronales recurrentes (RNN)/checkpointsV3/cp_0084.ckpt\n","52/52 [==============================] - 14s 246ms/step - loss: 0.1520 - accuracy: 0.9718\n","Epoch 85/100\n","52/52 [==============================] - ETA: 0s - loss: 0.1526 - accuracy: 0.9716\n","Epoch 00085: loss did not improve from 0.15204\n","52/52 [==============================] - 13s 241ms/step - loss: 0.1526 - accuracy: 0.9716\n","Epoch 86/100\n","52/52 [==============================] - ETA: 0s - loss: 0.1523 - accuracy: 0.9715\n","Epoch 00086: loss did not improve from 0.15204\n","52/52 [==============================] - 13s 240ms/step - loss: 0.1523 - accuracy: 0.9715\n","Epoch 87/100\n","52/52 [==============================] - ETA: 0s - loss: 0.1532 - accuracy: 0.9715\n","Epoch 00087: loss did not improve from 0.15204\n","52/52 [==============================] - 13s 242ms/step - loss: 0.1532 - accuracy: 0.9715\n","Epoch 88/100\n","52/52 [==============================] - ETA: 0s - loss: 0.1528 - accuracy: 0.9717\n","Epoch 00088: loss did not improve from 0.15204\n","52/52 [==============================] - 13s 240ms/step - loss: 0.1528 - accuracy: 0.9717\n","Epoch 89/100\n","52/52 [==============================] - ETA: 0s - loss: 0.1504 - accuracy: 0.9719\n","Epoch 00089: loss improved from 0.15204 to 0.15042, saving model to /content/gdrive/MyDrive/Colab Notebooks/P2_Deep_Learning/PLN/Redes neuronales recurrentes (RNN)/checkpointsV3/cp_0089.ckpt\n","52/52 [==============================] - 14s 246ms/step - loss: 0.1504 - accuracy: 0.9719\n","Epoch 90/100\n","52/52 [==============================] - ETA: 0s - loss: 0.1525 - accuracy: 0.9717\n","Epoch 00090: loss did not improve from 0.15042\n","52/52 [==============================] - 13s 242ms/step - loss: 0.1525 - accuracy: 0.9717\n","Epoch 91/100\n","52/52 [==============================] - ETA: 0s - loss: 0.1527 - accuracy: 0.9717\n","Epoch 00091: loss did not improve from 0.15042\n","52/52 [==============================] - 13s 242ms/step - loss: 0.1527 - accuracy: 0.9717\n","Epoch 92/100\n","52/52 [==============================] - ETA: 0s - loss: 0.1530 - accuracy: 0.9715\n","Epoch 00092: loss did not improve from 0.15042\n","52/52 [==============================] - 13s 241ms/step - loss: 0.1530 - accuracy: 0.9715\n","Epoch 93/100\n","52/52 [==============================] - ETA: 0s - loss: 0.1524 - accuracy: 0.9717\n","Epoch 00093: loss did not improve from 0.15042\n","52/52 [==============================] - 13s 241ms/step - loss: 0.1524 - accuracy: 0.9717\n","Epoch 94/100\n","52/52 [==============================] - ETA: 0s - loss: 0.1511 - accuracy: 0.9719\n","Epoch 00094: loss did not improve from 0.15042\n","52/52 [==============================] - 13s 242ms/step - loss: 0.1511 - accuracy: 0.9719\n","Epoch 95/100\n","52/52 [==============================] - ETA: 0s - loss: 0.1509 - accuracy: 0.9719\n","Epoch 00095: loss did not improve from 0.15042\n","52/52 [==============================] - 14s 244ms/step - loss: 0.1509 - accuracy: 0.9719\n","Epoch 96/100\n","52/52 [==============================] - ETA: 0s - loss: 0.1497 - accuracy: 0.9724\n","Epoch 00096: loss improved from 0.15042 to 0.14970, saving model to /content/gdrive/MyDrive/Colab Notebooks/P2_Deep_Learning/PLN/Redes neuronales recurrentes (RNN)/checkpointsV3/cp_0096.ckpt\n","52/52 [==============================] - 14s 247ms/step - loss: 0.1497 - accuracy: 0.9724\n","Epoch 97/100\n","52/52 [==============================] - ETA: 0s - loss: 0.1473 - accuracy: 0.9726\n","Epoch 00097: loss improved from 0.14970 to 0.14733, saving model to /content/gdrive/MyDrive/Colab Notebooks/P2_Deep_Learning/PLN/Redes neuronales recurrentes (RNN)/checkpointsV3/cp_0097.ckpt\n","52/52 [==============================] - 14s 247ms/step - loss: 0.1473 - accuracy: 0.9726\n","Epoch 98/100\n","52/52 [==============================] - ETA: 0s - loss: 0.1489 - accuracy: 0.9723\n","Epoch 00098: loss did not improve from 0.14733\n","52/52 [==============================] - 13s 241ms/step - loss: 0.1489 - accuracy: 0.9723\n","Epoch 99/100\n","52/52 [==============================] - ETA: 0s - loss: 0.1484 - accuracy: 0.9724\n","Epoch 00099: loss did not improve from 0.14733\n","52/52 [==============================] - 13s 241ms/step - loss: 0.1484 - accuracy: 0.9724\n","Epoch 100/100\n","52/52 [==============================] - ETA: 0s - loss: 0.1469 - accuracy: 0.9727\n","Epoch 00100: loss improved from 0.14733 to 0.14690, saving model to /content/gdrive/MyDrive/Colab Notebooks/P2_Deep_Learning/PLN/Redes neuronales recurrentes (RNN)/checkpointsV3/cp_0100.ckpt\n","52/52 [==============================] - 14s 246ms/step - loss: 0.1469 - accuracy: 0.9727\n"]}]},{"cell_type":"markdown","metadata":{"id":"uIkOBKGAP0y-"},"source":["####P4.2b entrenando con tensorboard (opcional)"]},{"cell_type":"markdown","metadata":{"id":"hFDzT0NtUpua"},"source":["#####Activando TENSORBOARD \n","\n","---\n","(DASHBOARD para ver el proceso de entrenamiento)"]},{"cell_type":"code","metadata":{"id":"2x20xRy-UwzZ"},"source":["# You can change the directory name\n","LOG_DIR = '/content/gdrive/MyDrive/Colab Notebooks/P2_Deep_Learning/PLN/Redes neuronales recurrentes (RNN)/checkpoints'\n","\n","!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","!unzip ngrok-stable-linux-amd64.zip\n","\n","import os\n","if not os.path.exists(LOG_DIR):\n","  os.makedirs(LOG_DIR)\n","  \n","get_ipython().system_raw(\n","    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n","    .format(LOG_DIR))\n","\n","get_ipython().system_raw('./ngrok http 6006 &')\n","\n","!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n","    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uJ1L-Vm1ZrTU","executionInfo":{"status":"ok","timestamp":1637027709412,"user_tz":300,"elapsed":186,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"e8e0d6b6-e124-46f1-9ab9-481459318cca"},"source":["tbCallBack = tf.keras.callbacks.TensorBoard(log_dir=LOG_DIR, \n","                         histogram_freq=1,\n","                         write_graph=True,\n","                         write_grads=True,\n","                         batch_size=BATCH_SIZE,\n","                         write_images=True)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:`write_grads` will be ignored in TensorFlow 2.0 for the `TensorBoard` Callback.\n","WARNING:tensorflow:`batch_size` is no longer needed in the `TensorBoard` Callback and will be ignored in TensorFlow 2.0.\n"]}]},{"cell_type":"markdown","metadata":{"id":"SmC4IO8rg5TV"},"source":["#####Fit"]},{"cell_type":"code","metadata":{"id":"jcLIbeJjGmDF"},"source":["\n","#model.fit(X, y, epochs=50, batch_size=64, callbacks=callbacks_list)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FnIbqMyqzrWU"},"source":["##P5. Generando texto nuevo usando la RNN"]},{"cell_type":"code","metadata":{"id":"1vGr7GvUzwxg","executionInfo":{"status":"ok","timestamp":1637186006001,"user_tz":300,"elapsed":1010,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}}},"source":["#creamos un modelo tomando como base el ultimo checkpoint\n","model = build_model(vocab_size, embedding_dim, rnn_units, batch_size=1)\n","model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n","model.build(tf.TensorShape([1,None]))"],"execution_count":84,"outputs":[]},{"cell_type":"code","metadata":{"id":"CvoSiWWp2_H-","executionInfo":{"status":"ok","timestamp":1637186034489,"user_tz":300,"elapsed":353,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}}},"source":["#funcion para generar texto\n","def generate_text(model, start_string):\n","  #definimos cuantos tensores/cantidad de texto generaremos\n","  num_generate=500\n","  #convertimos el texto en números\n","  input_eval=[char2idx[s] for s in start_string]\n","  input_eval= tf.expand_dims (input_eval,0)\n","  text_generated = []\n","\n","  temperature = 0.3  #(0.0 a  1) entre más alta la temperatura más creatividad al modelo, pero tambien más errores ortograficos.\n","  model.reset_states() #bucle para generar caracteres, mediante predicciones\n","  for i in range(num_generate):\n","    predictions = model(input_eval)\n","    predictions = tf.squeeze(predictions, 0)\n","    predictions = predictions / temperature\n","    predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n","    input_eval= tf.expand_dims([predicted_id],0)\n","    text_generated.append (idx2char[predicted_id])\n","  \n","  return (start_string+ ''.join(text_generated))\n"],"execution_count":85,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZFfQ5EiP4ghF"},"source":["###P5.1 generando texto "]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BkLdbX724kBy","executionInfo":{"status":"ok","timestamp":1637186041882,"user_tz":300,"elapsed":4452,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"3e0725c2-918e-4a4a-883d-cf7c2e77b725"},"source":["print(generate_text(model, start_string=u\"la colonia europea\"))"],"execution_count":86,"outputs":[{"output_type":"stream","name":"stdout","text":["la colonia europea, que siguió a los heroísmos de los primeros exploradores, fue \n","acompañado, en otro plano, por la aventura. la aventura personal. en los primeros libros de \n","melancolía, y por extraño que parezca, no nos sentíamos \n","demasiado mal tras la terrible experiencia del valor y atractivo aventurero); y por fin, inevitablemente, \n","una lucha con la muerte, que es a la vez concreta y una alegoría ún que el pueblo kukuana preserva a sus reyes \n","muertos desde tiempo inmemorial. los petrifica. no llegué a descubr\n"]}]},{"cell_type":"markdown","metadata":{"id":"T-3PF45LpJBS"},"source":["##P6.exportando modelo\n","\n","---\n","Guardamos y Serializamos el Modelo (con esto ya podemos vender nuestro modelo de predicción de texto según lo aprendido por nuestra RNN).\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5_BJSb-7pL7B","executionInfo":{"status":"ok","timestamp":1637186491343,"user_tz":300,"elapsed":2212,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"ada6d475-9157-4676-ad1b-ff2baab9c92e"},"source":["from keras.models import model_from_json\n","import os\n","dir_export= '/content/gdrive/MyDrive/Colab Notebooks/P2_Deep_Learning/PLN/Redes neuronales recurrentes (RNN)/Modelos'\n","#dir_export= os.path.join(dir_drive)\n","# Serializamos el modelo en forma JSON\n","model_json = model.to_json()\n","with open(os.path.join(dir_export,'RNN_LasMinasDelReySalomon_json.json'), 'w') as json_file:\n","    json_file.write(model_json)\n","# serialize weights to HDF5\n","model.save_weights(os.path.join(dir_export,'RNN_LasMinasDelReySalomon_pesos.hdf5'))\n","model.save(os.path.join(dir_export,'RNN_LasMinasDelReySalomon_model.h5'))\n","print(\"modelo salvado en Drive de google\")"],"execution_count":95,"outputs":[{"output_type":"stream","name":"stdout","text":["modelo salvado en Drive de google\n"]}]},{"cell_type":"markdown","metadata":{"id":"JfogT546zoDp"},"source":["##P7.Cargando un modelo serializado"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3R11dLzBzwv0","executionInfo":{"status":"ok","timestamp":1637186572079,"user_tz":300,"elapsed":4166,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"9a7ae670-5d53-48bf-a71a-f93245967de0"},"source":["# Recrea exactamente el mismo modelo solo desde el archivo\n","new_model = tf.keras.models.load_model(os.path.join(dir_export,'RNN_LasMinasDelReySalomon_model.h5'))"],"execution_count":97,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Z-rwH5vd0oGc","executionInfo":{"status":"ok","timestamp":1637186590892,"user_tz":300,"elapsed":4394,"user":{"displayName":"Luis Fernando Castellanos Guarin","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiNf725gjhpmPoePk2pKrbFIASNL2N1rVYLatwsNg=s64","userId":"08966922054785833228"}},"outputId":"81b069ba-8016-4751-e05d-52aa2901291a"},"source":["print(generate_text(new_model, start_string=u\"la guerra nos llevo a \"))"],"execution_count":98,"outputs":[{"output_type":"stream","name":"stdout","text":["la guerra nos llevo a cabeza y hacía yo menore de cuarenta yardas de distancia, y su lanza se precipitaron hacia adelante, lanzas en \n","ristre, y los dos regimientos chocaron en terrible contienda. a los pocos segundos llegó la noche anterior, y nosotros, quedamos solos en el \n","escenario, junto al cuerpo muerto de scragga, el aire extraño \n","y desconocida y se uniesen a las nuestras, pero no podíamos contar con esa \n","eventualidad. \n","    entretanto, estaba claro que empezaban a hacer preparativos para sobre la atmósfera no f\n"]}]}]}