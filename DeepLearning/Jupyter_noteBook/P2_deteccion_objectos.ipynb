{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"202001_deteccion_objectos.ipynb","provenance":[],"private_outputs":true,"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"wmaDNlkBRDPP","colab_type":"text"},"source":["# .0. Ejecutar cada vez que se iniciar sesión"]},{"cell_type":"markdown","metadata":{"id":"8AgP-mGkMLzT","colab_type":"text"},"source":["##0.1 Instalar librerias necesarias\n","\n","\n","---\n","debemos hacer este proceso siempre que cerremos la sesión, pues por defecto se inicia con tensorflow=2.2 y necesitamos la 1.15\n"]},{"cell_type":"code","metadata":{"id":"JU7UmHfZao6s","colab_type":"code","colab":{}},"source":["!pip install tensorflow==1.15"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dYpNiRdMSd4Q","colab_type":"code","colab":{}},"source":["!apt-get install -qq protobuf-compiler python-pil python-lxml python-tk #serialización de grafos inferenciales\n","\n","!pip install -q Cython contextlib2 pillow lxml matplotlib  #librerias para visualizar imagenes\n","\n","!pip install -q pycocotools  #para trabajar con unas herramientas de http://cocodataset.org/\n","\n","!pip install -q watermark   #imprimir marcas de fecha y hora, números de versión e información de hardware.\n","\n","#esta libreria es obligatoria desde el 2020/05/28\n","!pip install tf_slim"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"C4yPM8C0SS8v","colab_type":"code","colab":{}},"source":["!python3 --version\n","%load_ext watermark\n","print(\"--Computer vision(hardware)--\")\n","%watermark\n","%watermark -a \"--Computer vision(libraries)--\" -u -d -v -p numpy,tensorflow,pycocotools"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hGp5KzDOQX4N","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"eufJ_MT5brTk","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","device_name = tf.test.gpu_device_name()\n","if device_name != '/device:GPU:0':\n","  print('GPU NO esta activa para el entorno')\n","tf.__version__"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ss-QxfofMYji","colab_type":"text"},"source":["##0.2 habilitar google drive\n","\n","---\n","\n"]},{"cell_type":"code","metadata":{"id":"v0-1PFe6nkYB","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"naaowhg-gGnA","colab_type":"text"},"source":["# .1. Ejecutar solo una vez (cuando se crea el proyecto)\n","\n","---\n","Se van a descargar los repositorios desde GITHUB y se compilan los archivos de configuración"]},{"cell_type":"markdown","metadata":{"id":"LtNX63eBS_qX","colab_type":"text"},"source":["##.1.1 descargar reporsitorio de GITHUB de tensorflow"]},{"cell_type":"code","metadata":{"id":"-CvcSPdPgl0I","colab_type":"code","colab":{}},"source":["#descargamos el repositorio de object_detection que esta en GITHUB\n","%cd /content/gdrive/My\\ Drive/deteccion_objectos\n","!git clone --quiet https://github.com/tensorflow/models.git\n","#cambiamos la variable de entorno para que sea ahora la del repositorio clonado\n","import os\n","os.environ['PYTHONPATH'] += ':/content/gdrive/My Drive/deteccion_objectos/models/research/:/content/gdrive/My Drive/deteccion_objectos/models/research/slim/'\n","#compliamos protos\n","%cd /content/gdrive/My\\ Drive/deteccion_objectos/models/research\n","#compilar protos (generar los archivos .py que van en la carpeta protos/)\n","!protoc object_detection/protos/*.proto --python_out=."],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9LDrdkFmW4th","colab_type":"text"},"source":["##.1.2.Parametros para descargar un grafo inferencia preentrenado\n","\n","\n","---\n","Usaremos el grafo inferencial preentrenado ssd_mobilenet_v2\n"]},{"cell_type":"code","metadata":{"id":"_LjqZBJfZF3T","colab_type":"code","colab":{}},"source":["#variables con las rutas de nuestras dataset de entrenamiento\n","test_record_fname     = '/content/gdrive/My Drive/deteccion_objectos/TFRecords/test.record'\n","train_record_fname    = '/content/gdrive/My Drive/deteccion_objectos/TFRecords/train.record'\n","label_map_pbtxt_fname = '/content/gdrive/My Drive/deteccion_objectos/configuracion/label_map.pbtxt'\n","\n","# número de pasos (epochs) que usaremos para entrenar\n","num_steps = 2000  # 200000\n","\n","# número de evaluaciones por pasos (cada 50 pasos evaluamos el modelo).\n","num_eval_steps = 50\n","\n","# Selecionamos el archivo de configuración del modelo\n","selected_model = 'ssd_mobilenet_v2'\n","\n","MODELS_CONFIG = {\n","    'ssd_mobilenet_v2': {\n","        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n","        'pipeline_file': 'ssd_mobilenet_v2_coco.config',\n","        'batch_size': 12\n","    },\n","    'faster_rcnn_inception_v2': {\n","        'model_name': 'faster_rcnn_inception_v2_coco_2018_01_28',\n","        'pipeline_file': 'faster_rcnn_inception_v2_pets.config',\n","        'batch_size': 12\n","    },\n","    'rfcn_resnet101': {\n","        'model_name': 'rfcn_resnet101_coco_2018_01_28',\n","        'pipeline_file': 'rfcn_resnet101_pets.config',\n","        'batch_size': 8\n","    }\n","}\n","\n","# definimos el tamaño del lote de entrenamiento para uso en la memoria de \n","# la GPU Tesla K80 de Colaborate para el modelo seleccionado.\n","batch_size = MODELS_CONFIG[selected_model]['batch_size']\n","\n","# Nombre del modelo de detección de objectos que usaremos\n","MODEL = MODELS_CONFIG[selected_model]['model_name']\n","\n","# Nombre del archivo de canalización en la API de detección de objetos de tensorflow.\n","pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n","\n","pipeline_fname = os.path.join('/content/gdrive/My Drive/deteccion_objectos/models/research/object_detection/samples/configs/', pipeline_file)\n","print(\"pipeline_fname:\"+pipeline_fname)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZhawEt_Zjhec","colab_type":"text"},"source":["##.1.3. Descargamos el grafo preentreando ssd_mobilenet_v2"]},{"cell_type":"code","metadata":{"id":"hOacIf8eiLcz","colab_type":"code","colab":{}},"source":["# ubicación de la carpeta base\n","%cd /content/gdrive/My\\ Drive/deteccion_objectos/models/research\n","\n","import os\n","import shutil\n","import glob\n","import urllib.request\n","import tarfile\n","MODEL_FILE = MODEL + '.tar.gz'\n","DOWNLOAD_BASE = 'http://download.tensorflow.org/models/object_detection/'\n","\n","# ubicación donde guardaremos el grafo preentrenado que descargamos\n","DEST_DIR = '/content/gdrive/My Drive/deteccion_objectos/models/research/pretrained_model'\n","\n","if not (os.path.exists(MODEL_FILE)):\n","    urllib.request.urlretrieve(DOWNLOAD_BASE + MODEL_FILE, MODEL_FILE)\n","\n","tar = tarfile.open(MODEL_FILE)\n","tar.extractall()\n","tar.close()\n","\n","os.remove(MODEL_FILE)\n","if (os.path.exists(DEST_DIR)):\n","  shutil.rmtree(DEST_DIR)\n","os.rename(MODEL, DEST_DIR)\n","\n","# listamos los archivos descargados\n","!echo $DEST_DIR\n","!ls -alh pretrained_model"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PkS5eIHWj-gZ","colab_type":"text"},"source":["##.1.4 Modificamos el archivo de configuración del grafo\n","\n","---\n","AGregaremos los .records que crearemos más adelante\n"]},{"cell_type":"code","metadata":{"id":"mUes9xifZ2cG","colab_type":"code","colab":{}},"source":["# Nombre del archivo de canalización en la API de detección de objetos de tensorflow.\n","pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n","\n","pipeline_fname = os.path.join('/content/gdrive/My Drive/deteccion_objectos/models/research/object_detection/samples/configs/', pipeline_file)\n","print(\"pipeline_fname:\"+pipeline_fname)\n","\n","fine_tune_checkpoint = os.path.join(DEST_DIR, \"model.ckpt\")\n","fine_tune_checkpoint\n","%cd /content/gdrive/My\\ Drive/deteccion_objectos/models/research"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3pe3NGl1bLiT","colab_type":"text"},"source":["###1.4.1. configurar la canalización en la API de detección de objetos de tensorflow)"]},{"cell_type":"code","metadata":{"id":"OHyUuFxdbgRG","colab_type":"code","colab":{}},"source":["import os\n","\n","assert os.path.isfile(pipeline_fname), '`{}` not exist'.format(pipeline_fname)\n","\n","def get_num_classes(pbtxt_fname):\n","    from object_detection.utils import label_map_util\n","    label_map = label_map_util.load_labelmap(pbtxt_fname)\n","    categories = label_map_util.convert_label_map_to_categories(\n","        label_map, max_num_classes=90, use_display_name=True)\n","    category_index = label_map_util.create_category_index(categories)\n","    return len(category_index.keys())"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RUdszSZvkONt","colab_type":"text"},"source":["###1.4.2.Modificamos el archivo de configuración del grafo con los parametros personalizados de nuestros proyecto."]},{"cell_type":"code","metadata":{"id":"2ykWqdDadAaN","colab_type":"code","colab":{}},"source":["import re\n","\n","num_classes = get_num_classes(label_map_pbtxt_fname)\n","with open(pipeline_fname) as f:\n","    s = f.read()\n","with open(pipeline_fname, 'w') as f:\n","    \n","    # punto de control de inicio\n","    s = re.sub('fine_tune_checkpoint: \".*?\"','fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n","    \n","    # ubicación de los tfrecords de train y test\n","    s = re.sub('(input_path: \".*?)(train.record)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n","    s = re.sub('(input_path: \".*?)(val.record)(.*?\")', 'input_path: \"{}\"'.format(test_record_fname), s)\n","\n","    # ubicación del labelmap.pbtxt\n","    s = re.sub('label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_pbtxt_fname), s)\n","\n","    # Establecemos el tamaño del lote de entrenamiento\n","    s = re.sub('batch_size: [0-9]+','batch_size: {}'.format(batch_size), s)\n","\n","    # Establecemos la cantidad de pasos de entrenamiento\n","    s = re.sub('num_steps: [0-9]+','num_steps: {}'.format(num_steps), s)\n","    \n","    # establecemos el número de clases (etiquetas)\n","    s = re.sub('num_classes: [0-9]+','num_classes: {}'.format(num_classes), s)\n","    f.write(s)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"LlxcUebqe8os","colab_type":"text"},"source":["###.1.4.3.revisamos que todo quede bien"]},{"cell_type":"code","metadata":{"id":"SyZo2SSLe_tv","colab_type":"code","colab":{}},"source":["print(pipeline_fname)\n","!cat pipeline_fname\n","!cat /content/gdrive/My\\ Drive/deteccion_objectos/models/research/object_detection/samples/configs/ssd_mobilenet_v2_coco.config"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"F5_WIiJTKdHL","colab_type":"code","colab":{}},"source":["model_dir = '/content/gdrive/My Drive/deteccion_objectos/models/research/training/'"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"47gkBILKhgEt","colab_type":"text"},"source":["##.1.5.creando los listados csv"]},{"cell_type":"code","metadata":{"id":"4JaXIJPtfI0M","colab_type":"code","colab":{}},"source":["# Convierte los archivos xml que estan en la carpeta de entrenamiento a una lista CSV \n","# y genera el archivo label_map.pbtxt en el directorio configuracion\n","!python /content/gdrive/My\\ Drive/deteccion_objectos/xml_a_csv_v2.py \\\n","--inputDir /content/gdrive/My\\ Drive/deteccion_objectos/img_entrenamiento \\\n","--outputFile /content/gdrive/My\\ Drive/deteccion_objectos/csv/train_labels.csv \\\n","--labelMapDir /content/gdrive/My\\ Drive/deteccion_objectos/configuracion"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"CUNIJx8os5su","colab_type":"code","colab":{}},"source":["# Convierte los archivos xml que estan en la carpeta de test a una lista CSV\n","!python /content/gdrive/My\\ Drive/deteccion_objectos/xml_a_csv_v2.py \\\n","--inputDir /content/gdrive/My\\ Drive/deteccion_objectos/img_test \\\n","--outputFile /content/gdrive/My\\ Drive/deteccion_objectos/csv/test_labels.csv"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BnwkmpQwh214","colab_type":"text"},"source":["##.1.6.creando los TFRecords"]},{"cell_type":"code","metadata":{"id":"EKmWGrPaVhIL","colab_type":"code","colab":{}},"source":["# Generando el archivo  train.record\n","!python /content/gdrive/My\\ Drive/deteccion_objectos/csv_a_tf_v2.py \\\n","--csv_input=/content/gdrive/My\\ Drive/deteccion_objectos/csv/train_labels.csv \\\n","--output_path=/content/gdrive/My\\ Drive/deteccion_objectos/TFRecords/train.record \\\n","--img_path=/content/gdrive/My\\ Drive/deteccion_objectos/img_entrenamiento \\\n","--label_map /content/gdrive/My\\ Drive/deteccion_objectos/configuracion/label_map.pbtxt"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"i_91XRwtHQn7","colab_type":"code","colab":{}},"source":["# Generando el archivo  test.record\n","!python /content/gdrive/My\\ Drive/deteccion_objectos/csv_a_tf_v2.py \\\n","--csv_input /content/gdrive/My\\ Drive/deteccion_objectos/csv/test_labels.csv \\\n","--output_path /content/gdrive/My\\ Drive/deteccion_objectos/TFRecords/test.record \\\n","--img_path /content/gdrive/My\\ Drive/deteccion_objectos/img_test \\\n","--label_map /content/gdrive/My\\ Drive/deteccion_objectos/configuracion/label_map.pbtxt"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2lUQ_Em_gUgA","colab_type":"text"},"source":["#.2. Entrenamiento y reentrenamiento\n","\n","---\n","\n","\n","definiendo variables de entorno"]},{"cell_type":"markdown","metadata":{"id":"TpWtjzf_ZJqx","colab_type":"text"},"source":["##.2.1. parametros para el entrenamiento"]},{"cell_type":"code","metadata":{"id":"rFyAQiKuag9T","colab_type":"code","colab":{}},"source":["import os\n","os.environ['PYTHONPATH'] = '/env/python:/content/gdrive/My Drive/deteccion_objectos/models/research/:/content/gdrive/My Drive/deteccion_objectos/models/research/slim/'\n","#os.environ['PYTHONPATH'] =   '/content/gdrive/My Drive/deteccion_objectos/models/research'\n","#os.environ['PYTHONPATH'] += ':/content/gdrive/My Drive/deteccion_objectos/models/research/slim'\n","#os.environ['PYTHONPATH'] += ':/content/gdrive/My Drive/deteccion_objectos/models/research/object_detection/protos'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bq3nRl5g4Wg_","colab_type":"code","colab":{}},"source":["!echo $PYTHONPATH"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oj7KaOR3ZNZ3","colab_type":"code","colab":{}},"source":["#variables con las rutas de nuestras dataset de entrenamiento\n","test_record_fname     = '/content/gdrive/My Drive/deteccion_objectos/TFRecords/test.record'\n","train_record_fname    = '/content/gdrive/My Drive/deteccion_objectos/TFRecords/train.record'\n","label_map_pbtxt_fname = '/content/gdrive/My Drive/deteccion_objectos/configuracion/label_map.pbtxt'\n","\n","# número de pasos (epochs) que usaremos para entrenar\n","num_steps = 2000  # 200000\n","\n","# número de evaluaciones por pasos (cada 50 pasos evaluamos el modelo).\n","num_eval_steps = 50\n","\n","# Selecionamos el archivo de configuración del modelo\n","selected_model = 'ssd_mobilenet_v2'\n","\n","MODELS_CONFIG = {\n","    'ssd_mobilenet_v2': {\n","        'model_name': 'ssd_mobilenet_v2_coco_2018_03_29',\n","        'pipeline_file': 'ssd_mobilenet_v2_coco.config',\n","        'batch_size': 12\n","    },\n","    'faster_rcnn_inception_v2': {\n","        'model_name': 'faster_rcnn_inception_v2_coco_2018_01_28',\n","        'pipeline_file': 'faster_rcnn_inception_v2_pets.config',\n","        'batch_size': 12\n","    },\n","    'rfcn_resnet101': {\n","        'model_name': 'rfcn_resnet101_coco_2018_01_28',\n","        'pipeline_file': 'rfcn_resnet101_pets.config',\n","        'batch_size': 8\n","    }\n","}\n","\n","# definimos el tamaño del lote de entrenamiento para uso en la memoria de \n","# la GPU Tesla K80 de Colaborate para el modelo seleccionado.\n","batch_size = MODELS_CONFIG[selected_model]['batch_size']\n","\n","# Nombre del modelo de detección de objectos que usaremos\n","MODEL = MODELS_CONFIG[selected_model]['model_name']\n","\n","# Nombre del archivo de canalización en la API de detección de objetos de tensorflow.\n","pipeline_file = MODELS_CONFIG[selected_model]['pipeline_file']\n","\n","pipeline_fname = os.path.join('/content/gdrive/My Drive/deteccion_objectos/models/research/object_detection/samples/configs/', pipeline_file)\n","print(\"pipeline_fname:\"+pipeline_fname)\n","\n","model_dir = '/content/gdrive/My Drive/deteccion_objectos/models/research/training/'"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"peRAPXkxKfp5","colab_type":"text"},"source":["##.2.2. Crear carpeta necesaria para entrenar (solo una vez)\n","\n","\n","---\n","(una vez creada no se debe ejecutar otra vez o perdemos todo)\n"]},{"cell_type":"code","metadata":{"id":"V91ohigRjmiz","colab_type":"code","colab":{}},"source":["# Recuerden este codigo se hace una sola vez (de lo contrario perderan el entrenamiento)\n","# la carpeta se debe crear en /content/gdrive/My Drive/deteccion_objectos/models/research/\n","!rm -rf {model_dir}\n","os.makedirs(model_dir, exist_ok=True)\n","print(model_dir)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D4Klb-82jDpy","colab_type":"text"},"source":["##.2.3. habilitar tensorboard (opcional)"]},{"cell_type":"markdown","metadata":{"id":"1MAsbH8e9X3B","colab_type":"text"},"source":["###2.3.1 opción 1"]},{"cell_type":"code","metadata":{"id":"o-Lk1H0ojGbW","colab_type":"code","colab":{}},"source":["#descargar y descomprimir el servidor de tensorboard\n","!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n","!unzip -o ngrok-stable-linux-amd64.zip"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1FTifCopji23","colab_type":"code","colab":{}},"source":["LOG_DIR = model_dir\n","get_ipython().system_raw(\n","    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n","    .format('/content/gdrive/My Drive/deteccion_objectos/models/research/training/')\n",")"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BI9HWED-5RKc","colab_type":"code","colab":{}},"source":["get_ipython().system_raw('./ngrok http 6006 &')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fzUaLI9S9d19","colab_type":"text"},"source":["###2.3.2 opción 2"]},{"cell_type":"code","metadata":{"id":"4HBxRpNiB_41","colab_type":"code","colab":{}},"source":["!pip install tensorboardcolab"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"sWsCJOd5CV9l","colab_type":"code","colab":{}},"source":["tbc=TensorBoardColab()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xd-Rc0i_kbhe","colab_type":"text"},"source":["###.2.3.3.generar el link de tensorboard"]},{"cell_type":"code","metadata":{"id":"AxigmcqPk5yc","colab_type":"code","colab":{}},"source":["! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n","    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Kb57vlGflkJ7","colab_type":"text"},"source":["##.2.4 A entrenar se dijo!!!"]},{"cell_type":"code","metadata":{"id":"qQYNs0SX58vj","colab_type":"code","colab":{}},"source":["#aca podemos revisar algunos de los parametros que vamos a tener presente para entrenar\n","print (\"---archivos necesarios para el entremiento---\\n\")\n","print(\"pipeline_fname: \"+pipeline_fname)\n","print(\"model_dir: \"+model_dir)\n","print(\"\\n---parametros para el entrenamiento---\")\n","print(\"num_steps: \"+str(num_steps))\n","print(\"num_eval_steps: \"+str(num_eval_steps))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lXc3O8f1y_5L","colab_type":"text"},"source":["###.2.4.1 opcion 1 para entrenar"]},{"cell_type":"code","metadata":{"id":"Imei5IFKlmcA","colab_type":"code","colab":{}},"source":["!python /content/gdrive/My\\ Drive/deteccion_objectos/models/research/object_detection/model_main.py \\\n","    --pipeline_config_path /content/gdrive/My\\ Drive/deteccion_objectos/models/research/object_detection/samples/configs/ssd_mobilenet_v2_coco.config \\\n","    --model_dir  /content/gdrive/My\\ Drive/deteccion_objectos/models/research/training/ \\\n","    --alsologtostderr \\\n","    --num_train_steps 2000 \\\n","    --num_eval_steps 50"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XlFkiAU0zF6Z","colab_type":"text"},"source":["###.2.4.2 opcion 2 para entrenar usando de forma heredada"]},{"cell_type":"code","metadata":{"id":"BYJmI_8KyX76","colab_type":"code","colab":{}},"source":["%cd /content\n","# Forma de entrenamiento heredada (también funciona y mucho mejor).\n","!python /content/gdrive/My\\ Drive/deteccion_objectos/models/research/object_detection/legacy/train.py \\\n","--alsologtostderr \\\n","--train_dir /content/gdrive/My\\ Drive/deteccion_objectos/models/research/training \\\n","--pipeline_config_path /content/gdrive/My\\ Drive/deteccion_objectos/models/research/object_detection/samples/configs/ssd_mobilenet_v2_coco.config\n","\n","\n","# !python /content/gdrive/My\\ Drive/deteccion_objectos/models/research/object_detection/legacy/train.py --logtostderr --train_dir /content/gdrive/My\\ Drive/deteccion_objectos/models/research/training/ --pipeline_config_path content/gdrive/My\\ Drive/deteccion_objectos/models/research/object_detection/samples/configs/ssd_mobilenet_v2_coco.config "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"T8AOZ3eCpWSi","colab_type":"text"},"source":["#.3. Congelando el grafo inferencial según ultimo checkpoint \n","\n","---\n","\n","Una vez que se completa su trabajo de entrenamiento, debe extraer el gráfico de inferencia recién entrenado, que luego se utilizará para realizar la detección de objetos. Esto puede hacerse de la siguiente manera:"]},{"cell_type":"code","metadata":{"id":"MZpVPuVsEHy6","colab_type":"code","colab":{}},"source":["#eliminamos la carpeta donde se guarda el grafo inferencial congelado\n","import shutil\n","shutil.rmtree('/content/gdrive/My Drive/deteccion_objectos/models/research/fine_tuned_model')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9mi-JQuApX_N","colab_type":"code","colab":{}},"source":["#generamos el nombre el ultimo checkpoint valido de entrenamiento\n","import re\n","import numpy as np\n","\n","%cd /content/gdrive/My\\ Drive/deteccion_objectos/models/research\n","\n","output_directory = '/content/gdrive/My Drive/deteccion_objectos/models/research/fine_tuned_model'\n","\n","lst = os.listdir(model_dir)\n","lst = [l for l in lst if 'model.ckpt-' in l and '.meta' in l]\n","steps=np.array([int(re.findall('\\d+', l)[0]) for l in lst])\n","last_model = lst[steps.argmax()].replace('.meta', '')\n","\n","last_model_path = os.path.join(model_dir, last_model)\n","print(last_model_path)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NHBpGX91E_wj","colab_type":"code","colab":{}},"source":["#generamos el grafo inferencias congelado\n","!python /content/gdrive/My\\ Drive/deteccion_objectos/models/research/object_detection/export_inference_graph.py \\\n","    --input_type=image_tensor \\\n","    --pipeline_config_path='/content/gdrive/My Drive/deteccion_objectos/models/research/object_detection/samples/configs/ssd_mobilenet_v2_coco.config' \\\n","    --output_directory='/content/gdrive/My Drive/deteccion_objectos/models/research/fine_tuned_model' \\\n","    --trained_checkpoint_prefix='/content/gdrive/My Drive/deteccion_objectos/models/research/training/model.ckpt-758'"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"McFkeqtDseYh","colab_type":"text"},"source":["#.4. Exportando el grafo inferencial en un archivo serializado (.PB)"]},{"cell_type":"code","metadata":{"id":"mDGUb-AZsg0D","colab_type":"code","colab":{}},"source":["import os\n","output_directory='/content/gdrive/My Drive/deteccion_objectos/models/research/fine_tuned_model'\n","pb_fname = os.path.join(os.path.abspath(output_directory), \"frozen_inference_graph.pb\")\n","\n","assert os.path.isfile(pb_fname), '`{}` not exist'.format(pb_fname)\n","!ls -alh {pb_fname}\n","from google.colab import files\n","#descargamos el modelo\n","files.download(pb_fname)\n","#descargamos el mapa de etiquetas.\n","files.download(label_map_pbtxt_fname)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"YXzaBNYgt3RU","colab_type":"text"},"source":["#.5. probando el grafo de inferencia."]},{"cell_type":"code","metadata":{"id":"7ptEwrTot5d1","colab_type":"code","colab":{}},"source":["import os\n","import glob\n","\n","# Ruta del gráfo de detección congelado. Este es el modelo real que se utiliza para la detección de objetos.\n","PATH_TO_CKPT = pb_fname\n","\n","# Lista de las cadenas que se utilizan para agregar la etiqueta correcta para cada cuadro.\n","PATH_TO_LABELS = label_map_pbtxt_fname\n","\n","# ruta donde estan las imágenes para probar\n","PATH_TO_TEST_IMAGES_DIR =  \"/content/gdrive/My Drive/deteccion_objectos/img_prueba\"\n","\n","assert os.path.isfile(pb_fname)\n","assert os.path.isfile(PATH_TO_LABELS)\n","TEST_IMAGE_PATHS = glob.glob(os.path.join(PATH_TO_TEST_IMAGES_DIR, \"*.*\"))\n","assert len(TEST_IMAGE_PATHS) > 0, 'No image found in `{}`.'.format(PATH_TO_TEST_IMAGES_DIR)\n","print(TEST_IMAGE_PATHS)\n","\n","#número de clases a las que se liminara el grafo.\n","num_classes = 3"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"AgAfrZdawB4t","colab_type":"code","colab":{}},"source":["%cd /content/gdrive/My\\ Drive/deteccion_objectos/models/research/object_detection\n","\n","import numpy as np\n","import os\n","import six.moves.urllib as urllib\n","import sys\n","import tarfile\n","import tensorflow as tf\n","import zipfile\n","from collections import defaultdict\n","from io import StringIO\n","from matplotlib import pyplot as plt\n","from PIL import Image\n","\n","sys.path.append(\"..\")\n","from object_detection.utils import ops as utils_ops\n","\n","#Esto es necesario para mostrar las imágenes.\n","%matplotlib inline\n","\n","from object_detection.utils import label_map_util\n","from object_detection.utils import visualization_utils as vis_util\n","\n","detection_graph = tf.Graph()\n","with detection_graph.as_default():\n","  od_graph_def = tf.GraphDef()\n","  with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n","    serialized_graph = fid.read()\n","    od_graph_def.ParseFromString(serialized_graph)\n","    tf.import_graph_def(od_graph_def, name='')\n","\n","label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n","categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=num_classes, use_display_name=True)\n","category_index = label_map_util.create_category_index(categories)\n","\n","def load_image_into_numpy_array(image):\n","    (im_width, im_height) = image.size\n","    return np.array(image.getdata()).reshape(\n","        (im_height, im_width, 3)).astype(np.uint8)\n","\n","# Size, in inches, of the output images.\n","IMAGE_SIZE = (12, 8)\n","\n","#funcion para analizar inferencia en una imagen\n","def run_inference_for_single_image(image, graph):\n","    with graph.as_default():\n","        with tf.Session() as sess:\n","            # Obtenga manijas para tensores de entrada y salida\n","            ops = tf.get_default_graph().get_operations()\n","            all_tensor_names = {\n","                output.name for op in ops for output in op.outputs}\n","            tensor_dict = {}\n","            for key in [\n","                'num_detections', 'detection_boxes', 'detection_scores',\n","                'detection_classes', 'detection_masks'\n","            ]:\n","                tensor_name = key + ':0'\n","                if tensor_name in all_tensor_names:\n","                    tensor_dict[key] = tf.get_default_graph().get_tensor_by_name(\n","                        tensor_name)\n","            if 'detection_masks' in tensor_dict:\n","                # El siguiente procesamiento es solo para una sola imagen\n","                detection_boxes = tf.squeeze(\n","                    tensor_dict['detection_boxes'], [0])\n","                detection_masks = tf.squeeze(\n","                    tensor_dict['detection_masks'], [0])\n","                # Es necesario volver a enmarcar para traducir la máscara de las coordenadas del cuadro a las coordenadas de la imagen y ajustar el tamaño de la imagen.\n","                real_num_detection = tf.cast(\n","                    tensor_dict['num_detections'][0], tf.int32)\n","                detection_boxes = tf.slice(detection_boxes, [0, 0], [\n","                                           real_num_detection, -1])\n","                detection_masks = tf.slice(detection_masks, [0, 0, 0], [\n","                                           real_num_detection, -1, -1])\n","                detection_masks_reframed = utils_ops.reframe_box_masks_to_image_masks(\n","                    detection_masks, detection_boxes, image.shape[0], image.shape[1])\n","                detection_masks_reframed = tf.cast(\n","                    tf.greater(detection_masks_reframed, 0.5), tf.uint8)\n","                # Siga la convención agregando nuevamente la dimensión del lote\n","                tensor_dict['detection_masks'] = tf.expand_dims(\n","                    detection_masks_reframed, 0)\n","            image_tensor = tf.get_default_graph().get_tensor_by_name('image_tensor:0')\n","\n","            # Run inference\n","            output_dict = sess.run(tensor_dict,feed_dict={image_tensor: np.expand_dims(image, 0)})\n","\n","            # todas las salidas son matrices numpy float32, así que convierta los tipos según corresponda\n","            output_dict['num_detections'] = int(output_dict['num_detections'][0])\n","            output_dict['detection_classes'] = output_dict['detection_classes'][0].astype(np.uint8)\n","            output_dict['detection_boxes'] = output_dict['detection_boxes'][0]\n","            output_dict['detection_scores'] = output_dict['detection_scores'][0]\n","            if 'detection_masks' in output_dict:\n","                output_dict['detection_masks'] = output_dict['detection_masks'][0]\n","    return output_dict\n","\n","\n","for image_path in TEST_IMAGE_PATHS:\n","  print(image_path)\n","  image = Image.open(image_path)\n","  # la representación basada en matriz de la imagen se usará más adelante para preparar la imagen resultante con cuadros y etiquetas.\n","  image_np = load_image_into_numpy_array(image)\n","  # Amplíe las dimensiones ya que el modelo espera que las imágenes tengan forma: [1, None, None, 3]\n","  image_np_expanded = np.expand_dims(image_np, axis=0)\n","  # deteción actual\n","  output_dict = run_inference_for_single_image(image_np, detection_graph)\n","  # Visualización de los resultados de una detección.\n","  vis_util.visualize_boxes_and_labels_on_image_array(\n","    image_np,\n","    output_dict['detection_boxes'],\n","    output_dict['detection_classes'],\n","    output_dict['detection_scores'],\n","    category_index,\n","    instance_masks=output_dict.get('detection_masks'),\n","    use_normalized_coordinates=True,\n","    line_thickness=8)\n","  plt.figure(figsize=IMAGE_SIZE)\n","  plt.imshow(image_np)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BGDQAQT76lUS","colab_type":"text"},"source":["#.6.Exportando grafo a un formato lite (celulares y raspberry)."]},{"cell_type":"code","metadata":{"id":"wTzBNg1F7WiR","colab_type":"code","colab":{}},"source":["DEST_DIR='/content/gdrive/My Drive/deteccion_objectos/models/research/pretrained_model'\n","fine_tune_checkpoint = os.path.join(\"/content/gdrive/My Drive/deteccion_objectos/models/research/pretrained_model\", \"model.ckpt\")\n","#!echo {DEST_DIR}\n","#!ls -alh {DEST_DIR}\n","print(\"fine_tune_checkpoint: \"+fine_tune_checkpoint)\n","print(\"pb_fname: \"+pb_fname)\n","print(\"pipeline_fname: \"+pipeline_fname)\n","print(\"model_dir: \"+model_dir)\n","!ls -alh /content/gdrive/My\\ Drive/deteccion_objectos/models/research/training/"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"IWnO6LTl6VWV","colab_type":"code","colab":{}},"source":["!python /content/gdrive/My\\ Drive/deteccion_objectos/models/research/object_detection/export_tflite_ssd_graph.py \\\n","--pipeline_config_path=/content/gdrive/My\\ Drive/deteccion_objectos/models/research/object_detection/samples/configs/ssd_mobilenet_v2_coco.config \\\n","--trained_checkpoint_prefix=/content/gdrive/My\\ Drive/deteccion_objectos/models/research/training/model.ckpt-663 \\\n","--output_directory=/content/gdrive/My\\ Drive/deteccion_objectos/models/research/tflite \\\n","--add_postprocessing_op=true"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1-efDEF1pgaW","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","converter = tf.lite.TFLiteConverter.from_saved_model(\"/content/modelo_salvado\")\n","converter.optimizations = [tf.lite.Optimize.DEFAULT]\n","tflite_quant_model = converter.convert()"],"execution_count":0,"outputs":[]}]}